{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how data are represented at each level (forward, backward, forward with padding on top) needs a little\n",
    "    #experimentation to determine the best representation\n",
    "    #also, is encoding at each layer really the best way? or just feeding the raw through?\n",
    "    \n",
    "#Outside web ips are going to be a problem/messy/noisy. Start by categorizing all outside ips by <OUTSIDE_IP>\n",
    "    #instead of the ip address, or another 4 digit symbol to insert into the hex string.\n",
    "    \n",
    "#to help the models generalize more, for a given source ip address with probability p (say p = 0.1) \n",
    "    #use the token <OTHER_MACHINE>\n",
    "    \n",
    "#should we remove random parts of the header, i.e. checksum\n",
    "\n",
    "#should I take out bias for RNNs?\n",
    "\n",
    "#for the decoder,does the fork encoding need to happen ?\n",
    "    #do we simply cat the hContext with the next words?\n",
    "    \n",
    "#Should the architecture just be encode, context and then prediction???\n",
    "\n",
    "#Input data, should it have character and hex pair encoding as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to execute tcpdump. Check it is installed and in the PATH\n",
      "WARNING: No route found for IPv6 destination :: (no default route?)\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=gpu'#,optimizer=fast_compile'\n",
    "\n",
    "import sys\n",
    "import binascii\n",
    "import multiprocessing as mp\n",
    "from itertools import chain\n",
    "from scapy.all import *\n",
    "sys.path.append('hed-dlg/')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import itemfreq\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "\n",
    "import blocks\n",
    "from blocks.bricks import Linear, Softmax, Softplus, NDimensionalSoftmax, BatchNormalizedMLP, \\\n",
    "                                Rectifier, Logistic, Tanh, MLP\n",
    "from blocks.bricks.recurrent import GatedRecurrent, Fork, LSTM\n",
    "from blocks.initialization import Constant, IsotropicGaussian, Identity, Uniform\n",
    "from blocks.bricks.cost import BinaryCrossEntropy, CategoricalCrossEntropy\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.roles import PARAMETER\n",
    "from blocks.graph import ComputationGraph\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "###These warnings do not impede progress\n",
    "#WARNING: Failed to execute tcpdump. Check it is installed and in the PATH\n",
    "#WARNING: No route found for IPv6 destination :: (no default route?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPath = '/data/fs4/datasets/pcaps/smallFlows.pcap'\n",
    "pcaps = rdpcap(dataPath)\n",
    "sessionPrep = pcaps.sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def parse_header(line):\n",
    "    ret_dict = {}\n",
    "    h = line.split()\n",
    "    #ret_dict['direction'] = \" \".join(h[3:6])\n",
    "\n",
    "    if h[2] == 'IP6':\n",
    "        \"\"\"\n",
    "        Conditional formatting based on ethernet type.\n",
    "        IPv4 format: 0.0.0.0.port\n",
    "        IPv6 format (one of many): 0:0:0:0:0:0.port\n",
    "        \"\"\"\n",
    "        ret_dict['src_port'] = h[3].split('.')[-1]\n",
    "        ret_dict['src_ip'] = h[3].split('.')[0]\n",
    "\n",
    "        ret_dict['dest_port'] = h[5].split('.')[-1].split(':')[0]\n",
    "        ret_dict['dest_ip'] = h[5].split('.')[0]\n",
    "    else:\n",
    "        if len(h[3].split('.')) > 4:\n",
    "            ret_dict['src_port'] = h[3].split('.')[-1]\n",
    "            ret_dict['src_ip'] = '.'.join(h[3].split('.')[:-1])\n",
    "        else:\n",
    "            ret_dict['src_ip'] = h[3]\n",
    "            ret_dict['src_port'] = ''\n",
    "\n",
    "        if len(h[5].split('.')) > 4:\n",
    "            ret_dict['dest_port'] = h[5].split('.')[-1].split(':')[0]\n",
    "            ret_dict['dest_ip'] = '.'.join(h[5].split('.')[:-1])\n",
    "        else:\n",
    "            ret_dict['dest_ip'] = h[5].split(':')[0]\n",
    "            ret_dict['dest_port'] = ''\n",
    "\n",
    "    try:\n",
    "        if ret_dict['src_port'] == '53' or ret_dict['dst_port'] == '53':\n",
    "            ret_dict['length'] = int(h[-1][1:-1])\n",
    "        else:\n",
    "            try:\n",
    "                ret_dict['length'] = int(line.split(' length ')[1].split(':')[0])\n",
    "            except:\n",
    "                ret_dict['length'] = 0\n",
    "    except:\n",
    "        try:\n",
    "            ret_dict['length'] = int(line.split(' length ')[1].split(':')[0])\n",
    "        except:\n",
    "            ret_dict['length'] = 0\n",
    "\n",
    "    return ret_dict\n",
    "\n",
    "def parse_data(line, length):\n",
    "    ret_str = ''\n",
    "    h, d = line.split(':', 1)\n",
    "    ret_str = d.strip().replace(' ', '')\n",
    "    if length != 0:\n",
    "        ret_str = ret_str[:-(2 * length)]\n",
    "    return ret_str\n",
    "\n",
    "def process_packet(output):\n",
    "    # TODO!! throws away the first packet!\n",
    "    ret_header = {}\n",
    "    ret_dict = {}\n",
    "    ret_data = ''\n",
    "    for line in output:\n",
    "        line = line.strip()\n",
    "        if line.startswith('0x'):\n",
    "            data = parse_data(line, ret_header['length'])\n",
    "            ret_data = ret_data + data\n",
    "        else:\n",
    "            ret_header = parse_header(line)\n",
    "            ret_dict.update(ret_header)\n",
    "            if ret_data != '':\n",
    "                ret_dict['data'] = ret_data\n",
    "                ret_data = ''\n",
    "            yield ret_dict\n",
    "\n",
    "def read_pcap(path):\n",
    "    hex_sessions = {}\n",
    "    proc = subprocess.Popen('tcpdump -nn -tttt -xx -r '+path,\n",
    "                            shell=True,\n",
    "                            stdout=subprocess.PIPE)\n",
    "    for packet in process_packet(proc.stdout):\n",
    "        a = str(packet)\n",
    "        a = ast.literal_eval(a)\n",
    "        if 'data' in a:\n",
    "            key = (a['src_ip']+\":\"+a['src_port'], a['dest_ip']+\":\"+a['dest_port'])\n",
    "            keys = [k for k in hex_sessions if (k[0] == key[0] and k[1] == key[1]) or (k[0] == key[1] and k[1] == key[0])]\n",
    "            if len(keys) > 0:\n",
    "                #hex_sessions[keys[0]].append(a['direction']+a['data'])\n",
    "                hex_sessions[keys[0]].append(a['data'])\n",
    "            else:\n",
    "                #hex_sessions[key] = [a['direction']+a['data']]\n",
    "                hex_sessions[key] = [a['data']]\n",
    "    return hex_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hexSessions = read_pcap(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#turns the sessions into a dictionary key = session_number, val = list of packages in hex\n",
    "minPackets = 2\n",
    "\n",
    "def hexSessionDictCreator(scapySessions, minPackets = 2):\n",
    "\n",
    "    hexSessions = {}\n",
    "    i=0\n",
    "    for k,v in sessionPrep.items(): # v is the session\n",
    "        \n",
    "        if len(v) < minPackets:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            scpcaps = []    \n",
    "            \n",
    "            for p in v: #p is the individual packet in the session  \n",
    "                \n",
    "                try: #getting rid of payload\n",
    "                    rawindex = len(p[Raw]) \n",
    "                    #payloadLens.append(rawindex)\n",
    "                    scpcaps.append(binascii.hexlify(str(p.original)[:-rawindex])) #turn it into hex\n",
    "                \n",
    "                except: #if no payload\n",
    "                    scpcaps.append(binascii.hexlify(str(p.original)))\n",
    "    \n",
    "            hexSessions['session_' + str(i)] = scpcaps\n",
    "            i+=1\n",
    "    #assert that all sessions have len of at least minPackets\n",
    "    return hexSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hexSessions = hexSessionDictCreator(sessionPrep, minPackets=minPackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making the hex dictionary\n",
    "def hexTokenizer():\n",
    "    hexstring = '0,\t1,\t2,\t3,\t4,\t5,\t6,\t7,\t8,\t9,\tA,\tB,\tC,\tD,\tE,\tF,\t10,\t11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19\\\n",
    "    ,\t1A,\t1B,\t1C,\t1D,\t1E,\t1F,\t20,\t21,\t22,\t23,\t24,\t25,\t26,\t27,\t28,\t29,\t2A,\t2B,\t2C,\t2D,\t2E,\t2F,\t30,\t31,\t32,\t33,\t34,\t35\\\n",
    "    ,\t36,\t37,\t38,\t39,\t3A,\t3B,\t3C,\t3D,\t3E,\t3F,\t40,\t41,\t42,\t43,\t44,\t45,\t46,\t47,\t48,\t49,\t4A,\t4B,\t4C,\t4D,\t4E,\t4F,\t50,\t51\\\n",
    "    ,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t5A,\t5B,\t5C,\t5D,\t5E,\t5F,\t60,\t61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t6A,\t6B,\t6C,\t6D\\\n",
    "    ,\t6E,\t6F,\t70,\t71,\t72,\t73,\t74,\t75,\t76,\t77,\t78,\t79,\t7A,\t7B,\t7C,\t7D,\t7E,\t7F,\t80,\t81,\t82,\t83,\t84,\t85,\t86,\t87,\t88,\t89\\\n",
    "    ,\t8A,\t8B,\t8C,\t8D,\t8E,\t8F,\t90,\t91,\t92,\t93,\t94,\t95,\t96,\t97,\t98,\t99,\t9A,\t9B,\t9C,\t9D,\t9E,\t9F,\tA0,\tA1,\tA2,\tA3,\tA4,\tA5\\\n",
    "    ,\tA6,\tA7,\tA8,\tA9,\tAA,\tAB,\tAC,\tAD,\tAE,\tAF,\tB0,\tB1,\tB2,\tB3,\tB4,\tB5,\tB6,\tB7,\tB8,\tB9,\tBA,\tBB,\tBC,\tBD,\tBE,\tBF,\tC0,\tC1\\\n",
    "    ,\tC2,\tC3,\tC4,\tC5,\tC6,\tC7,\tC8,\tC9,\tCA,\tCB,\tCC,\tCD,\tCE,\tCF,\tD0,\tD1,\tD2,\tD3,\tD4,\tD5,\tD6,\tD7,\tD8,\tD9,\tDA,\tDB,\tDC,\tDD\\\n",
    "    ,\tDE,\tDF,\tE0,\tE1,\tE2,\tE3,\tE4,\tE5,\tE6,\tE7,\tE8,\tE9,\tEA,\tEB,\tEC,\tED,\tEE,\tEF,\tF0,\tF1,\tF2,\tF3,\tF4,\tF5,\tF6,\tF7,\tF8,\tF9\\\n",
    "    ,\tFA,\tFB,\tFC,\tFD,\tFE,\tFF'.replace('\\t', '')\n",
    "\n",
    "    hexList = [x.strip() for x in hexstring.lower().split(',')]\n",
    "    hexList.append('<EOP>') #End Of Packet token\n",
    "    #EOS token??????\n",
    "    hexDict = {}\n",
    "\n",
    "    for key, val in enumerate(hexList):\n",
    "        if len(val) == 1:\n",
    "            val = '0'+val\n",
    "        hexDict[val] = key  #dictionary k=hex, v=int  \n",
    "    \n",
    "    return hexDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hexDict = hexTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary of IP communications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def srcIpDict(hexSessionDict):\n",
    "    ''' \n",
    "    input: dictionary of key = sessions, value = list of HEX HEADERS of packets in session\n",
    "    output: dictionary of key = source IP, value/subkey = dictionary of destination IPs, \n",
    "                                           subvalue = [[sport], [dport], [plen], [protocol]]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    srcIpDict = {}   \n",
    "    uniqIPs = [] #some ips are dest only. this will collect all ips, not just srcIpDict.keys()\n",
    "    \n",
    "    for session in hexSessionDict.keys():\n",
    "        \n",
    "        for rawpacket in hexSessionDict[session]:\n",
    "            packet = copy(rawpacket)\n",
    "            \n",
    "            dstIpSubDict = {}\n",
    "\n",
    "            srcip = packet[52:60]\n",
    "            dstip = packet[60:68]\n",
    "            sport = packet[68:72]\n",
    "            dport = packet[72:76]\n",
    "            plen = packet[32:36]\n",
    "            protocol = packet[46:48]\n",
    "            \n",
    "            uniqIPs = list(set(uniqIPs) | set([dstip, srcip]))\n",
    "            \n",
    "            if srcip not in srcIpDict:\n",
    "                dstIpSubDict[dstip] = [[sport], [dport], [plen], [protocol]]\n",
    "                srcIpDict[srcip] = dstIpSubDict\n",
    "            \n",
    "            if dstip not in srcIpDict[srcip]:    \n",
    "                srcIpDict[srcip][dstip] = [[sport], [dport], [plen], [protocol]]\n",
    "            else:\n",
    "                srcIpDict[srcip][dstip][0].append(sport)\n",
    "                srcIpDict[srcip][dstip][1].append(dport)\n",
    "                srcIpDict[srcip][dstip][2].append(plen)\n",
    "                srcIpDict[srcip][dstip][3].append(protocol)\n",
    "                \n",
    "\n",
    "    return srcIpDict, uniqIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictUniquerizer(dictOdictsOlistOlists):\n",
    "    '''\n",
    "    input: dictionary of dictionaries that have a list of lists \n",
    "           ex. srcIpDict[srcip][dstip] = [[sport], [dport], [plen], [protocol]]\n",
    "    output: dictionary of dictionaries with list of lists with unique items in the final sublist\n",
    "    \n",
    "    WARNING: will overwrite your input dictionary. Make a copy if you want to preserve dictOdictsOlistOlists.\n",
    "    '''\n",
    "    #dictCopy\n",
    "    for key in dictOdictsOlistOlists.keys():\n",
    "        for subkey in dictOdictsOlistOlists[key].keys():\n",
    "            for sublist in xrange(len(dictOdictsOlistOlists[key][subkey])):\n",
    "                dictOdictsOlistOlists[key][subkey][sublist] = list(set(dictOdictsOlistOlists[key][subkey][sublist]))\n",
    "    \n",
    "    return dictOdictsOlistOlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "comsDict, uniqIPs = srcIpDict(hexSessions)\n",
    "#test\n",
    "comsDict = dictUniquerizer(comsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directionality adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ipDirSwitcher(hexSessionList):\n",
    "    '''\n",
    "    input is a list of packets from ONE session\n",
    "    '''\n",
    "    \n",
    "    ipdirsession = []\n",
    "        \n",
    "    for p in hexSessionList:\n",
    "        sourceIP = p[52:60]\n",
    "        destIP = p[60:68]\n",
    "\n",
    "        ipdirsession.append(p[:52]+destIP+sourceIP+p[68:])\n",
    "\n",
    "    return ipdirsession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def portDirSwitcher(hexSessionList):\n",
    "    '''\n",
    "    input is a list of packets from ONE session\n",
    "    '''\n",
    "    \n",
    "    portdirsession = []\n",
    "    \n",
    "    for p in hexSessionList:\n",
    "        sport = p[68:72]\n",
    "        dport = p[72:76]\n",
    "\n",
    "        portdirsession.append(p[:68]+dport+sport+p[76:])\n",
    "\n",
    "    return portdirsession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one swap one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dstIpSwapOut(hexSessionList, dictOcoms, listOuniqIPs):\n",
    "    #srcIpDict[srcip][dstip] = [[sport], [dport], [plen], [protocol]]\n",
    "    \n",
    "    swapSession = []\n",
    "    srcip = hexSessionList[0][52:60] #assumes first packet contains true initial direction\n",
    "    dstip = hexSessionList[0][60:68]\n",
    "    normDstIps = dictOcoms[srcip].keys()+[srcip] #get list of dstIPs that srcIP talks to\n",
    "    abbynormIps = copy(listOuniqIPs)\n",
    "    \n",
    "    for normIp in normDstIps:\n",
    "        abbynormIps.remove(normIp) #remove itself and know dstIPs from list of consideration.\n",
    "    \n",
    "    abbynormDestIp = random.sample(abbynormIps, 1)[0] #get random ip that srcip doesn't talk to\n",
    "\n",
    "    for rawpacket in hexSessionList:\n",
    "        packet = copy(rawpacket)\n",
    "        \n",
    "        if packet[60:68] == dstip:\n",
    "            packet = packet[:60] + abbynormDestIp + packet[68:] #\n",
    "        elif packet[61:69] == srcip:\n",
    "            packet = packet[:52] + abbynormDestIp + packet[60:] #in case direction switches for packet in session\n",
    "            \n",
    "        swapSession.append(packet)\n",
    "\n",
    "    return swapSession\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dstPortSwapOneOut(hexSessionList):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHot(index, granular = 'hex'):\n",
    "    if granular == 'hex':\n",
    "        vecLen = 257\n",
    "    else:\n",
    "        vecLen = 17\n",
    "    \n",
    "    zeroVec = np.zeros(vecLen)\n",
    "    zeroVec[index] = 1.0\n",
    "    \n",
    "    return zeroVec\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneSessionTokenized(sessionDict, hexDict, packetTimeSteps=50):\n",
    "\n",
    "    dstMac = []\n",
    "    srcMac = []\n",
    "    firstType = []\n",
    "    ihl = []\n",
    "    tos = []\n",
    "    firLen = []\n",
    "    firId = []\n",
    "    frag = []\n",
    "    ttl = []\n",
    "    protocol = []\n",
    "    firCheck = []\n",
    "    srcip = []\n",
    "    dstip = []\n",
    "    sport = []\n",
    "    dport = []\n",
    "    \n",
    "    i=0\n",
    "    for key in sessionDict.keys():\n",
    "        sessionPackets = sessionDict[key]\n",
    "        \n",
    "        #if len(sessionPackets) > maxPackets: #crop the number of sessions to maxPackets\n",
    "        #    sessionList = sessionPackets[:maxPackets]\n",
    "        #else:\n",
    "        #    sessionList = sessionPackets\n",
    "\n",
    "        for packet in sessionPackets:\n",
    "            \n",
    "            dstMac.append(packet[0:12]) \n",
    "            srcMac.append(packet[12:24]) \n",
    "            firstType.append(packet[24:28])\n",
    "            ihl.append(packet[28:30]) \n",
    "            tos.append(packet[30:32])\n",
    "            firLen.append(packet[32:36])\n",
    "            firId.append(packet[36:40]) \n",
    "            frag.append(packet[40:44]) \n",
    "            ttl.append(packet[44:46])\n",
    "            protocol.append(packet[46:48])\n",
    "            firCheck.append(packet[48:52]) \n",
    "            srcip.append(packet[52:60])\n",
    "            dstip.append(packet[60:68])\n",
    "            sport.append(packet[68:72])\n",
    "            dport.append(packet[72:76])\n",
    "            \n",
    "            i+=1\n",
    "    print i\n",
    "    return np.asarray(dstMac), np.asarray(srcMac),np.asarray(firstType),np.asarray(ihl),np.asarray(tos),\\\n",
    "           np.asarray(firLen),np.asarray(firId),np.asarray(frag),np.asarray(ttl),np.asarray(protocol),\\\n",
    "           np.asarray(firCheck),np.asarray(srcip),np.asarray(dstip), np.asarray(sport), np.asarray(dport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netstats  = oneSessionTokenized(hexSessions, hexDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indx = ['dstMac', 'srcMac', 'firstType', 'ihl', 'tos', 'firLen', 'firId', 'frag', 'ttl', 'protocol', 'firCheck',\n",
    "       'srcip', 'dstip', 'sport', 'dport']\n",
    "for num in range(13):\n",
    "    print indx[num], len(np.unique(netstats[num]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packet = hexSessions[hexSessions.keys()[1]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coll = []\n",
    "for key in hexSessions.keys():\n",
    "    sessionPackets = hexSessions[key]\n",
    "    for packet in sessionPackets:\n",
    "        coll.append(packet[32:36]+packet[44:46]+packet[46:48]+packet[52:60]+packet[60:68]+packet[68:70]+packet[70:72]+\n",
    "                   packet[72:74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(coll).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxPackets = 2\n",
    "packetTimeSteps = 16\n",
    "\n",
    "def oneSessionEncoder(sessionPackets, hexDict, maxPackets = 2, packetTimeSteps = 100,\n",
    "                       packetReverse = False, charLevel = False, padOldTimeSteps = True):    \n",
    "            \n",
    "    sessionCollect = []\n",
    "    packetCollect = []\n",
    "    \n",
    "    if charLevel:\n",
    "        vecLen = 17\n",
    "    else:\n",
    "        vecLen = 257\n",
    "    \n",
    "    if len(sessionPackets) > maxPackets: #crop the number of sessions to maxPackets\n",
    "        sessionList = copy(sessionPackets[:maxPackets])\n",
    "    else:\n",
    "        sessionList = copy(sessionPackets)\n",
    "\n",
    "    for rawpacket in sessionList:\n",
    "        packet = copy(rawpacket)\n",
    "        packet = packet[32:36]+packet[44:46]+packet[46:48]+packet[52:60]+packet[60:68]+\\\n",
    "                 packet[68:70]+packet[70:72]+packet[72:74]\n",
    "        packet = [hexDict[packet[i:i+2]] for i in xrange(0,len(packet)-2+1,2)]\n",
    "        \n",
    "        #print np.asarray(packet)\n",
    "            \n",
    "        if len(packet) >= packetTimeSteps: #crop packet to length packetTimeSteps\n",
    "            packet = packet[:packetTimeSteps]\n",
    "            packet = packet+[256] #add <EOP> end of packet token\n",
    "        else:\n",
    "            packet = packet+[256] #add <EOP> end of packet token\n",
    "        \n",
    "        packetCollect.append(packet)\n",
    "        \n",
    "        pacMat = np.array([oneHot(x) for x in packet]) #one hot encoding of packet into a matrix\n",
    "        pacMatLen = len(pacMat)\n",
    "        \n",
    "        #padding packet\n",
    "        if packetReverse:\n",
    "            pacMat = pacMat[::-1]\n",
    "\n",
    "        if pacMatLen < packetTimeSteps:\n",
    "            #pad by stacking zeros on top of data so that earlier timesteps do not have information\n",
    "            #padding the packet such that zeros are after the actual info for better translation\n",
    "            if padOldTimeSteps:\n",
    "                pacMat = np.vstack( ( np.zeros((packetTimeSteps-pacMatLen,vecLen)), pacMat) ) \n",
    "            else:\n",
    "                pacMat = np.vstack( (pacMat, np.zeros((packetTimeSteps-pacMatLen,vecLen))) ) \n",
    "\n",
    "        if pacMatLen > packetTimeSteps:\n",
    "            pacMat = pacMat[:packetTimeSteps, :]\n",
    "\n",
    "        sessionCollect.append(pacMat)\n",
    "\n",
    "    #padding session\n",
    "    sessionCollect = np.asarray(sessionCollect, dtype=theano.config.floatX)\n",
    "    numPacketsInSession = sessionCollect.shape[0]\n",
    "    if numPacketsInSession < maxPackets:\n",
    "        #pad sessions to fit the \n",
    "        sessionCollect = np.vstack( (sessionCollect,np.zeros((maxPackets-numPacketsInSession, \n",
    "                                                             packetTimeSteps, vecLen))) )\n",
    "    \n",
    "    return sessionCollect, packetCollect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p != 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X / retain_prob * srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "    return X\n",
    "\n",
    "# Gradient clipping\n",
    "def clip_norm(g, c, n): \n",
    "    '''n is the norm, c is the threashold, and g is the gradient'''\n",
    "    \n",
    "    if c > 0: \n",
    "        g = T.switch(T.ge(n, c), g*c/n, g) \n",
    "    return g\n",
    "\n",
    "def clip_norms(gs, c):\n",
    "    norm = T.sqrt(sum([T.sum(g**2) for g in gs]))\n",
    "    return [clip_norm(g, c, norm) for g in gs]\n",
    "\n",
    "# Regularizers\n",
    "def max_norm(p, maxnorm = 0.):\n",
    "    if maxnorm > 0:\n",
    "        norms = T.sqrt(T.sum(T.sqr(p), axis=0))\n",
    "        desired = T.clip(norms, 0, maxnorm)\n",
    "        p = p * (desired/ (1e-7 + norms))\n",
    "    return p\n",
    "\n",
    "def gradient_regularize(p, g, l1 = 0., l2 = 0.):\n",
    "    g += p * l2\n",
    "    g += T.sgn(p) * l1\n",
    "    return g\n",
    "\n",
    "def weight_regularize(p, maxnorm = 0.):\n",
    "    p = max_norm(p, maxnorm)\n",
    "    return p\n",
    "\n",
    "def Adam(params, cost, lr=0.0002, b1=0.1, b2=0.001, e=1e-8, l1 = 0., l2 = 0., maxnorm = 0., c = 8):\n",
    "    \n",
    "    updates = []\n",
    "    grads = T.grad(cost, params)\n",
    "    grads = clip_norms(grads, c)\n",
    "    \n",
    "    i = theano.shared(floatX(0.))\n",
    "    i_t = i + 1.\n",
    "    fix1 = 1. - b1**(i_t)\n",
    "    fix2 = 1. - b2**(i_t)\n",
    "    lr_t = lr * (T.sqrt(fix2) / fix1)\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        m = theano.shared(p.get_value() * 0.)\n",
    "        v = theano.shared(p.get_value() * 0.)\n",
    "        m_t = (b1 * g) + ((1. - b1) * m)\n",
    "        v_t = (b2 * T.sqr(g)) + ((1. - b2) * v)\n",
    "        g_t = m_t / (T.sqrt(v_t) + e)\n",
    "        g_t = gradient_regularize(p, g_t, l1=l1, l2=l2)\n",
    "        p_t = p - (lr_t * g_t)\n",
    "        p_t = weight_regularize(p_t, maxnorm=maxnorm)\n",
    "        \n",
    "        updates.append((m, m_t))\n",
    "        updates.append((v, v_t))\n",
    "        updates.append((p, p_t))\n",
    "    \n",
    "    updates.append((i, i_t))\n",
    "    return updates\n",
    "\n",
    "def RMSprop(cost, params, lr = 0.001, l1 = 0., l2 = 0., maxnorm = 0., rho=0.9, epsilon=1e-6, c = 8):\n",
    "    \n",
    "    grads = T.grad(cost, params)\n",
    "    grads = clip_norms(grads, c)\n",
    "    updates = []\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        g = gradient_regularize(p, g, l1 = l1, l2 = l2)\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        updates.append((acc, acc_new))\n",
    "        \n",
    "        updated_p = p - lr * (g / T.sqrt(acc_new + epsilon))\n",
    "        updated_p = weight_regularize(updated_p, maxnorm = maxnorm)\n",
    "        updates.append((p, updated_p))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#makes output by shifting inputs down in time one step and then copying the last time step to the end.\n",
    "#def targetModifier(targetArray):\n",
    "#    newTarget = np.vstack((targetArray[1:, :], targetArray[-1,:]))\n",
    "#    return newTarget\n",
    "\n",
    "#def targetMaker(listOinputs):\n",
    "    #TODO: do this with arrays\n",
    "#    outputs = []\n",
    "#    for inp in listOinputs:\n",
    "#        outputs.append(targetModifier(inp))\n",
    "#    outputs = np.asarray(outputs)\n",
    "#    \n",
    "#    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization for both the unsupervised net and the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4('inputs')\n",
    "Y = T.matrix('targets')\n",
    "\n",
    "dimIn = 257 #hex has 256 characters + the <EOP> character\n",
    "dim = 100 #dimension reduction size\n",
    "rnnType = 'gru' #gru or lstm\n",
    "bidirectional = False\n",
    "linewt_init = IsotropicGaussian(0.1)\n",
    "line_bias = Constant(1.0)\n",
    "rnnwt_init = IsotropicGaussian(0.1)\n",
    "rnnbias_init = Constant(0.0)\n",
    "packetReverse = False\n",
    "\n",
    "###ENCODER\n",
    "if rnnType == 'gru':\n",
    "    rnn = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "fork = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dimIn, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "\n",
    "###CONTEXT\n",
    "if rnnType == 'gru':\n",
    "    rnnContext = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                biases_init = rnnbias_init, name = 'gruContext')\n",
    "else:\n",
    "    rnnContext = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, \n",
    "                      name = 'lstmContext')\n",
    "\n",
    "forkContext = Fork(output_names=['linearContext', 'gatesContext'],\n",
    "            name='forkContext', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "if bidirectional:\n",
    "    dimDec = dim*2\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        rnnContextRev = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                       biases_init = rnnbias_init, name = 'gruContextRev')\n",
    "        \n",
    "    else:\n",
    "        rnnContextRev = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init,\n",
    "                             name = 'lstmContextRev')\n",
    "    \n",
    "    rnnContextRev.initialize()\n",
    "\n",
    "else:\n",
    "    dimDec = dim\n",
    "\n",
    "\n",
    "###DECODER\n",
    "'''if rnnType == 'gru':\n",
    "    rnnDec = GatedRecurrent(dim=dimIn, weights_init = rnnwt_init, \n",
    "                            biases_init = rnnbias_init, name = 'gruDecoder')\n",
    "else:\n",
    "    rnnDec = LSTM(dim=dimIn, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstmDecoder')'''\n",
    "\n",
    "\n",
    "forkDec = Fork(output_names=['linear', 'gates'],\n",
    "            name='forkDec', input_dim=dimDec, output_dims=[dim, dim*dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "#forkFinal = Fork(output_names=['linear', 'gates'],\n",
    "#            name='forkFinal', input_dim=dim, output_dims=[dimIn, dimIn*dimMultiplier], \n",
    "#            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "#initialize the weights in all the functions\n",
    "fork.initialize()\n",
    "rnn.initialize()\n",
    "\n",
    "forkContext.initialize()\n",
    "rnnContext.initialize()\n",
    "forkDec.initialize()\n",
    "\n",
    "#forkFinal.initialize()\n",
    "#rnnDec.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This section can be skipped if you want to go directly to the classifier\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "data1, data2 = fork.apply(X) #data1 shape = (batch_size, maxPackets, dimIn)\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hEnc = rnn.apply(data1, data2)[:,-1] #the [:,-1] gets the last hidden state for each obs in minibatch\n",
    "                                         #i.e. the last state for each sentence\n",
    "else:\n",
    "    hinit, _ = rnn.apply(data2)\n",
    "    hEnc = hinit[:,-1] #hEnc shape = (batch_size*maxPackets, dim) \n",
    "\n",
    "hEnc = T.reshape(hEnc,(batch_size, maxPackets, dim))\n",
    "\n",
    "data3, data4 = forkContext.apply(hEnc)\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hContext = rnnContext.apply(data3, data4)\n",
    "else:\n",
    "    hinitContext, _ = rnnContext.apply(data4)\n",
    "    hContext = hinitContext #hContext shape = (batch_size, maxPackets, dim)\n",
    "\n",
    "#TODO:test bidirectional and make work\n",
    "\n",
    "'''if bidirectional:\n",
    "    data3 = data3[::-1]\n",
    "    data4 = data4[::-1]\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hContextRev = rnnContextRev.apply(data3, data4)\n",
    "    else:\n",
    "        hinitContext, _ = rnnContextRev.apply(data4)\n",
    "        hContextRev = hinitContext\n",
    "\n",
    "    hContext = T.concatenate((hContext, hContextRev), axis=2)\n",
    "'''\n",
    "\n",
    "data5, _ = forkDec.apply(hContext) #this fork makes data5 same dim as data1 (the orig word embedding)\n",
    "\n",
    "#decoding data needs to be one timestep (next packet in session) ahead, thus data1 we ignore the first packet\n",
    "#and the last hidden state of the context RNN.\n",
    "#THINK about L2 pooling before cat\n",
    "#THINK should we concatenate with X instead of data5\n",
    "#if packetReverse:\n",
    "#    data1 = data1[:,::-1]\n",
    "\n",
    "data7 = T.concatenate((T.reshape(data5[:,:-1],(batch_size*(maxPackets-1),1,dim)), \n",
    "                       T.reshape(T.reshape(data1,(batch_size, maxPackets, packetTimeSteps, dim))[:,1:,1:,:], \n",
    "                                 (batch_size*(maxPackets-1),packetTimeSteps - 1,dim))), axis=1) \n",
    "                      \n",
    "                      #data1 is the original embedding of X, data5 is transformed context output\n",
    "                      #get rid of first packet in data 5\n",
    "                      #get rid of last context vector\n",
    "                      \n",
    "data8, data9 = forkFinal.apply(data7) #forkFinal transforms back to original dimIn\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hDec = rnnDec.apply(data8, data9) \n",
    "else:\n",
    "    hinit, _ = rnnDec.apply(data9)\n",
    "    hDec = hinit #hDec shape = (batch_size*(maxPackets-1), packetTimeSteps, 257)\n",
    "\n",
    "softmax = NDimensionalSoftmax()\n",
    "softout = softmax.apply(hDec, extra_ndim = 1)\n",
    "predX = T.reshape(T.reshape(X,(batch_size, maxPackets, packetTimeSteps, dimIn))[:,1:,:,:], \n",
    "                  (batch_size*(maxPackets-1), packetTimeSteps, 257))\n",
    "\n",
    "precost = predX*T.log(softout) + (1-predX)*T.log(1-softout)\n",
    "precost2 = -T.sum(T.sum(precost, axis = 2), axis = 1)\n",
    "#precost2 = -T.mean(T.sum(T.sum(precost, axis = 2), axis = 1))\n",
    "\n",
    "#cost = T.mean(precost2)\n",
    "cost = T.mean(BinaryCrossEntropy().apply(predX, softout))\n",
    "cg = ComputationGraph([cost])\n",
    "learning_rate = 0.0001\n",
    "params = VariableFilter(roles = [PARAMETER])(cg.variables)\n",
    "updates = Adam(params, cost, learning_rate, c=5) #c is gradient clipping parameter\n",
    "#updates = RMSprop(cost, params, learning_rate, c=5)\n",
    "\n",
    "#gradients = T.grad(cost, params)\n",
    "#gradients = clip_norms(gradients, 1)\n",
    "#gradientFun = theano.function([X], gradients, allow_input_downcast=True)\n",
    "\n",
    "print \"compiling you beautiful person\"\n",
    "train = theano.function([X], [cost, hContext], updates = updates, allow_input_downcast=True)\n",
    "predict = theano.function([X], softout, allow_input_downcast=True)\n",
    "print \"finished compiling\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#randomize data\n",
    "hexSessionsKeys = hexSessions.keys()\n",
    "random.shuffle(hexSessionsKeys)\n",
    "trainPercent = 0.9\n",
    "trainIndex = int(len(hexSessionsKeys)*trainPercent)\n",
    "\n",
    "runname = 'hred'\n",
    "epochCost = []\n",
    "gradNorms = []\n",
    "contextCollect = []\n",
    "\n",
    "epochs = 10\n",
    "iteration = 0\n",
    "\n",
    "for epoch in xrange(epochs):\n",
    "    costCollect = []\n",
    "    \n",
    "    for start, end in zip(range(0, trainIndex,batch_size), range(batch_size, trainIndex, batch_size)):\n",
    "        \n",
    "        trainingSessions = []\n",
    "        \n",
    "        for trainKey in range(start, end):\n",
    "            sessionForEncoding = hexSessions[hexSessions.keys()[trainKey]]\n",
    "            oneHotSes = oneSessionEncoder(sessionForEncoding, packetReverse=packetReverse, \n",
    "                                          padOldTimeSteps = packetReverse,\n",
    "                                          hexDict = hexDict,\n",
    "                                          maxPackets = maxPackets, packetTimeSteps = packetTimeSteps)\n",
    "            trainingSessions.append(oneHotSes[0])\n",
    "        \n",
    "        trainingSessions = [item for sublist in trainingSessions for item in sublist]\n",
    "        sessionsMinibatch = np.asarray(trainingSessions)\n",
    "        \n",
    "    \n",
    "        costfun = train(sessionsMinibatch)\n",
    "        costCollect.append(costfun[0])\n",
    "        \n",
    "            \n",
    "        iteration+=1\n",
    "        \n",
    "        '''if iteration%20:\n",
    "            print '   iteration: ', iteration\n",
    "            print '   intermed cost: ', np.mean(costCollect)'''\n",
    "    ####SAVE COST TO FILE  \n",
    "    if epoch%2 == 0:\n",
    "        print(' ')\n",
    "        print 'Epoch: ', epoch\n",
    "        epochCost.append(np.mean(costCollect))\n",
    "        contextCollect.append(costfun[1][:4])\n",
    "        print 'Epoch cost average: ', epochCost[-1]\n",
    "        #grads = gradientFun(inputs, outputs)\n",
    "        #for gra in grads:\n",
    "        #    print '  gradient norms: ', np.linalg.norm(gra)\n",
    "        \n",
    "    np.savetxt(runname+\"_COST.csv\", epochCost, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can be used with or without unsupervised learning\n",
    "\n",
    "#X = T.matrix('classtest')\n",
    "#Y = T.matrix('targets')\n",
    "batch_sizeClass = 20\n",
    "numClasses = 2\n",
    "clippings = 1\n",
    "learning_rateClass = 0.01\n",
    "classifierWts = IsotropicGaussian(0.1, 0)\n",
    "\n",
    "bmlp = BatchNormalizedMLP(activations=[Logistic(),Logistic()], \n",
    "           dims=[dim, dim, numClasses],\n",
    "           weights_init=classifierWts,\n",
    "           biases_init=Constant(0.0001) )\n",
    "\n",
    "\n",
    "bmlp.initialize()\n",
    "\n",
    "def onestepEnc(X):\n",
    "    data1, data2 = fork.apply(X) #data1 shape = (batch_size, maxPackets, dimIn)\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hEnc = rnn.apply(data1, data2) \n",
    "    else:\n",
    "        hEnc, _ = rnn.apply(data2)\n",
    "        #hinit, _ = rnn.apply(data2)\n",
    "        #hEnc = hinit[:,-1] #hEnc shape = (batch_size, maxPackets, dim) \n",
    "\n",
    "    #hEnc2 = hEnc[-1]#T.reshape(hEnc[:,-1],(batch_sizeClass, maxPackets, dim))#the [:,-1] gets the last hidden state for \n",
    "                                                                    #each obs in minibatch\n",
    "                                                                    #i.e. the last state for each sentence\n",
    "    return hEnc\n",
    "\n",
    "hEnc, _ = theano.scan(onestepEnc, X)\n",
    "hEncReshape = T.reshape(hEnc[:,-1], (batch_sizeClass,maxPackets,1,dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testenc = theano.function([X], hContextReshape, allow_input_downcast=True)\n",
    "\n",
    "testenc(np.ones((40,2,1,257))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onestepContext(hEncReshape):\n",
    "    \n",
    "    data3, data4 = forkContext.apply(hEncReshape)\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        hContext = rnnContext.apply(data3, data4)\n",
    "    else:\n",
    "        hinitContext, _ = rnnContext.apply(data4)\n",
    "        hContext = hinitContext #hContext shape = (batch_size, maxPackets, dim)\n",
    "    \n",
    "    return hContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hContext, _ = theano.scan(onestepContext, hEncReshape)\n",
    "hContextReshape = T.reshape(hContext[:,-1], (batch_sizeClass,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad compiling\n",
      "finish with grads\n",
      "compiling functions you talented soul\n",
      "finished compiling\n"
     ]
    }
   ],
   "source": [
    "data5, _ = forkDec.apply(hContextReshape)\n",
    "\n",
    "pyx = bmlp.apply(data5)\n",
    "softmax = Softmax()\n",
    "softoutClass = softmax.apply(pyx)\n",
    "costClass = T.mean(CategoricalCrossEntropy().apply(Y, softoutClass))\n",
    "\n",
    "cgClass = ComputationGraph([costClass])\n",
    "paramsClass = VariableFilter(roles = [PARAMETER])(cgClass.variables)\n",
    "\n",
    "#updatesClass = Adam(paramsClass, costClass, learning_rateClass, c=clippings) \n",
    "updatesClass = RMSprop(costClass, paramsClass, learning_rateClass, c=clippings)\n",
    "\n",
    "print 'grad compiling'\n",
    "gradients = T.grad(costClass, paramsClass)\n",
    "gradients = clip_norms(gradients, clippings)\n",
    "gradientFun = theano.function([X,Y], gradients, allow_input_downcast=True)\n",
    "print 'finish with grads'\n",
    "\n",
    "print 'compiling functions you talented soul'\n",
    "classifierTrain = theano.function([X,Y], [costClass, hEnc, hContext,pyx, softoutClass], updates=updatesClass, allow_input_downcast=True)\n",
    "classifierPredict = theano.function([X], softoutClass, allow_input_downcast=True)\n",
    "print 'finished compiling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testfun = theano.function([X], data5, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65000000000000002"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(testfun(sessionsMinibatch), axis = 1) == targetsMinibatch[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.08552187e-05,   6.52331073e-05,  -2.25954122e-04,\n",
       "         -1.36082061e-04,  -7.98002293e-06,   8.73750178e-05,\n",
       "          2.70325472e-05,   1.24739963e-04,   3.48383648e-04,\n",
       "         -1.28321408e-04,   1.09236425e-04,  -3.02765184e-05,\n",
       "         -2.40783629e-05,  -1.76583038e-04,  -8.73717727e-06,\n",
       "         -2.33404600e-04,   2.26700911e-04,   7.02253965e-05,\n",
       "         -4.26690895e-05,   1.10909677e-04,   1.87109967e-04,\n",
       "         -8.72958917e-05,  -3.27984453e-05,  -1.36528979e-04,\n",
       "          2.00399983e-04,   1.63435412e-04,   4.90299317e-06,\n",
       "          1.39666867e-04,   2.22454291e-05,   4.94174783e-05,\n",
       "          1.50146312e-04,   2.91250144e-05,   5.92990509e-05,\n",
       "          1.95969897e-05,  -6.95251802e-05,  -3.13746968e-05,\n",
       "         -1.18822209e-04,   1.64653247e-04,   3.89593260e-05,\n",
       "          2.20949805e-05,  -8.09883350e-05,  -1.47104874e-04,\n",
       "         -2.93077930e-04,   8.31233683e-06,   2.04733806e-06,\n",
       "          2.28485587e-05,   4.18248746e-05,   3.89189154e-06,\n",
       "         -8.84771653e-05,   6.60988226e-05],\n",
       "       [ -3.30614021e-05,   7.12026740e-05,  -2.31720958e-04,\n",
       "         -1.34781803e-04,  -9.12860014e-06,   9.36506913e-05,\n",
       "          3.84596242e-05,   1.16550000e-04,   3.37550882e-04,\n",
       "         -1.19791301e-04,   1.24059909e-04,  -3.86621687e-05,\n",
       "         -2.93236662e-05,  -1.81032286e-04,  -6.01143256e-07,\n",
       "         -2.34340318e-04,   2.23176612e-04,   6.29714996e-05,\n",
       "         -4.22481935e-05,   1.07605723e-04,   1.92731532e-04,\n",
       "         -7.79658731e-05,  -3.02934350e-05,  -1.34547619e-04,\n",
       "          1.86833815e-04,   1.70119703e-04,  -2.21450136e-06,\n",
       "          1.39390177e-04,   2.76204955e-05,   5.92686010e-05,\n",
       "          1.55946240e-04,   2.68426593e-05,   6.66473352e-05,\n",
       "          1.05411455e-05,  -7.03383557e-05,  -3.16099940e-05,\n",
       "         -1.17656891e-04,   1.63138393e-04,   3.48368085e-05,\n",
       "          1.35670125e-05,  -8.78903229e-05,  -1.52505163e-04,\n",
       "         -2.85052840e-04,   4.10972643e-06,  -2.48930883e-06,\n",
       "          4.24901882e-05,   4.52637360e-05,   1.26453779e-05,\n",
       "         -8.75662736e-05,   7.07036161e-05],\n",
       "       [ -4.70767482e-05,   7.35889626e-05,  -2.08327270e-04,\n",
       "         -9.73603164e-05,  -3.85645617e-05,   1.03899452e-04,\n",
       "          3.84774357e-05,   1.02647959e-04,   3.12831195e-04,\n",
       "         -1.30094297e-04,   1.14753871e-04,  -2.95791906e-05,\n",
       "         -3.20864201e-05,  -1.67282589e-04,   3.32996933e-06,\n",
       "         -2.45396135e-04,   2.12065745e-04,   2.77087602e-05,\n",
       "         -6.56050615e-05,   8.90869123e-05,   2.05544318e-04,\n",
       "         -9.17991056e-05,  -4.33008927e-06,  -1.25241873e-04,\n",
       "          1.95261775e-04,   1.41254830e-04,   1.42545541e-05,\n",
       "          1.59434363e-04,   6.77678618e-05,   4.43979188e-05,\n",
       "          1.67098813e-04,   6.79242657e-06,   6.96092611e-05,\n",
       "          4.15776085e-05,  -7.38958624e-05,  -2.12319173e-05,\n",
       "         -1.23705540e-04,   1.86009624e-04,   2.60691831e-05,\n",
       "          9.41363396e-06,  -5.43040769e-05,  -1.61458069e-04,\n",
       "         -2.70846940e-04,   2.54949373e-05,  -2.59335757e-05,\n",
       "          3.12006159e-05,   3.87230830e-06,   1.09374087e-05,\n",
       "         -1.03097169e-04,   8.93046599e-05],\n",
       "       [ -4.66235870e-05,   6.89862500e-05,  -2.21432856e-04,\n",
       "         -1.02145059e-04,  -4.06751096e-05,   1.11136134e-04,\n",
       "          4.91464998e-05,   8.61810258e-05,   3.01920751e-04,\n",
       "         -1.24450191e-04,   1.16258758e-04,  -3.61931816e-05,\n",
       "         -3.89261768e-05,  -1.64138881e-04,   5.86429087e-06,\n",
       "         -2.38784763e-04,   2.08587357e-04,   3.93931259e-05,\n",
       "         -7.01951285e-05,   8.94041514e-05,   2.02646523e-04,\n",
       "         -8.50038123e-05,  -8.46872126e-07,  -1.21679535e-04,\n",
       "          1.87960686e-04,   1.47227285e-04,   9.02844840e-06,\n",
       "          1.62663331e-04,   7.17283037e-05,   4.26728511e-05,\n",
       "          1.60663389e-04,   1.32239547e-05,   6.06124559e-05,\n",
       "          2.53948838e-05,  -6.72778697e-05,  -3.03120651e-05,\n",
       "         -1.19247285e-04,   1.92416410e-04,   7.63090429e-06,\n",
       "          5.26044460e-07,  -4.83912409e-05,  -1.49933112e-04,\n",
       "         -2.70067219e-04,   2.89686941e-05,  -3.28569986e-05,\n",
       "          3.39366961e-05,   4.12873487e-06,   1.47991777e-05,\n",
       "         -9.81131598e-05,   8.50137003e-05],\n",
       "       [  2.43486429e-05,   8.91796735e-05,  -3.16334248e-04,\n",
       "         -9.11651514e-05,   2.37674194e-05,   1.00707526e-04,\n",
       "          1.02192476e-04,   5.84372938e-05,   2.56836152e-04,\n",
       "         -1.11981128e-04,   2.15112814e-04,  -1.69011517e-04,\n",
       "          3.66439781e-06,  -1.95240471e-04,   4.05594401e-05,\n",
       "         -3.07060167e-04,   1.61424265e-04,   8.26391479e-05,\n",
       "         -5.44002505e-05,   1.14699506e-04,   1.62748562e-04,\n",
       "         -2.20873553e-05,   1.23916188e-05,  -1.15090297e-04,\n",
       "          2.00400478e-04,   1.16051262e-04,  -5.99824925e-05,\n",
       "          1.29810287e-04,   2.27538112e-06,   7.61601259e-05,\n",
       "          1.56644237e-04,   1.55087837e-05,   1.95346111e-05,\n",
       "          7.37750306e-05,   1.69157502e-05,  -4.46987433e-05,\n",
       "         -1.96842757e-05,   2.45306699e-04,   6.80377270e-05,\n",
       "         -1.16573749e-04,  -1.04012390e-04,  -1.26060622e-04,\n",
       "         -3.00896063e-04,  -2.42187125e-05,   9.32943658e-06,\n",
       "          8.17722612e-05,   6.47727575e-07,   1.12281959e-05,\n",
       "         -1.50553940e-04,   3.18636448e-05],\n",
       "       [  2.09716600e-05,   9.15266282e-05,  -3.15747893e-04,\n",
       "         -9.43311752e-05,   1.77021411e-05,   9.91744164e-05,\n",
       "          9.81734556e-05,   7.40015239e-05,   2.56871775e-04,\n",
       "         -1.15151001e-04,   2.14537999e-04,  -1.52414810e-04,\n",
       "          8.89413059e-07,  -1.86766600e-04,   3.65265951e-05,\n",
       "         -3.05557973e-04,   1.66284561e-04,   8.65733164e-05,\n",
       "         -5.67912321e-05,   1.17187461e-04,   1.64228928e-04,\n",
       "         -3.02461558e-05,   1.48702193e-05,  -1.18112337e-04,\n",
       "          1.90047780e-04,   1.21339232e-04,  -5.64756519e-05,\n",
       "          1.33540845e-04,  -2.49459845e-07,   7.81526105e-05,\n",
       "          1.56498965e-04,   1.27289823e-05,   2.74149970e-05,\n",
       "          6.60688675e-05,   1.21017365e-05,  -4.63551150e-05,\n",
       "         -2.71392837e-05,   2.42119597e-04,   6.23580199e-05,\n",
       "         -1.11835652e-04,  -1.10135814e-04,  -1.27515887e-04,\n",
       "         -2.94265628e-04,  -1.69619707e-05,   1.05187773e-05,\n",
       "          9.17980215e-05,   2.76419451e-06,   1.52451321e-05,\n",
       "         -1.45876053e-04,   3.13585842e-05],\n",
       "       [ -3.15355610e-05,   7.75088483e-05,  -2.14866071e-04,\n",
       "         -9.25181594e-05,  -8.50009201e-06,   9.54203206e-05,\n",
       "          3.50602386e-05,   1.15346862e-04,   3.33868142e-04,\n",
       "         -1.30128552e-04,   1.24138343e-04,  -6.77352509e-05,\n",
       "         -3.09443494e-05,  -2.08151541e-04,   2.06592813e-06,\n",
       "         -2.62521295e-04,   2.22477203e-04,   3.64671087e-06,\n",
       "         -3.84089362e-05,   9.19370650e-05,   2.00070877e-04,\n",
       "         -5.91914686e-05,  -9.38293852e-06,  -1.39695097e-04,\n",
       "          1.81634357e-04,   1.46115592e-04,  -2.39577766e-05,\n",
       "          1.13935959e-04,   4.64296136e-05,   7.13054033e-05,\n",
       "          1.82050280e-04,   1.50464475e-05,   8.16899556e-05,\n",
       "          4.72714783e-05,  -7.36551156e-05,  -1.54320114e-05,\n",
       "         -1.17833522e-04,   1.85035169e-04,   6.76050840e-05,\n",
       "          2.17451743e-05,  -7.08998414e-05,  -1.63370743e-04,\n",
       "         -2.86045455e-04,  -3.66531422e-05,   3.56794772e-07,\n",
       "          4.21467921e-05,   3.27031739e-06,   2.86587820e-05,\n",
       "         -1.18765340e-04,   1.00899968e-04],\n",
       "       [ -2.33932697e-05,   7.56882437e-05,  -2.10572223e-04,\n",
       "         -1.00560232e-04,  -1.59570918e-05,   1.02939783e-04,\n",
       "          3.27427952e-05,   1.10220193e-04,   3.17638100e-04,\n",
       "         -1.32762216e-04,   1.21111749e-04,  -6.01323736e-05,\n",
       "         -3.65175074e-05,  -1.95119574e-04,  -3.55052543e-06,\n",
       "         -2.62670772e-04,   2.23438052e-04,   1.06009838e-05,\n",
       "         -3.48484900e-05,   9.43047271e-05,   2.02290161e-04,\n",
       "         -6.34372336e-05,   3.92248694e-06,  -1.36727263e-04,\n",
       "          1.75994530e-04,   1.59344578e-04,  -1.96393921e-05,\n",
       "          1.18470249e-04,   5.64860820e-05,   6.88295986e-05,\n",
       "          1.70745014e-04,   9.99728945e-06,   8.31929647e-05,\n",
       "          3.36220983e-05,  -8.45176255e-05,  -2.31522099e-05,\n",
       "         -1.19337928e-04,   1.93751664e-04,   4.44753605e-05,\n",
       "          2.37858039e-05,  -7.36271468e-05,  -1.58337149e-04,\n",
       "         -2.80377048e-04,  -3.62829705e-05,  -8.51013101e-06,\n",
       "          4.76034475e-05,   1.33559879e-05,   3.08720337e-05,\n",
       "         -1.08944165e-04,   1.00575569e-04],\n",
       "       [  1.40460252e-05,   5.95588062e-05,  -3.16649908e-04,\n",
       "         -1.95497851e-04,   2.47055086e-05,   1.22080673e-04,\n",
       "          2.83568588e-05,   4.62877179e-05,   2.75187660e-04,\n",
       "         -6.77015196e-05,   1.20411016e-04,  -1.27683015e-04,\n",
       "         -1.03843558e-04,  -1.83237687e-04,   8.64352405e-05,\n",
       "         -2.01291172e-04,   2.23464333e-04,   1.18696931e-04,\n",
       "         -1.18257914e-04,   1.16007359e-04,   1.68663566e-04,\n",
       "         -1.08278982e-05,  -3.21854022e-05,  -1.41220255e-04,\n",
       "          1.76326052e-04,   2.20227725e-04,  -6.57016499e-05,\n",
       "          1.50734297e-04,   8.61910303e-06,   3.35332261e-05,\n",
       "          2.25725409e-04,   6.05437344e-05,   4.25976141e-05,\n",
       "         -6.49206486e-05,  -8.01309579e-06,  -6.15784957e-05,\n",
       "         -4.87686448e-05,   2.15251130e-04,  -2.69353077e-05,\n",
       "         -1.59676638e-05,  -6.80848825e-05,  -1.12052454e-04,\n",
       "         -3.18155158e-04,  -2.14100619e-05,  -1.97801019e-05,\n",
       "          5.63920330e-05,   5.31019759e-05,  -4.90319726e-05,\n",
       "         -7.61030897e-05,   2.17395318e-05],\n",
       "       [  2.39523506e-05,   6.97968571e-05,  -3.15706129e-04,\n",
       "         -2.06918659e-04,   3.44336840e-05,   1.36637027e-04,\n",
       "          3.13913552e-05,   5.21810398e-05,   2.81945773e-04,\n",
       "         -6.35627366e-05,   1.03966879e-04,  -1.28940883e-04,\n",
       "         -9.09546361e-05,  -1.71603082e-04,   8.19127818e-05,\n",
       "         -2.06868281e-04,   2.25069729e-04,   9.93259164e-05,\n",
       "         -1.01893398e-04,   1.24722530e-04,   1.71910709e-04,\n",
       "         -3.06974835e-06,  -2.56736494e-05,  -1.34228409e-04,\n",
       "          1.79433089e-04,   2.11631414e-04,  -6.46866392e-05,\n",
       "          1.49318395e-04,   8.50404103e-06,   4.95773893e-05,\n",
       "          2.22152914e-04,   6.82872997e-05,   3.48628273e-05,\n",
       "         -4.91664250e-05,  -8.87950955e-06,  -6.01358879e-05,\n",
       "         -4.19395437e-05,   2.16549670e-04,  -1.91583931e-05,\n",
       "         -1.33147405e-05,  -7.07766885e-05,  -1.13108981e-04,\n",
       "         -3.12073767e-04,  -3.22853084e-05,  -7.97881512e-08,\n",
       "          4.59042349e-05,   7.43241108e-05,  -6.07964685e-05,\n",
       "         -7.03776022e-05,   1.80375282e-05],\n",
       "       [ -5.63828507e-06,   1.00369485e-04,  -2.32576305e-04,\n",
       "         -1.41218887e-04,   2.58338991e-06,   1.06488988e-04,\n",
       "          3.89406450e-05,   8.77316488e-05,   3.11609358e-04,\n",
       "         -1.18852848e-04,   1.37260329e-04,  -5.91700627e-05,\n",
       "         -2.60243032e-05,  -1.77582013e-04,  -1.45396316e-05,\n",
       "         -2.48239638e-04,   2.22995470e-04,   5.84389527e-05,\n",
       "         -6.10392890e-05,   8.66673363e-05,   1.82343501e-04,\n",
       "         -7.50767649e-05,  -2.24560936e-05,  -1.27782987e-04,\n",
       "          1.89270097e-04,   1.79796567e-04,   1.10610381e-06,\n",
       "          1.64134122e-04,   5.58627144e-05,   7.99875561e-05,\n",
       "          1.45928774e-04,   1.70406238e-05,   7.52484630e-05,\n",
       "         -2.01907897e-05,  -5.22542359e-05,  -7.73690990e-05,\n",
       "         -1.02651044e-04,   1.83851327e-04,  -6.96571806e-06,\n",
       "          2.33190585e-05,  -9.07616995e-05,  -1.54402514e-04,\n",
       "         -2.69742915e-04,   1.08646764e-05,  -2.22627023e-05,\n",
       "          5.91966382e-05,   5.74164806e-05,   3.38891696e-05,\n",
       "         -1.36814735e-04,   7.94967127e-05],\n",
       "       [ -1.54540976e-05,   8.04308293e-05,  -2.42396520e-04,\n",
       "         -1.42710167e-04,  -2.43554223e-06,   1.09592249e-04,\n",
       "          4.37598756e-05,   7.11782050e-05,   3.17139609e-04,\n",
       "         -1.22714322e-04,   1.29993859e-04,  -5.41951085e-05,\n",
       "         -2.62371032e-05,  -1.68161248e-04,  -1.62421547e-05,\n",
       "         -2.46154930e-04,   2.14872911e-04,   5.22241789e-05,\n",
       "         -7.12876936e-05,   8.05767049e-05,   1.93321364e-04,\n",
       "         -7.63767021e-05,  -2.06404657e-05,  -1.25488703e-04,\n",
       "          1.88376493e-04,   1.78339396e-04,   1.91297295e-06,\n",
       "          1.66454643e-04,   5.70236916e-05,   7.79339462e-05,\n",
       "          1.41256081e-04,   3.13007040e-05,   5.35978797e-05,\n",
       "         -2.26203920e-05,  -3.51923118e-05,  -8.18129629e-05,\n",
       "         -1.01078811e-04,   1.85003199e-04,  -9.08816583e-06,\n",
       "          2.00487120e-05,  -8.75681217e-05,  -1.46202685e-04,\n",
       "         -2.72004050e-04,   1.61351763e-05,  -1.30511071e-05,\n",
       "          4.75754568e-05,   6.16759498e-05,   3.26128793e-05,\n",
       "         -1.37906187e-04,   6.99298325e-05],\n",
       "       [ -2.78146981e-05,   1.17253163e-04,  -2.73761398e-04,\n",
       "         -1.71792635e-04,   2.94136407e-05,   8.84547553e-05,\n",
       "          6.41591032e-05,   8.79805448e-05,   2.06736324e-04,\n",
       "         -1.60747477e-05,   1.70992673e-04,  -1.32848683e-04,\n",
       "         -5.53678256e-05,  -1.72321656e-04,   4.52140303e-05,\n",
       "         -2.33362400e-04,   2.09965074e-04,   1.10599431e-04,\n",
       "         -6.26787732e-05,   1.27694177e-04,   1.86699661e-04,\n",
       "         -2.00812792e-06,  -1.09043667e-05,  -1.36995979e-04,\n",
       "          1.33628084e-04,   1.24760874e-04,  -5.11614126e-05,\n",
       "          1.34433096e-04,   5.14596468e-06,   2.13608255e-05,\n",
       "          1.50988606e-04,   7.69631079e-05,   4.80852432e-05,\n",
       "         -3.63295112e-05,   5.86621572e-05,  -5.26021286e-05,\n",
       "         -1.57732466e-05,   2.21015158e-04,   2.45072188e-05,\n",
       "         -4.09650856e-05,  -8.88670183e-05,  -6.17834885e-05,\n",
       "         -2.46599928e-04,  -5.00609349e-05,   3.70666530e-05,\n",
       "          4.96222710e-05,   1.71781212e-05,  -3.58058460e-05,\n",
       "         -1.39590193e-04,   6.01837964e-05],\n",
       "       [ -4.12035697e-05,   1.19563803e-04,  -2.57050560e-04,\n",
       "         -1.71952706e-04,   1.93080923e-05,   7.99439804e-05,\n",
       "          6.55423792e-05,   1.03800005e-04,   2.24167015e-04,\n",
       "         -2.72248180e-05,   1.68879633e-04,  -1.09874658e-04,\n",
       "         -5.93291916e-05,  -1.79994182e-04,   2.61027599e-05,\n",
       "         -2.22512812e-04,   2.18583009e-04,   1.16028255e-04,\n",
       "         -6.28108828e-05,   1.22250844e-04,   1.79623748e-04,\n",
       "         -1.91888903e-05,  -1.36512222e-06,  -1.36181421e-04,\n",
       "          1.29731605e-04,   1.32222180e-04,  -3.01050241e-05,\n",
       "          1.34841015e-04,   6.86283965e-06,   1.46778275e-05,\n",
       "          1.50655440e-04,   6.32400479e-05,   3.73416005e-05,\n",
       "         -2.94201673e-05,   4.87130455e-05,  -6.83355465e-05,\n",
       "         -4.33577661e-05,   2.12882340e-04,   1.98667422e-05,\n",
       "         -2.39235051e-05,  -9.62054983e-05,  -6.71196685e-05,\n",
       "         -2.39892106e-04,  -4.24663158e-05,   3.01764012e-05,\n",
       "          3.96818723e-05,   1.66436002e-05,  -3.79706325e-05,\n",
       "         -1.25627790e-04,   7.00130695e-05],\n",
       "       [  9.89140972e-06,   5.52825950e-05,  -3.05712165e-04,\n",
       "         -1.52001710e-04,   3.87590262e-05,   7.78588437e-05,\n",
       "          3.40453989e-05,   5.26169788e-05,   1.81231459e-04,\n",
       "         -5.41334593e-05,   1.73215754e-04,  -1.15317795e-04,\n",
       "         -2.13720195e-05,  -1.43679092e-04,   5.27344237e-05,\n",
       "         -2.62021204e-04,   1.96658191e-04,   1.30878456e-04,\n",
       "         -1.07074644e-04,   1.19275777e-04,   1.55173155e-04,\n",
       "         -4.74387489e-05,  -3.98152588e-05,  -1.24922270e-04,\n",
       "          1.79026014e-04,   1.62201832e-04,  -5.10342725e-05,\n",
       "          1.79059571e-04,   1.47546925e-05,   7.47914673e-05,\n",
       "          1.68500759e-04,   3.70822563e-05,   3.18780840e-05,\n",
       "         -8.67827112e-06,   1.83014854e-05,  -3.09756761e-05,\n",
       "          9.43802297e-06,   2.06522513e-04,   2.68304193e-05,\n",
       "         -8.51717632e-05,  -6.52100425e-05,  -5.36432926e-05,\n",
       "         -2.84525566e-04,  -5.06796241e-05,  -7.45542638e-06,\n",
       "          8.32154474e-05,   8.27351105e-05,   1.79891067e-05,\n",
       "         -2.25191616e-04,   2.96418912e-05],\n",
       "       [  8.53909296e-06,   5.30425241e-05,  -3.09403898e-04,\n",
       "         -1.50293272e-04,   3.55252232e-05,   8.05364543e-05,\n",
       "          3.52683965e-05,   5.16173932e-05,   1.96332185e-04,\n",
       "         -5.06155193e-05,   1.63419201e-04,  -1.12225782e-04,\n",
       "         -2.03212076e-05,  -1.37989118e-04,   5.87371323e-05,\n",
       "         -2.61865585e-04,   1.92597523e-04,   1.19978577e-04,\n",
       "         -1.08607441e-04,   1.17252712e-04,   1.57465533e-04,\n",
       "         -4.92298859e-05,  -3.35848454e-05,  -1.22032347e-04,\n",
       "          1.81500407e-04,   1.60392083e-04,  -4.74009139e-05,\n",
       "          1.81942101e-04,   1.34114889e-05,   7.82136703e-05,\n",
       "          1.75033347e-04,   4.46770355e-05,   2.37165987e-05,\n",
       "         -2.84933412e-06,   2.60085872e-05,  -3.01812033e-05,\n",
       "          9.22854815e-06,   2.07277437e-04,   3.06734146e-05,\n",
       "         -8.09497651e-05,  -6.84461702e-05,  -5.61757843e-05,\n",
       "         -2.78355670e-04,  -4.32592460e-05,   3.69397821e-06,\n",
       "          7.01752288e-05,   8.96095225e-05,   1.73269655e-06,\n",
       "         -2.13147359e-04,   2.57860629e-05],\n",
       "       [ -2.19264257e-05,   7.82132265e-05,  -1.98951559e-04,\n",
       "         -1.28190382e-04,  -4.27154628e-05,   8.67382405e-05,\n",
       "          4.82092109e-05,   9.98728356e-05,   2.88921467e-04,\n",
       "         -1.14256101e-04,   1.41652708e-04,  -4.73820000e-05,\n",
       "         -2.67912546e-05,  -1.71439067e-04,  -2.19949907e-05,\n",
       "         -2.43760602e-04,   2.19859299e-04,   7.56222871e-05,\n",
       "         -3.16264486e-05,   9.13324111e-05,   1.87182872e-04,\n",
       "         -9.04936605e-05,   1.05933032e-05,  -1.42966222e-04,\n",
       "          1.74357105e-04,   1.65681908e-04,   6.39482460e-06,\n",
       "          1.61981705e-04,   5.67225507e-05,   3.84725827e-05,\n",
       "          1.19788252e-04,   1.54924528e-05,   7.42881675e-05,\n",
       "          5.01919203e-06,  -8.25277821e-05,  -5.37156047e-05,\n",
       "         -1.11956324e-04,   1.95655972e-04,   4.63796459e-06,\n",
       "          7.83816358e-06,  -8.27722615e-05,  -1.33672700e-04,\n",
       "         -2.59523746e-04,  -9.47555782e-06,  -1.94381682e-05,\n",
       "          3.31757328e-05,   4.13036105e-05,   3.83435181e-05,\n",
       "         -1.12616843e-04,   5.58582433e-05],\n",
       "       [ -4.28352723e-05,   7.49897517e-05,  -1.99006041e-04,\n",
       "         -1.31691515e-04,  -4.30771652e-05,   7.83778232e-05,\n",
       "          5.23909548e-05,   1.03819475e-04,   2.70332966e-04,\n",
       "         -1.07006497e-04,   1.45938960e-04,  -3.57004974e-05,\n",
       "         -3.58794205e-05,  -1.79516734e-04,  -2.09957070e-05,\n",
       "         -2.36383334e-04,   2.24173244e-04,   9.86389423e-05,\n",
       "         -3.66757813e-05,   9.35943535e-05,   1.91268962e-04,\n",
       "         -8.93809993e-05,  -6.18010381e-06,  -1.48427600e-04,\n",
       "          1.65716760e-04,   1.69523788e-04,   1.78210685e-05,\n",
       "          1.64725832e-04,   5.79258449e-05,   1.53934088e-05,\n",
       "          1.13861861e-04,   1.69307714e-05,   8.01503047e-05,\n",
       "         -1.92236766e-05,  -5.97029975e-05,  -6.35744072e-05,\n",
       "         -1.19245946e-04,   1.97966088e-04,  -7.55353176e-06,\n",
       "          2.01210642e-05,  -8.87414935e-05,  -1.25952851e-04,\n",
       "         -2.50132987e-04,   6.33939544e-06,  -1.23031787e-05,\n",
       "          3.83593797e-05,   4.78064030e-05,   3.49583715e-05,\n",
       "         -1.14557224e-04,   5.93976620e-05],\n",
       "       [  6.83456892e-06,   8.95036283e-05,  -3.24976514e-04,\n",
       "         -1.05268016e-04,   2.00051072e-05,   1.16311086e-04,\n",
       "          5.69170697e-05,  -1.89722468e-05,   1.94804248e-04,\n",
       "         -2.25992917e-05,   1.68988583e-04,  -1.47982530e-04,\n",
       "         -5.87145332e-05,  -1.64775949e-04,   7.00221499e-05,\n",
       "         -2.21151902e-04,   2.07459001e-04,   6.89862209e-05,\n",
       "         -8.86283669e-05,   9.70419860e-05,   2.10775572e-04,\n",
       "         -2.57129213e-05,   2.94290330e-05,  -1.31216599e-04,\n",
       "          1.42719204e-04,   2.23531621e-04,  -1.08228516e-04,\n",
       "          1.55394795e-04,   4.49872823e-06,   8.93615870e-05,\n",
       "          2.36870517e-04,   7.54161738e-06,   5.90223390e-05,\n",
       "         -5.24269490e-05,  -3.72612449e-05,   1.20551740e-05,\n",
       "         -3.65678970e-05,   2.49674922e-04,  -1.39304502e-05,\n",
       "         -8.25779643e-05,  -5.35450490e-05,  -1.22090860e-04,\n",
       "         -2.81709246e-04,  -2.44778348e-05,  -2.46010495e-05,\n",
       "          1.17330448e-04,   4.51494125e-05,  -5.68116957e-06,\n",
       "         -1.32855232e-04,   5.29507852e-05],\n",
       "       [  1.00013567e-05,   9.93589711e-05,  -3.16912192e-04,\n",
       "         -1.16210445e-04,   2.79311789e-05,   1.12361915e-04,\n",
       "          6.60836522e-05,  -1.25747356e-05,   1.99532384e-04,\n",
       "         -2.22240524e-05,   1.69959647e-04,  -1.53135057e-04,\n",
       "         -6.07640322e-05,  -1.78848146e-04,   6.48157584e-05,\n",
       "         -2.15697524e-04,   2.14019208e-04,   6.34772878e-05,\n",
       "         -8.58620042e-05,   9.67078668e-05,   2.05694523e-04,\n",
       "         -1.60613417e-05,   3.68876608e-05,  -1.31152512e-04,\n",
       "          1.36374234e-04,   2.28248973e-04,  -1.02718608e-04,\n",
       "          1.50058273e-04,   7.42436896e-06,   8.94338227e-05,\n",
       "          2.42793962e-04,  -4.00893623e-06,   5.33727907e-05,\n",
       "         -4.67721329e-05,  -3.39923972e-05,  -2.69551674e-06,\n",
       "         -4.44784237e-05,   2.43622839e-04,  -1.25858787e-05,\n",
       "         -6.95894487e-05,  -6.47074121e-05,  -1.18900418e-04,\n",
       "         -2.76342558e-04,  -3.54588265e-05,  -1.81123432e-05,\n",
       "          1.13013346e-04,   5.13178165e-05,  -1.51334534e-05,\n",
       "         -1.28287822e-04,   6.05135829e-05]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfun(sessionsMinibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Epoch:  0\n",
      "Epoch cost average:  0.694072\n",
      "train accuracy:  0.5\n",
      "[[ 0.50013024  0.49986985]\n",
      " [ 0.50011772  0.49988228]\n",
      " [ 0.50013918  0.49986085]\n",
      " [ 0.50015932  0.49984074]\n",
      " [ 0.50017017  0.49982983]\n",
      " [ 0.50016433  0.49983567]\n",
      " [ 0.50013524  0.49986476]\n",
      " [ 0.50014669  0.49985328]\n",
      " [ 0.5001694   0.49983054]\n",
      " [ 0.5001514   0.49984866]\n",
      " [ 0.50023353  0.49976653]\n",
      " [ 0.50024313  0.4997569 ]\n",
      " [ 0.50015199  0.49984798]\n",
      " [ 0.5001744   0.49982566]\n",
      " [ 0.50015932  0.49984074]\n",
      " [ 0.50017303  0.49982703]\n",
      " [ 0.50014555  0.49985442]\n",
      " [ 0.5001691   0.4998309 ]\n",
      " [ 0.5001353   0.49986473]\n",
      " [ 0.50011939  0.49988055]]\n",
      "  gradient norms:  2.55651e-05\n",
      "  gradient norms:  5.50307e-05\n",
      "  gradient norms:  0.000137269\n",
      "  gradient norms:  3.41082e-06\n",
      "  gradient norms:  4.39799e-06\n",
      "  gradient norms:  5.31536e-05\n",
      "  gradient norms:  3.01433e-06\n",
      "  gradient norms:  3.3706e-05\n",
      "  gradient norms:  1.10027e-05\n",
      "  gradient norms:  3.04262e-06\n",
      "  gradient norms:  1.6702e-06\n",
      "  gradient norms:  7.85756e-07\n",
      "  gradient norms:  9.51295e-06\n",
      "  gradient norms:  3.73002e-06\n",
      "  gradient norms:  3.58572e-05\n",
      "  gradient norms:  6.68814e-05\n",
      "  gradient norms:  2.40116e-05\n",
      "  gradient norms:  1.27614e-08\n",
      "  gradient norms:  3.11661e-06\n",
      "  gradient norms:  5.85726e-06\n",
      "  gradient norms:  7.58543e-06\n",
      "  gradient norms:  4.12753e-05\n",
      " \n",
      "Epoch:  2\n",
      "Epoch cost average:  0.693118\n",
      "train accuracy:  0.5\n",
      "[[ 0.50590098  0.49409899]\n",
      " [ 0.50574023  0.49425983]\n",
      " [ 0.50557739  0.49442261]\n",
      " [ 0.50613528  0.49386469]\n",
      " [ 0.50605208  0.49394795]\n",
      " [ 0.50587672  0.49412328]\n",
      " [ 0.50579268  0.49420738]\n",
      " [ 0.50594938  0.49405062]\n",
      " [ 0.50603336  0.49396667]\n",
      " [ 0.50596344  0.49403656]\n",
      " [ 0.50588548  0.49411449]\n",
      " [ 0.50635624  0.49364379]\n",
      " [ 0.50587302  0.49412692]\n",
      " [ 0.50641304  0.49358705]\n",
      " [ 0.50599128  0.49400875]\n",
      " [ 0.50612569  0.49387434]\n",
      " [ 0.50619394  0.49380606]\n",
      " [ 0.50633448  0.49366555]\n",
      " [ 0.50610095  0.49389899]\n",
      " [ 0.50595534  0.49404472]]\n",
      "  gradient norms:  0.00113991\n",
      "  gradient norms:  0.0022851\n",
      "  gradient norms:  0.0056729\n",
      "  gradient norms:  0.000188479\n",
      "  gradient norms:  0.00018058\n",
      "  gradient norms:  0.00230178\n",
      "  gradient norms:  0.000201272\n",
      "  gradient norms:  0.00132186\n",
      "  gradient norms:  0.000377516\n",
      "  gradient norms:  0.000100856\n",
      "  gradient norms:  6.35292e-05\n",
      "  gradient norms:  3.03352e-05\n",
      "  gradient norms:  0.000219791\n",
      "  gradient norms:  0.000147055\n",
      "  gradient norms:  0.00106674\n",
      "  gradient norms:  0.00103962\n",
      "  gradient norms:  0.000243352\n",
      "  gradient norms:  3.08361e-07\n",
      "  gradient norms:  3.29402e-05\n",
      "  gradient norms:  6.81833e-05\n",
      "  gradient norms:  0.000174996\n",
      "  gradient norms:  0.000454643\n",
      " \n",
      "Epoch:  4\n",
      "Epoch cost average:  0.693192\n",
      "train accuracy:  0.5\n",
      "[[ 0.43052414  0.56947589]\n",
      " [ 0.43012884  0.56987119]\n",
      " [ 0.42949972  0.57050025]\n",
      " [ 0.43014705  0.56985295]\n",
      " [ 0.42985189  0.57014811]\n",
      " [ 0.42993286  0.57006717]\n",
      " [ 0.43007454  0.56992543]\n",
      " [ 0.43068588  0.56931406]\n",
      " [ 0.42990205  0.57009792]\n",
      " [ 0.43002966  0.56997031]\n",
      " [ 0.42956623  0.5704338 ]\n",
      " [ 0.43011147  0.56988847]\n",
      " [ 0.42952409  0.57047594]\n",
      " [ 0.42991427  0.57008576]\n",
      " [ 0.43015397  0.56984603]\n",
      " [ 0.43026477  0.56973523]\n",
      " [ 0.43019509  0.56980497]\n",
      " [ 0.4308058   0.56919414]\n",
      " [ 0.43002421  0.56997585]\n",
      " [ 0.42996651  0.57003349]]\n",
      "  gradient norms:  0.00264853\n",
      "  gradient norms:  0.0060208\n",
      "  gradient norms:  0.0115904\n",
      "  gradient norms:  0.000329426\n",
      "  gradient norms:  0.000545395\n",
      "  gradient norms:  0.00418384\n",
      "  gradient norms:  0.00041559\n",
      "  gradient norms:  0.00292255\n",
      "  gradient norms:  0.000875618\n",
      "  gradient norms:  0.000266994\n",
      "  gradient norms:  0.000151121\n",
      "  gradient norms:  8.11634e-05\n",
      "  gradient norms:  0.000604001\n",
      "  gradient norms:  0.000298425\n",
      "  gradient norms:  0.00211041\n",
      "  gradient norms:  0.00618041\n",
      "  gradient norms:  0.00297888\n",
      "  gradient norms:  0.000606782\n",
      "  gradient norms:  0.000516568\n",
      "  gradient norms:  0.000261209\n",
      "  gradient norms:  0.000852577\n",
      "  gradient norms:  0.00101943\n",
      " \n",
      "Epoch:  6\n",
      "Epoch cost average:  0.693021\n",
      "train accuracy:  0.5\n",
      "[[ 0.49246913  0.50753087]\n",
      " [ 0.49292693  0.50707304]\n",
      " [ 0.47407001  0.52592999]\n",
      " [ 0.49838969  0.50161034]\n",
      " [ 0.49442425  0.50557572]\n",
      " [ 0.49589157  0.50410849]\n",
      " [ 0.48878631  0.51121372]\n",
      " [ 0.49275526  0.50724471]\n",
      " [ 0.49434435  0.50565565]\n",
      " [ 0.49704319  0.50295681]\n",
      " [ 0.47358862  0.52641141]\n",
      " [ 0.49556643  0.50443363]\n",
      " [ 0.47549149  0.52450848]\n",
      " [ 0.49661103  0.503389  ]\n",
      " [ 0.48816472  0.51183522]\n",
      " [ 0.49064606  0.50935394]\n",
      " [ 0.48957425  0.51042581]\n",
      " [ 0.49449703  0.505503  ]\n",
      " [ 0.49771327  0.50228673]\n",
      " [ 0.49684969  0.50315034]]\n",
      "  gradient norms:  0.00408078\n",
      "  gradient norms:  0.00908676\n",
      "  gradient norms:  0.0180885\n",
      "  gradient norms:  0.000862838\n",
      "  gradient norms:  0.000782454\n",
      "  gradient norms:  0.0131724\n",
      "  gradient norms:  0.00113894\n",
      "  gradient norms:  0.00925938\n",
      "  gradient norms:  0.00678024\n",
      "  gradient norms:  0.00141117\n",
      "  gradient norms:  0.000967624\n",
      "  gradient norms:  0.000349385\n",
      "  gradient norms:  0.00264361\n",
      "  gradient norms:  0.00230364\n",
      "  gradient norms:  0.0147953\n",
      "  gradient norms:  0.104535\n",
      "  gradient norms:  0.0397866\n",
      "  gradient norms:  0.00761176\n",
      "  gradient norms:  0.00657314\n",
      "  gradient norms:  0.00316767\n",
      "  gradient norms:  0.017094\n",
      "  gradient norms:  0.0119517\n",
      " \n",
      "Epoch:  8\n",
      "Epoch cost average:  0.692892\n",
      "train accuracy:  0.5\n",
      "[[ 0.50751793  0.49248204]\n",
      " [ 0.50754642  0.49245358]\n",
      " [ 0.50937074  0.4906292 ]\n",
      " [ 0.50862747  0.49137247]\n",
      " [ 0.50885999  0.49113995]\n",
      " [ 0.50818819  0.49181172]\n",
      " [ 0.50824273  0.49175724]\n",
      " [ 0.50784111  0.49215892]\n",
      " [ 0.50897986  0.49102011]\n",
      " [ 0.50859469  0.49140537]\n",
      " [ 0.51045716  0.48954284]\n",
      " [ 0.50955033  0.49044967]\n",
      " [ 0.50924724  0.4907527 ]\n",
      " [ 0.50841415  0.49158585]\n",
      " [ 0.50742292  0.49257714]\n",
      " [ 0.50716943  0.49283051]\n",
      " [ 0.5076744   0.49232563]\n",
      " [ 0.50733894  0.49266112]\n",
      " [ 0.508044    0.491956  ]\n",
      " [ 0.50785154  0.49214849]]\n",
      "  gradient norms:  0.0023926\n",
      "  gradient norms:  0.00425938\n",
      "  gradient norms:  0.00799673\n",
      "  gradient norms:  0.000304509\n",
      "  gradient norms:  0.000433067\n",
      "  gradient norms:  0.00321801\n",
      "  gradient norms:  0.000463577\n",
      "  gradient norms:  0.00311035\n",
      "  gradient norms:  0.00144625\n",
      "  gradient norms:  0.000459537\n",
      "  gradient norms:  0.000430746\n",
      "  gradient norms:  0.000149154\n",
      "  gradient norms:  0.00131495\n",
      "  gradient norms:  0.000521954\n",
      "  gradient norms:  0.00461026\n",
      "  gradient norms:  0.00478849\n",
      "  gradient norms:  0.00283561\n",
      "  gradient norms:  0.000126277\n",
      "  gradient norms:  0.000342562\n",
      "  gradient norms:  0.000185055\n",
      "  gradient norms:  0.000795391\n",
      "  gradient norms:  0.00059669\n",
      " \n",
      "Epoch:  10\n",
      "Epoch cost average:  0.688462\n",
      "train accuracy:  0.65\n",
      "[[ 0.49864087  0.50135911]\n",
      " [ 0.49854925  0.50145066]\n",
      " [ 0.49910378  0.50089616]\n",
      " [ 0.50083244  0.49916753]\n",
      " [ 0.50067443  0.49932551]\n",
      " [ 0.50059974  0.49940032]\n",
      " [ 0.49863914  0.50136083]\n",
      " [ 0.4987672   0.5012328 ]\n",
      " [ 0.50070131  0.49929869]\n",
      " [ 0.50066036  0.49933967]\n",
      " [ 0.49886122  0.50113869]\n",
      " [ 0.50000995  0.49999011]\n",
      " [ 0.49902755  0.50097245]\n",
      " [ 0.50083619  0.49916378]\n",
      " [ 0.49861968  0.50138032]\n",
      " [ 0.49882647  0.5011735 ]\n",
      " [ 0.49852407  0.50147593]\n",
      " [ 0.49863833  0.50136173]\n",
      " [ 0.50048953  0.49951053]\n",
      " [ 0.50026494  0.499735  ]]\n",
      "  gradient norms:  0.000257008\n",
      "  gradient norms:  0.000204743\n",
      "  gradient norms:  0.00139148\n",
      "  gradient norms:  5.03764e-05\n",
      "  gradient norms:  0.000148072\n",
      "  gradient norms:  0.00103613\n",
      "  gradient norms:  5.25715e-05\n",
      "  gradient norms:  0.000732222\n",
      "  gradient norms:  0.000340973\n",
      "  gradient norms:  0.000128226\n",
      "  gradient norms:  5.76859e-05\n",
      "  gradient norms:  3.51021e-05\n",
      "  gradient norms:  0.000295963\n",
      "  gradient norms:  8.86959e-05\n",
      "  gradient norms:  0.000905117\n",
      "  gradient norms:  0.00106311\n",
      "  gradient norms:  0.00103678\n",
      "  gradient norms:  0.000112031\n",
      "  gradient norms:  0.000155566\n",
      "  gradient norms:  0.000130835\n",
      "  gradient norms:  0.000291873\n",
      "  gradient norms:  0.000340313\n",
      " \n",
      "Epoch:  12\n",
      "Epoch cost average:  0.592083\n",
      "train accuracy:  0.7\n",
      "[[ 0.26939127  0.73060876]\n",
      " [ 0.26939285  0.73060709]\n",
      " [ 0.26940539  0.73059458]\n",
      " [ 0.7195214   0.28047863]\n",
      " [ 0.26939607  0.73060399]\n",
      " [ 0.26940182  0.73059821]\n",
      " [ 0.26938888  0.73061115]\n",
      " [ 0.2693904   0.7306096 ]\n",
      " [ 0.26939726  0.73060274]\n",
      " [ 0.71193528  0.28806472]\n",
      " [ 0.26939452  0.73060554]\n",
      " [ 0.71816093  0.28183907]\n",
      " [ 0.26939541  0.73060465]\n",
      " [ 0.71774417  0.28225577]\n",
      " [ 0.26938888  0.73061115]\n",
      " [ 0.26939198  0.73060799]\n",
      " [ 0.26938871  0.73061132]\n",
      " [ 0.26939821  0.73060179]\n",
      " [ 0.26939341  0.73060662]\n",
      " [ 0.2693935   0.7306065 ]]\n",
      "  gradient norms:  0.00240996\n",
      "  gradient norms:  0.0108741\n",
      "  gradient norms:  0.00926459\n",
      "  gradient norms:  9.86153e-05\n",
      "  gradient norms:  0.000200504\n",
      "  gradient norms:  0.00179902\n",
      "  gradient norms:  0.000160518\n",
      "  gradient norms:  0.000965205\n",
      "  gradient norms:  0.000446956\n",
      "  gradient norms:  0.000136238\n",
      "  gradient norms:  0.000163461\n",
      "  gradient norms:  5.75226e-05\n",
      "  gradient norms:  0.000340599\n",
      "  gradient norms:  0.000222071\n",
      "  gradient norms:  0.00130735\n",
      "  gradient norms:  0.00595507\n",
      "  gradient norms:  0.000818355\n",
      "  gradient norms:  0.000441136\n",
      "  gradient norms:  0.000154125\n",
      "  gradient norms:  0.00016739\n",
      "  gradient norms:  0.00139393\n",
      "  gradient norms:  0.00253085\n",
      " \n",
      "Epoch:  14\n",
      "Epoch cost average:  0.467677\n",
      "train accuracy:  0.7\n",
      "[[ 0.26899004  0.73100996]\n",
      " [ 0.26899031  0.73100966]\n",
      " [ 0.26899007  0.73100996]\n",
      " [ 0.26899108  0.73100889]\n",
      " [ 0.26899028  0.73100972]\n",
      " [ 0.67222226  0.32777768]\n",
      " [ 0.26899004  0.73101002]\n",
      " [ 0.26899007  0.73100996]\n",
      " [ 0.26899025  0.73100972]\n",
      " [ 0.73033643  0.26966354]\n",
      " [ 0.26899004  0.73100996]\n",
      " [ 0.730699    0.26930103]\n",
      " [ 0.26899004  0.73100996]\n",
      " [ 0.72461635  0.27538365]\n",
      " [ 0.26899004  0.73100996]\n",
      " [ 0.26901975  0.73098028]\n",
      " [ 0.26899004  0.73101002]\n",
      " [ 0.26899064  0.73100936]\n",
      " [ 0.6175192   0.3824808 ]\n",
      " [ 0.6481961   0.35180387]]\n",
      "  gradient norms:  0.000108246\n",
      "  gradient norms:  0.00036506\n",
      "  gradient norms:  0.000390752\n",
      "  gradient norms:  1.07716e-05\n",
      "  gradient norms:  1.78928e-05\n",
      "  gradient norms:  0.000141877\n",
      "  gradient norms:  2.96871e-05\n",
      "  gradient norms:  0.000106944\n",
      "  gradient norms:  8.26819e-05\n",
      "  gradient norms:  1.86917e-05\n",
      "  gradient norms:  5.12269e-05\n",
      "  gradient norms:  1.37536e-05\n",
      "  gradient norms:  6.90836e-05\n",
      "  gradient norms:  8.34691e-05\n",
      "  gradient norms:  0.000418423\n",
      "  gradient norms:  0.0052944\n",
      "  gradient norms:  0.000843854\n",
      "  gradient norms:  0.000778194\n",
      "  gradient norms:  0.000141101\n",
      "  gradient norms:  0.00023179\n",
      "  gradient norms:  0.00245216\n",
      "  gradient norms:  0.00371643\n",
      " \n",
      "Epoch:  16\n",
      "Epoch cost average:  0.496097\n",
      "train accuracy:  0.95\n",
      "[[ 0.26897112  0.73102885]\n",
      " [ 0.73095644  0.26904353]\n",
      " [ 0.26897109  0.73102891]\n",
      " [ 0.73095644  0.26904353]\n",
      " [ 0.26897156  0.73102844]\n",
      " [ 0.73095649  0.26904351]\n",
      " [ 0.2689712   0.7310288 ]\n",
      " [ 0.73095649  0.26904351]\n",
      " [ 0.26897153  0.7310285 ]\n",
      " [ 0.73095489  0.26904511]\n",
      " [ 0.26897106  0.73102891]\n",
      " [ 0.73095638  0.26904362]\n",
      " [ 0.26897106  0.73102891]\n",
      " [ 0.73095644  0.26904353]\n",
      " [ 0.26897115  0.73102885]\n",
      " [ 0.73095649  0.26904353]\n",
      " [ 0.26897115  0.73102885]\n",
      " [ 0.73095649  0.26904351]\n",
      " [ 0.73095542  0.26904461]\n",
      " [ 0.73095626  0.26904374]]\n",
      "  gradient norms:  2.88981e-05\n",
      "  gradient norms:  0.000671267\n",
      "  gradient norms:  0.000231401\n",
      "  gradient norms:  2.888e-07\n",
      "  gradient norms:  4.98056e-07\n",
      "  gradient norms:  1.18917e-05\n",
      "  gradient norms:  3.24182e-07\n",
      "  gradient norms:  3.5846e-06\n",
      "  gradient norms:  4.95881e-07\n",
      "  gradient norms:  1.93355e-07\n",
      "  gradient norms:  1.08289e-07\n",
      "  gradient norms:  7.84029e-08\n",
      "  gradient norms:  4.17223e-07\n",
      "  gradient norms:  1.27001e-07\n",
      "  gradient norms:  6.67308e-07\n",
      "  gradient norms:  9.78286e-06\n",
      "  gradient norms:  1.43293e-06\n",
      "  gradient norms:  1.27974e-06\n",
      "  gradient norms:  3.83831e-07\n",
      "  gradient norms:  2.36194e-07\n",
      "  gradient norms:  1.20891e-06\n",
      "  gradient norms:  2.17598e-06\n",
      " \n",
      "Epoch:  18\n",
      "Epoch cost average:  0.464989\n",
      "train accuracy:  0.95\n",
      "[[ 0.2689676   0.73103237]\n",
      " [ 0.73101985  0.26898015]\n",
      " [ 0.26896766  0.73103237]\n",
      " [ 0.73101991  0.26898009]\n",
      " [ 0.268971    0.73102903]\n",
      " [ 0.73101985  0.26898015]\n",
      " [ 0.2689676   0.73103237]\n",
      " [ 0.73101985  0.26898015]\n",
      " [ 0.26897478  0.73102522]\n",
      " [ 0.73101985  0.26898009]\n",
      " [ 0.26896781  0.73103225]\n",
      " [ 0.73101985  0.26898012]\n",
      " [ 0.2689679   0.73103207]\n",
      " [ 0.73086798  0.26913205]\n",
      " [ 0.2689676   0.73103237]\n",
      " [ 0.73101985  0.26898018]\n",
      " [ 0.2689676   0.73103237]\n",
      " [ 0.73101985  0.26898009]\n",
      " [ 0.73101956  0.26898041]\n",
      " [ 0.73101968  0.26898035]]\n",
      "  gradient norms:  5.65801e-06\n",
      "  gradient norms:  0.000341741\n",
      "  gradient norms:  0.00011174\n",
      "  gradient norms:  1.34851e-06\n",
      "  gradient norms:  2.65079e-06\n",
      "  gradient norms:  2.34238e-05\n",
      "  gradient norms:  3.36281e-06\n",
      "  gradient norms:  1.70908e-05\n",
      "  gradient norms:  1.44795e-05\n",
      "  gradient norms:  8.64496e-06\n",
      "  gradient norms:  3.25924e-06\n",
      "  gradient norms:  1.7648e-06\n",
      "  gradient norms:  7.65337e-06\n",
      "  gradient norms:  5.4306e-06\n",
      "  gradient norms:  2.37151e-05\n",
      "  gradient norms:  0.000411107\n",
      "  gradient norms:  0.000181257\n",
      "  gradient norms:  6.37638e-05\n",
      "  gradient norms:  3.64725e-05\n",
      "  gradient norms:  3.51543e-05\n",
      "  gradient norms:  0.000184587\n",
      "  gradient norms:  0.000207471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-760f5986be8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mtargetsMinibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingTargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mcostfun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifierTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msessionsMinibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetsMinibatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mcostCollect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcostfun\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/bradh/.theano/compiledir_Linux-4.2--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/scan_perform/mod.cpp:4193)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#randomize data, if not already done in unsupervised portion\n",
    "hexSessionsKeys = hexSessions.keys()\n",
    "#random.shuffle(hexSessionsKeys)\n",
    "trainPercent = 0.9\n",
    "trainIndex = int(len(hexSessionsKeys)*trainPercent)\n",
    "packetReverse = False\n",
    "padOldTimeSteps = True\n",
    "\n",
    "runname = 'hredClassify'\n",
    "epochCost = []\n",
    "gradNorms = []\n",
    "\n",
    "epochs = 1000\n",
    "iteration = 0\n",
    "\n",
    "normalTarget = np.array([0,1], dtype=theano.config.floatX)\n",
    "abbyTarget = np.array([1,0], dtype=theano.config.floatX)\n",
    "\n",
    "for epoch in xrange(epochs):\n",
    "    costCollect = []\n",
    "\n",
    "    for start, end in zip(range(0, trainIndex,batch_sizeClass/2),\n",
    "                          range(batch_sizeClass/2, trainIndex, batch_sizeClass/2)):\n",
    "\n",
    "        #build a 4d array of oneHot sessions\n",
    "        \n",
    "        trainingTargets = []\n",
    "        trainingSessions = []\n",
    "        for trainKey in range(start, end):\n",
    "            sessionForEncoding = list(hexSessions[hexSessions.keys()[trainKey]])\n",
    "            \n",
    "            #encode a normal session\n",
    "            oneHotSes = oneSessionEncoder(sessionForEncoding,hexDict = hexDict, packetReverse=packetReverse, \n",
    "                                          padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets,\n",
    "                                          packetTimeSteps = packetTimeSteps)\n",
    "            trainingSessions.append(oneHotSes[0])\n",
    "            trainingTargets.append(normalTarget)\n",
    "            \n",
    "            #encode an abby normal session\n",
    "            abbyHexSession = dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs)\n",
    "            #abbyHexSession = portDirSwitcher(sessionForEncoding)\n",
    "            abbyOneHotSes = oneSessionEncoder(abbyHexSession,hexDict = hexDict,packetReverse=packetReverse, \n",
    "                                              padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets, \n",
    "                                              packetTimeSteps = packetTimeSteps)\n",
    "            trainingSessions.append(abbyOneHotSes[0])\n",
    "            trainingTargets.append(abbyTarget)\n",
    "            \n",
    "        #trainingSessions2 = [item for sublist in trainingSessions for item in sublist] #FIX\n",
    "        sessionsMinibatch = np.asarray(trainingSessions).reshape((batch_sizeClass*maxPackets, packetTimeSteps, 1, 257))\n",
    "        targetsMinibatch = np.asarray(trainingTargets)\n",
    "    \n",
    "        costfun = classifierTrain(sessionsMinibatch, targetsMinibatch)\n",
    "        costCollect.append(costfun[0])\n",
    "                \n",
    "        iteration+=1\n",
    "        \n",
    "    ####SAVE COST TO FILE  \n",
    "    if epoch%2 == 0:\n",
    "        print(' ')\n",
    "        print 'Epoch: ', epoch\n",
    "        epochCost.append(np.mean(costCollect))\n",
    "        print 'Epoch cost average: ', epochCost[-1]\n",
    "        grads = gradientFun(sessionsMinibatch, targetsMinibatch)\n",
    "        print 'train accuracy: ', np.mean(np.argmax(costfun[-1],axis=1) == targetsMinibatch[:,1])\n",
    "        print costfun[-1]\n",
    "        for gra in grads:\n",
    "            print '  gradient norms: ', np.linalg.norm(gra)\n",
    "        \n",
    "    np.savetxt(runname+\"_COST.csv\", epochCost, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[costClass,hEnc, hContext,pyx]\n",
    "costfun[1][0][0] == costfun[1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.51\n"
     ]
    }
   ],
   "source": [
    "#testing for generalization\n",
    "\n",
    "testCollect = []\n",
    "for start, end in zip(range(trainIndex, len(hexSessionsKeys), batch_sizeClass/2),\n",
    "                      range(trainIndex + batch_sizeClass/2, len(hexSessionsKeys), batch_sizeClass/2)):\n",
    "    trainingTargets = []\n",
    "    trainingSessions = []\n",
    "    for trainKey in range(start, end):\n",
    "        sessionForEncoding = hexSessions[hexSessions.keys()[trainKey]]\n",
    "\n",
    "        #encode a normal session\n",
    "        oneHotSes = oneSessionEncoder(sessionForEncoding,hexDict = hexDict, packetReverse=packetReverse, \n",
    "                                      padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets,\n",
    "                                      packetTimeSteps = packetTimeSteps)\n",
    "        trainingSessions.append(oneHotSes[0])\n",
    "        trainingTargets.append(normalTarget)\n",
    "\n",
    "        #encode an abby normal session\n",
    "        abbyHexSession = portDirSwitcher(sessionForEncoding)\n",
    "        abbyOneHotSes = oneSessionEncoder(abbyHexSession,hexDict = hexDict,packetReverse=packetReverse, \n",
    "                                          padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets, \n",
    "                                          packetTimeSteps = packetTimeSteps)\n",
    "        trainingSessions.append(abbyOneHotSes[0])\n",
    "        trainingTargets.append(abbyTarget)\n",
    "\n",
    "    #trainingSessions = [item for sublist in trainingSessions for item in sublist] #FIX in oneSessionEncoder\n",
    "    sessionsMinibatch = np.asarray(trainingSessions, dtype=theano.config.floatX).reshape((batch_sizeClass*maxPackets, packetTimeSteps, 1, 257))\n",
    "    targetsMinibatch = np.asarray(trainingTargets, dtype=theano.config.floatX)\n",
    "\n",
    "    costfun = classifierPredict(sessionsMinibatch)\n",
    "    testCollect.append(np.mean(np.argmax(costfun, axis=1) == targetsMinibatch[:,1]))\n",
    "\n",
    "print 'test accuracy: ', np.mean(testCollect)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26896736,  0.73103261],\n",
       "       [ 0.26896733,  0.73103267],\n",
       "       [ 0.2689673 ,  0.73103267],\n",
       "       [ 0.26896733,  0.73103267],\n",
       "       [ 0.73093122,  0.26906878],\n",
       "       [ 0.73093146,  0.26906857],\n",
       "       [ 0.7309261 ,  0.26907387],\n",
       "       [ 0.73087281,  0.26912722],\n",
       "       [ 0.26896733,  0.73103261],\n",
       "       [ 0.26896733,  0.73103267],\n",
       "       [ 0.73093158,  0.26906839],\n",
       "       [ 0.73093122,  0.26906881],\n",
       "       [ 0.26896733,  0.73103261],\n",
       "       [ 0.26896733,  0.73103267],\n",
       "       [ 0.2689673 ,  0.73103267],\n",
       "       [ 0.2689673 ,  0.73103267],\n",
       "       [ 0.73093152,  0.26906848],\n",
       "       [ 0.73092753,  0.2690725 ],\n",
       "       [ 0.26896742,  0.73103261],\n",
       "       [ 0.2689673 ,  0.73103267]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierPredict(sessionsMinibatch[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2689673 ,  0.73103267],\n",
       "       [ 0.26896742,  0.73103261],\n",
       "       [ 0.73092759,  0.26907244],\n",
       "       [ 0.73093152,  0.26906848],\n",
       "       [ 0.2689673 ,  0.73103267],\n",
       "       [ 0.2689673 ,  0.73103267],\n",
       "       [ 0.26896733,  0.73103267],\n",
       "       [ 0.26896733,  0.73103261],\n",
       "       [ 0.73093122,  0.26906881],\n",
       "       [ 0.73093158,  0.26906839],\n",
       "       [ 0.26896733,  0.73103267],\n",
       "       [ 0.26896733,  0.73103261],\n",
       "       [ 0.73087281,  0.26912722],\n",
       "       [ 0.7309261 ,  0.26907387],\n",
       "       [ 0.73093146,  0.26906857],\n",
       "       [ 0.73093122,  0.26906878],\n",
       "       [ 0.26896733,  0.73103267],\n",
       "       [ 0.2689673 ,  0.73103267],\n",
       "       [ 0.2689673 ,  0.73103267],\n",
       "       [ 0.26896736,  0.73103261]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierPredict(sessionsMinibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-9f98aad6b85b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#trainingSessions2 = [item for sublist in trainingSessions for item in sublist] #FIX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0msessionsMinibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSessions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_sizeClass\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmaxPackets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacketTimeSteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m257\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mtargetsMinibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingTargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "#padOldTimeSteps = True\n",
    "\n",
    "for trainKey in range(0, 20):\n",
    "    sessionForEncoding = hexSessions[hexSessions.keys()[trainKey]]\n",
    "    #encode a normal session\n",
    "    oneHotSes = oneSessionEncoder(portDirSwitcher(sessionForEncoding),hexDict = hexDict, packetReverse=packetReverse, \n",
    "                                  padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets,\n",
    "                                  packetTimeSteps = packetTimeSteps)\n",
    "    trainingSessions.append(oneHotSes[0])\n",
    "    trainingTargets.append(normalTarget)\n",
    "    \n",
    "    #encode an abby normal session\n",
    "    abbyHexSession = dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs)\n",
    "    #abbyHexSession = portDirSwitcher(sessionForEncoding)\n",
    "    abbyOneHotSes = oneSessionEncoder(abbyHexSession,hexDict = hexDict, packetReverse=packetReverse, \n",
    "                                      padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets, \n",
    "                                      packetTimeSteps = packetTimeSteps)\n",
    "    trainingSessions.append(abbyOneHotSes[0])\n",
    "    trainingTargets.append(abbyTarget)\n",
    "    \n",
    "#trainingSessions2 = [item for sublist in trainingSessions for item in sublist] #FIX\n",
    "sessionsMinibatch = np.asarray(trainingSessions).reshape((batch_sizeClass*maxPackets, packetTimeSteps, 1, 257))\n",
    "targetsMinibatch = np.asarray(trainingTargets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Can be used with or without unsupervised learning\n",
    "\n",
    "#X = T.matrix('classtest')\n",
    "#Y = T.matrix('targets')\n",
    "batch_sizeClass = 20\n",
    "numClasses = 2\n",
    "clippings = 5\n",
    "learning_rateClass = 0.0001\n",
    "classifierWts = IsotropicGaussian(0.03, 0)\n",
    "\n",
    "bmlp = BatchNormalizedMLP(activations=[Logistic(),Logistic()], \n",
    "           dims=[dim, dim, numClasses],\n",
    "           weights_init=classifierWts,\n",
    "           biases_init=Constant(0.0001) )\n",
    "\n",
    "\n",
    "bmlp.initialize()\n",
    "\n",
    "data1, data2 = fork.apply(X) #data1 shape = (batch_size, maxPackets, dimIn)\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hEnc = rnn.apply(data1, data2) \n",
    "else:\n",
    "    hEnc, _ = rnn.apply(data2, iterate = False)\n",
    "    #hinit, _ = rnn.apply(data2)\n",
    "    #hEnc = hinit[:,-1] #hEnc shape = (batch_size, maxPackets, dim) \n",
    "\n",
    "hEnc2 = T.reshape(hEnc[-1],(batch_sizeClass, maxPackets, dim))#the [:,-1] gets the last hidden state for \n",
    "                                                                #each obs in minibatch\n",
    "                                                                #i.e. the last state for each sentence\n",
    "\n",
    "data3, data4 = forkContext.apply(hEnc2)\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hContext = rnnContext.apply(data3, data4)\n",
    "else:\n",
    "    hinitContext, _ = rnnContext.apply(data4)\n",
    "    hContext = hinitContext #hContext shape = (batch_size, maxPackets, dim)\n",
    "\n",
    "data5, _ = forkDec.apply(hContext) \n",
    "\n",
    "#FIX bidirectional\n",
    "'''if bidirectional:\n",
    "\n",
    "    data3classRev = data3class[::-1]\n",
    "    data4classRev = data4class[::-1]\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hContextRev = rnnContextRev.apply(data3classRev, data4classRev)\n",
    "    else:\n",
    "        hinitContextRevClass, _ = rnnContextRev.apply(data4classRev)\n",
    "        hContextRevClass = hinitContextRevClass\n",
    "\n",
    "    hContextClass = T.concatenate((hContextClass, hContextRevClass), axis=2)'''\n",
    "        \n",
    "\n",
    "pyx = bmlp.apply(hContext[:,-1])\n",
    "#softmax = Softmax()\n",
    "#softoutClass = softmax.apply(pyx)\n",
    "costClass = T.mean(CategoricalCrossEntropy().apply(Y, pyx))\n",
    "\n",
    "cgClass = ComputationGraph([costClass])\n",
    "paramsClass = VariableFilter(roles = [PARAMETER])(cgClass.variables)\n",
    "\n",
    "updatesClass = Adam(paramsClass, costClass, learning_rateClass, c=clippings) \n",
    "#updatesClass = RMSprop(costClass, paramsClass, learning_rateClass, c=clippings)\n",
    "\n",
    "#print 'grad compiling'\n",
    "#gradients = T.grad(costClass, paramsClass)\n",
    "#gradients = clip_norms(gradients, clippings)\n",
    "#gradientFun = theano.function([X,Y], gradients, allow_input_downcast=True)\n",
    "#print 'finish with grads'\n",
    "\n",
    "print 'compiling functions you talented soul'\n",
    "#classifierTrain = theano.function([X,Y], [costClass,hEnc, hEnc2, hContext,pyx], updates=updatesClass, allow_input_downcast=True)\n",
    "#classifierPredict = theano.function([X], pyx, allow_input_downcast=True)\n",
    "print 'finished compiling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
