{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how data are represented at each level (forward, backward, forward with padding on top) needs a little\n",
    "    #experimentation to determine the best representation\n",
    "    #also, is encoding at each layer really the best way? or just feeding the raw through?\n",
    "    \n",
    "#Outside web ips are going to be a problem/messy/noisy. Start by categorizing all outside ips by <OUTSIDE_IP>\n",
    "    #instead of the ip address, or another 4 digit symbol to insert into the hex string.\n",
    "    \n",
    "#to help the models generalize more, for a given source ip address with probability p (say p = 0.1) \n",
    "    #use the token <OTHER_MACHINE>\n",
    "    \n",
    "#should we remove random parts of the header, i.e. checksum\n",
    "\n",
    "#should I take out bias for RNNs?\n",
    "\n",
    "#for the decoder,does the fork encoding need to happen ?\n",
    "    #do we simply cat the hContext with the next words?\n",
    "    \n",
    "#Should the architecture just be encode, context and then prediction???\n",
    "\n",
    "#Input data, should it have character and hex pair encoding as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=gpu'\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import subprocess\n",
    "import cPickle\n",
    "import sys\n",
    "import binascii\n",
    "import multiprocessing as mp\n",
    "from itertools import chain\n",
    "#from scapy.all import *\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "#from scipy.stats import itemfreq\n",
    "#import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "\n",
    "import blocks\n",
    "from blocks.bricks import Linear, Softmax, Softplus, NDimensionalSoftmax, BatchNormalizedMLP, \\\n",
    "                                Rectifier, Logistic, Tanh, MLP\n",
    "from blocks.bricks.recurrent import GatedRecurrent, Fork, LSTM\n",
    "from blocks.initialization import Constant, IsotropicGaussian, Identity, Uniform\n",
    "from blocks.bricks.cost import BinaryCrossEntropy, CategoricalCrossEntropy\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.roles import PARAMETER\n",
    "from blocks.graph import ComputationGraph\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "###These warnings do not impede progress\n",
    "#WARNING: Failed to execute tcpdump. Check it is installed and in the PATH\n",
    "#WARNING: No route found for IPv6 destination :: (no default route?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxPackets = 4\n",
    "packetTimeSteps = 80\n",
    "dataPath = '/data/fs4/datasets/pcaps/bigFlows.pcap'\n",
    "\n",
    "packetReverse = False\n",
    "padOldTimeSteps = True\n",
    "\n",
    "runname = 'hredClassify8FullPacketsSTD0_2'\n",
    "rnnType = 'gru' #gru or lstm\n",
    "\n",
    "wtstd = 0.2\n",
    "dimIn = 257 #hex has 256 characters + the <EOP> character\n",
    "dim = 100 #dimension reduction size\n",
    "batch_sizeClass = 20\n",
    "numClasses = 4\n",
    "clippings = 1\n",
    "\n",
    "epochs = 200\n",
    "learning_rateClass = theano.shared(np.array(0.0001, dtype=theano.config.floatX))\n",
    "learning_decay = np.array(0.9, dtype=theano.config.floatX)\n",
    "trainPercent = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def parse_header(line):\n",
    "    ret_dict = {}\n",
    "    h = line.split()\n",
    "    #ret_dict['direction'] = \" \".join(h[3:6])\n",
    "    if h[2] == 'IP6':\n",
    "        \"\"\"\n",
    "        Conditional formatting based on ethernet type.\n",
    "        IPv4 format: 0.0.0.0.port\n",
    "        IPv6 format (one of many): 0:0:0:0:0:0.port\n",
    "        \"\"\"\n",
    "        ret_dict['src_port'] = h[3].split('.')[-1]\n",
    "        ret_dict['src_ip'] = h[3].split('.')[0]\n",
    "        ret_dict['dest_port'] = h[5].split('.')[-1].split(':')[0]\n",
    "        ret_dict['dest_ip'] = h[5].split('.')[0]\n",
    "    else:\n",
    "        if len(h[3].split('.')) > 4:\n",
    "            ret_dict['src_port'] = h[3].split('.')[-1]\n",
    "            ret_dict['src_ip'] = '.'.join(h[3].split('.')[:-1])\n",
    "        else:\n",
    "            ret_dict['src_ip'] = h[3]\n",
    "            ret_dict['src_port'] = ''\n",
    "        if len(h[5].split('.')) > 4:\n",
    "            ret_dict['dest_port'] = h[5].split('.')[-1].split(':')[0]\n",
    "            ret_dict['dest_ip'] = '.'.join(h[5].split('.')[:-1])\n",
    "        else:\n",
    "            ret_dict['dest_ip'] = h[5].split(':')[0]\n",
    "            ret_dict['dest_port'] = ''\n",
    "    return ret_dict\n",
    "\n",
    "def parse_data(line):\n",
    "    ret_str = ''\n",
    "    h, d = line.split(':', 1)\n",
    "    ret_str = d.strip().replace(' ', '')\n",
    "    return ret_str\n",
    "\n",
    "def process_packet(output):\n",
    "    # TODO!! throws away the first packet!\n",
    "    ret_header = {}\n",
    "    ret_dict = {}\n",
    "    ret_data = ''\n",
    "    hasHeader = False\n",
    "    for line in output:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if not line.startswith('0x'):\n",
    "                # header line\n",
    "                if ret_dict and ret_data:\n",
    "                    # about to start new header, finished with hex\n",
    "                    ret_dict['data'] = ret_data\n",
    "                    yield ret_dict\n",
    "                    ret_dict.clear()\n",
    "                    ret_header.clear()\n",
    "                    ret_data = ''\n",
    "                    hasHeader = False\n",
    "                    \n",
    "                # parse next header    \n",
    "                try:\n",
    "                    ret_header = parse_header(line)\n",
    "                    ret_dict.update(ret_header)\n",
    "                    hasHeader = True\n",
    "                except:\n",
    "                    ret_header.clear()\n",
    "                    ret_dict.clear()\n",
    "                    ret_data = ''\n",
    "                    hasHeader = False\n",
    "                    \n",
    "            else:\n",
    "                # hex data line\n",
    "                if hasHeader:\n",
    "                    data = parse_data(line)\n",
    "                    ret_data = ret_data + data\n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "def is_clean_packet(packet):\n",
    "    \"\"\"\n",
    "    Returns whether or not the parsed packet is valid\n",
    "    or not. Checks that both the src and dest\n",
    "    ports are integers. Checks that src and dest IPs\n",
    "    are valid address formats. Checks that packet data\n",
    "    is hex. Returns True if all tests pass, False otherwise.\n",
    "    \"\"\"\n",
    "    if not packet['src_port'].isdigit(): return False\n",
    "    if not packet['dest_port'].isdigit(): return False\n",
    "    \n",
    "    if packet['src_ip'].isalpha(): return False\n",
    "    if packet['dest_ip'].isalpha(): return False\n",
    "    #try:\n",
    "    #    ipaddress.ip_address(packet['src_ip'])\n",
    "    #    ipaddress.ip_address(packet['dest_ip'])\n",
    "    #except:\n",
    "    #    return False\n",
    "     \n",
    "    if 'data' in packet:\n",
    "        try:\n",
    "            int(packet['data'], 16)\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "    \n",
    "    \n",
    "def read_pcap(path):\n",
    "    hex_sessions = OrderedDict()\n",
    "    proc = subprocess.Popen('tcpdump -nn -tttt -xx -r '+path,\n",
    "                            shell=True,\n",
    "                            stdout=subprocess.PIPE)\n",
    "    for packet in process_packet(proc.stdout):\n",
    "        if not is_clean_packet(packet): continue\n",
    "        if 'data' in packet:\n",
    "            key = (packet['src_ip']+\":\"+packet['src_port'], packet['dest_ip']+\":\"+packet['dest_port'])\n",
    "            keys = [k for k in hex_sessions if (k[0] == key[0] and k[1] == key[1]) or (k[0] == key[1] and k[1] == key[0])]\n",
    "            if len(keys) > 0:\n",
    "                #hex_sessions[keys[0]].append(a['direction']+a['data'])\n",
    "                hex_sessions[keys[0]].append(packet['data'])\n",
    "            else:\n",
    "                #hex_sessions[key] = [a['direction']+a['data']]\n",
    "                hex_sessions[key] = [packet['data']]\n",
    "    return hex_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hexSessions = read_pcap(dataPath)\n",
    "\n",
    "print 'gathering capture into sessions'\n",
    "\n",
    "for ses in hexSessions.keys():\n",
    "    paclens = []\n",
    "    for pac in hexSessions[ses]:\n",
    "        paclens.append(len(pac))\n",
    "    if np.min(paclens)<80:\n",
    "        del hexSessions[ses]\n",
    "print 'pickling sessions'\n",
    "\n",
    "with open('bigFlows.pickle', 'wb') as handle:\n",
    "    cPickle.dump(hexSessions, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('bigFlows.pickle', 'rb') as handle:\n",
    "    hexSessions = cPickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making the hex dictionary\n",
    "def hexTokenizer():\n",
    "    hexstring = '0,\t1,\t2,\t3,\t4,\t5,\t6,\t7,\t8,\t9,\tA,\tB,\tC,\tD,\tE,\tF,\t10,\t11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19\\\n",
    "    ,\t1A,\t1B,\t1C,\t1D,\t1E,\t1F,\t20,\t21,\t22,\t23,\t24,\t25,\t26,\t27,\t28,\t29,\t2A,\t2B,\t2C,\t2D,\t2E,\t2F,\t30,\t31,\t32,\t33,\t34,\t35\\\n",
    "    ,\t36,\t37,\t38,\t39,\t3A,\t3B,\t3C,\t3D,\t3E,\t3F,\t40,\t41,\t42,\t43,\t44,\t45,\t46,\t47,\t48,\t49,\t4A,\t4B,\t4C,\t4D,\t4E,\t4F,\t50,\t51\\\n",
    "    ,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t5A,\t5B,\t5C,\t5D,\t5E,\t5F,\t60,\t61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t6A,\t6B,\t6C,\t6D\\\n",
    "    ,\t6E,\t6F,\t70,\t71,\t72,\t73,\t74,\t75,\t76,\t77,\t78,\t79,\t7A,\t7B,\t7C,\t7D,\t7E,\t7F,\t80,\t81,\t82,\t83,\t84,\t85,\t86,\t87,\t88,\t89\\\n",
    "    ,\t8A,\t8B,\t8C,\t8D,\t8E,\t8F,\t90,\t91,\t92,\t93,\t94,\t95,\t96,\t97,\t98,\t99,\t9A,\t9B,\t9C,\t9D,\t9E,\t9F,\tA0,\tA1,\tA2,\tA3,\tA4,\tA5\\\n",
    "    ,\tA6,\tA7,\tA8,\tA9,\tAA,\tAB,\tAC,\tAD,\tAE,\tAF,\tB0,\tB1,\tB2,\tB3,\tB4,\tB5,\tB6,\tB7,\tB8,\tB9,\tBA,\tBB,\tBC,\tBD,\tBE,\tBF,\tC0,\tC1\\\n",
    "    ,\tC2,\tC3,\tC4,\tC5,\tC6,\tC7,\tC8,\tC9,\tCA,\tCB,\tCC,\tCD,\tCE,\tCF,\tD0,\tD1,\tD2,\tD3,\tD4,\tD5,\tD6,\tD7,\tD8,\tD9,\tDA,\tDB,\tDC,\tDD\\\n",
    "    ,\tDE,\tDF,\tE0,\tE1,\tE2,\tE3,\tE4,\tE5,\tE6,\tE7,\tE8,\tE9,\tEA,\tEB,\tEC,\tED,\tEE,\tEF,\tF0,\tF1,\tF2,\tF3,\tF4,\tF5,\tF6,\tF7,\tF8,\tF9\\\n",
    "    ,\tFA,\tFB,\tFC,\tFD,\tFE,\tFF'.replace('\\t', '')\n",
    "\n",
    "    hexList = [x.strip() for x in hexstring.lower().split(',')]\n",
    "    hexList.append('<EOP>') #End Of Packet token\n",
    "    #EOS token??????\n",
    "    hexDict = {}\n",
    "\n",
    "    for key, val in enumerate(hexList):\n",
    "        if len(val) == 1:\n",
    "            val = '0'+val\n",
    "        hexDict[val] = key  #dictionary k=hex, v=int  \n",
    "    \n",
    "    return hexDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hexDict = hexTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary of IP communications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def srcIpDict(hexSessionDict):\n",
    "    ''' \n",
    "    input: dictionary of key = sessions, value = list of HEX HEADERS of packets in session\n",
    "    output: dictionary of key = source IP, value/subkey = dictionary of destination IPs, \n",
    "                                           subvalue = [[sport], [dport], [plen], [protocol]]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    srcIpDict = OrderedDict()   \n",
    "    uniqIPs = [] #some ips are dest only. this will collect all ips, not just srcIpDict.keys()\n",
    "    \n",
    "    for session in hexSessionDict.keys():\n",
    "        \n",
    "        for rawpacket in hexSessionDict[session]:\n",
    "            packet = copy(rawpacket)\n",
    "            \n",
    "            dstIpSubDict = {}\n",
    "            \n",
    "            sourceMAC = packet[:12]\n",
    "            destMAC = packet[12:24]\n",
    "            srcip = packet[52:60]\n",
    "            dstip = packet[60:68]\n",
    "            sport = packet[68:72]\n",
    "            dport = packet[72:76]\n",
    "            plen = packet[32:36]\n",
    "            protocol = packet[46:48]\n",
    "            \n",
    "            uniqIPs = list(set(uniqIPs) | set([dstip, srcip]))\n",
    "\n",
    "            if srcip not in srcIpDict:\n",
    "                dstIpSubDict[dstip] = [[sport], [dport], [plen], [protocol], [sourceMAC], [destMAC]]\n",
    "                srcIpDict[srcip] = dstIpSubDict\n",
    "\n",
    "            if dstip not in srcIpDict[srcip]:    \n",
    "                srcIpDict[srcip][dstip] = [[sport], [dport], [plen], [protocol], [sourceMAC], [destMAC]]\n",
    "            else:\n",
    "                srcIpDict[srcip][dstip][0].append(sport)\n",
    "                srcIpDict[srcip][dstip][1].append(dport)\n",
    "                srcIpDict[srcip][dstip][2].append(plen)\n",
    "                srcIpDict[srcip][dstip][3].append(protocol)\n",
    "                srcIpDict[srcip][dstip][4].append(sourceMAC)\n",
    "                srcIpDict[srcip][dstip][5].append(destMAC)\n",
    "                \n",
    "    return srcIpDict, uniqIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictUniquerizer(dictOdictsOlistOlists):\n",
    "    '''\n",
    "    input: dictionary of dictionaries that have a list of lists \n",
    "           ex. srcIpDict[srcip][dstip] = [[sport], [dport], [plen], [protocol]]\n",
    "    output: dictionary of dictionaries with list of lists with unique items in the final sublist\n",
    "    \n",
    "    WARNING: will overwrite your input dictionary. Make a copy if you want to preserve dictOdictsOlistOlists.\n",
    "    '''\n",
    "    #dictCopy\n",
    "    for key in dictOdictsOlistOlists.keys():\n",
    "        for subkey in dictOdictsOlistOlists[key].keys():\n",
    "            for sublist in xrange(len(dictOdictsOlistOlists[key][subkey])):\n",
    "                dictOdictsOlistOlists[key][subkey][sublist] = list(set(dictOdictsOlistOlists[key][subkey][sublist]))\n",
    "    \n",
    "    return dictOdictsOlistOlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dictionary of ip communications\n"
     ]
    }
   ],
   "source": [
    "#TODO: parallelize\n",
    "print 'creating dictionary of ip communications'\n",
    "\n",
    "#comsDicttest, uniqIPstest = srcIpDict(hexSessionstest)\n",
    "comsDict, uniqIPs = srcIpDict(hexSessions)\n",
    "#test\n",
    "comsDict = dictUniquerizer(comsDict)\n",
    "#comsDicttest = dictUniquerizer(comsDicttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directionality adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ipDirSwitcher(hexSessionList):\n",
    "    '''\n",
    "    switches both ip and mac addresses\n",
    "    input is a list of packets from ONE session\n",
    "    '''\n",
    "    \n",
    "    ipdirsession = []\n",
    "        \n",
    "    for p in hexSessionList:\n",
    "        sourceMAC = p[:12]\n",
    "        destMAC = p[12:24]\n",
    "        sourceIP = p[52:60]\n",
    "        destIP = p[60:68]\n",
    "\n",
    "        ipdirsession.append(destMAC + sourceMAC + p[24:52] + destIP + sourceIP + p[68:])\n",
    "\n",
    "    return ipdirsession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def portDirSwitcher(hexSessionList):\n",
    "    '''\n",
    "    input is a list of packets from ONE session\n",
    "    '''\n",
    "    \n",
    "    portdirsession = []\n",
    "    \n",
    "    for p in hexSessionList:\n",
    "        sport = p[68:72]\n",
    "        dport = p[72:76]\n",
    "\n",
    "        portdirsession.append(p[:68]+dport+sport+p[76:])\n",
    "\n",
    "    return portdirsession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one swap one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: fix the mac switchout\n",
    "def dstIpSwapOut(hexSessionList, dictOcoms, listOuniqIPs):\n",
    "    #srcIpDict[srcip][dstip] = [[sport], [dport], [plen], [protocol]]\n",
    "    \n",
    "    swapSession = []\n",
    "    sourceMAC = hexSessionList[0][:12]#[0] assumes first packet contains true initial direction\n",
    "    destMAC = hexSessionList[0][12:24]\n",
    "    srcip = hexSessionList[0][52:60] \n",
    "    dstip = hexSessionList[0][60:68]\n",
    "    normDstIps = dictOcoms[srcip].keys()+[srcip] #get list of dstIPs that srcIP talks to\n",
    "    abbynormIps = copy(listOuniqIPs)\n",
    "    \n",
    "    for normIp in normDstIps:\n",
    "        abbynormIps.remove(normIp) #remove itself and know dstIPs from list of consideration.\n",
    "    \n",
    "    abbynormDestIp = random.sample(abbynormIps, 1)[0] #get random ip that srcip doesn't talk to\n",
    "\n",
    "    for rawpacket in hexSessionList:\n",
    "        packet = copy(rawpacket)\n",
    "        \n",
    "        if packet[60:68] == dstip:\n",
    "            packet = packet[:60] + abbynormDestIp + packet[68:] #\n",
    "        elif packet[60:68] == srcip:\n",
    "            packet = packet[:52] + abbynormDestIp + packet[60:] #in case direction switches for packet in session\n",
    "            \n",
    "        swapSession.append(packet)\n",
    "\n",
    "    return swapSession\n",
    "\n",
    "\n",
    "#destMAC + sourceMAC + p[24:52] + destIP + sourceIP + p[68:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def dstPortSwapOneOut(hexSessionList):\n",
    "    #THINK THROUGH\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHot(index, granular = 'hex'):\n",
    "    if granular == 'hex':\n",
    "        vecLen = 257\n",
    "    else:\n",
    "        vecLen = 17\n",
    "    \n",
    "    zeroVec = np.zeros(vecLen)\n",
    "    zeroVec[index] = 1.0\n",
    "    \n",
    "    return zeroVec\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oneSessionEncoder(sessionPackets, hexDict, maxPackets = 2, packetTimeSteps = 100,\n",
    "                       packetReverse = False, charLevel = False, padOldTimeSteps = True):    \n",
    "            \n",
    "    sessionCollect = []\n",
    "    packetCollect = []\n",
    "    \n",
    "    if charLevel:\n",
    "        vecLen = 17\n",
    "    else:\n",
    "        vecLen = 257\n",
    "    \n",
    "    if len(sessionPackets) > maxPackets: #crop the number of sessions to maxPackets\n",
    "        sessionList = copy(sessionPackets[:maxPackets])\n",
    "    else:\n",
    "        sessionList = copy(sessionPackets)\n",
    "\n",
    "    for rawpacket in sessionList:\n",
    "        packet = copy(rawpacket)\n",
    "        packet = packet[32:36]+packet[44:46]+packet[46:48]+packet[52:60]+packet[60:68]+\\\n",
    "                 packet[68:70]+packet[70:72]+packet[72:74]\n",
    "        packet = [hexDict[packet[i:i+2]] for i in xrange(0,len(packet)-2+1,2)]\n",
    "        \n",
    "        #print np.asarray(packet)\n",
    "            \n",
    "        if len(packet) >= packetTimeSteps: #crop packet to length packetTimeSteps\n",
    "            packet = packet[:packetTimeSteps]\n",
    "            packet = packet+[256] #add <EOP> end of packet token\n",
    "        else:\n",
    "            packet = packet+[256] #add <EOP> end of packet token\n",
    "        \n",
    "        packetCollect.append(packet)\n",
    "        \n",
    "        pacMat = np.array([oneHot(x) for x in packet]) #one hot encoding of packet into a matrix\n",
    "        pacMatLen = len(pacMat)\n",
    "        \n",
    "        #padding packet\n",
    "        if packetReverse:\n",
    "            pacMat = pacMat[::-1]\n",
    "\n",
    "        if pacMatLen < packetTimeSteps:\n",
    "            #pad by stacking zeros on top of data so that earlier timesteps do not have information\n",
    "            #padding the packet such that zeros are after the actual info for better translation\n",
    "            if padOldTimeSteps:\n",
    "                pacMat = np.vstack( ( np.zeros((packetTimeSteps-pacMatLen,vecLen)), pacMat) ) \n",
    "            else:\n",
    "                pacMat = np.vstack( (pacMat, np.zeros((packetTimeSteps-pacMatLen,vecLen))) ) \n",
    "\n",
    "        if pacMatLen > packetTimeSteps:\n",
    "            pacMat = pacMat[:packetTimeSteps, :]\n",
    "\n",
    "        sessionCollect.append(pacMat)\n",
    "\n",
    "    #padding session\n",
    "    sessionCollect = np.asarray(sessionCollect, dtype=theano.config.floatX)\n",
    "    numPacketsInSession = sessionCollect.shape[0]\n",
    "    if numPacketsInSession < maxPackets:\n",
    "        #pad sessions to fit the \n",
    "        sessionCollect = np.vstack( (sessionCollect,np.zeros((maxPackets-numPacketsInSession, \n",
    "                                                             packetTimeSteps, vecLen))) )\n",
    "    \n",
    "    return sessionCollect, packetCollect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p != 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X / retain_prob * srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "    return X\n",
    "\n",
    "# Gradient clipping\n",
    "def clip_norm(g, c, n): \n",
    "    '''n is the norm, c is the threashold, and g is the gradient'''\n",
    "    \n",
    "    if c > 0: \n",
    "        g = T.switch(T.ge(n, c), g*c/n, g) \n",
    "    return g\n",
    "\n",
    "def clip_norms(gs, c):\n",
    "    norm = T.sqrt(sum([T.sum(g**2) for g in gs]))\n",
    "    return [clip_norm(g, c, norm) for g in gs]\n",
    "\n",
    "# Regularizers\n",
    "def max_norm(p, maxnorm = 0.):\n",
    "    if maxnorm > 0:\n",
    "        norms = T.sqrt(T.sum(T.sqr(p), axis=0))\n",
    "        desired = T.clip(norms, 0, maxnorm)\n",
    "        p = p * (desired/ (1e-7 + norms))\n",
    "    return p\n",
    "\n",
    "def gradient_regularize(p, g, l1 = 0., l2 = 0.):\n",
    "    g += p * l2\n",
    "    g += T.sgn(p) * l1\n",
    "    return g\n",
    "\n",
    "def weight_regularize(p, maxnorm = 0.):\n",
    "    p = max_norm(p, maxnorm)\n",
    "    return p\n",
    "\n",
    "def Adam(params, cost, lr=0.0002, b1=0.1, b2=0.001, e=1e-8, l1 = 0., l2 = 0., maxnorm = 0., c = 8):\n",
    "    \n",
    "    updates = []\n",
    "    grads = T.grad(cost, params)\n",
    "    grads = clip_norms(grads, c)\n",
    "    \n",
    "    i = theano.shared(floatX(0.))\n",
    "    i_t = i + 1.\n",
    "    fix1 = 1. - b1**(i_t)\n",
    "    fix2 = 1. - b2**(i_t)\n",
    "    lr_t = lr * (T.sqrt(fix2) / fix1)\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        m = theano.shared(p.get_value() * 0.)\n",
    "        v = theano.shared(p.get_value() * 0.)\n",
    "        m_t = (b1 * g) + ((1. - b1) * m)\n",
    "        v_t = (b2 * T.sqr(g)) + ((1. - b2) * v)\n",
    "        g_t = m_t / (T.sqrt(v_t) + e)\n",
    "        g_t = gradient_regularize(p, g_t, l1=l1, l2=l2)\n",
    "        p_t = p - (lr_t * g_t)\n",
    "        p_t = weight_regularize(p_t, maxnorm=maxnorm)\n",
    "        \n",
    "        updates.append((m, m_t))\n",
    "        updates.append((v, v_t))\n",
    "        updates.append((p, p_t))\n",
    "    \n",
    "    updates.append((i, i_t))\n",
    "    #if iteration%100 == 0:\n",
    "    #    updates.append((lr, lr*0.93))\n",
    "    #else:\n",
    "    #    updates.append((lr, lr))\n",
    "    \n",
    "    return updates\n",
    "\n",
    "def RMSprop(cost, params, lr = 0.001, l1 = 0., l2 = 0., maxnorm = 0., rho=0.9, epsilon=1e-6, c = 8):\n",
    "    \n",
    "    grads = T.grad(cost, params)\n",
    "    grads = clip_norms(grads, c)\n",
    "    updates = []\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        g = gradient_regularize(p, g, l1 = l1, l2 = l2)\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        updates.append((acc, acc_new))\n",
    "        \n",
    "        updated_p = p - lr * (g / T.sqrt(acc_new + epsilon))\n",
    "        updated_p = weight_regularize(updated_p, maxnorm = maxnorm)\n",
    "        updates.append((p, updated_p))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictClass(predictFun, hexSessionsDict, comsDict, uniqIPs, hexDict,\n",
    "                 numClasses = 4, trainPercent = 0.9, dimIn=257, maxPackets=2,\n",
    "                 packetTimeSteps = 16, padOldTimeSteps=True, batch_sizeClass = 20):\n",
    "    \n",
    "    testCollect = []\n",
    "    predtargets = []\n",
    "    actualtargets = []\n",
    "    hexSessionsKeys = hexSessionsDict.keys()\n",
    "    trainPercent = 0.9\n",
    "    trainIndex = int(len(hexSessionsKeys)*trainPercent)\n",
    "        \n",
    "    for start, end in zip(range(trainIndex, len(hexSessionsKeys), batch_sizeClass),\n",
    "                          range(trainIndex + batch_sizeClass, len(hexSessionsKeys), batch_sizeClass)):\n",
    "        trainingSessions = []\n",
    "        trainingTargets = []\n",
    "        \n",
    "        for trainKey in range(start, end):\n",
    "            sessionForEncoding = list(hexSessionsDict[hexSessionsKeys[trainKey]])\n",
    "\n",
    "            #ENCODE NORMAL SESSION\n",
    "            #oneHotSes = oneSessionEncoder(sessionForEncoding,hexDict = hexDict, packetReverse=packetReverse, \n",
    "            #                              padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets,\n",
    "            #                              packetTimeSteps = packetTimeSteps)\n",
    "            #trainingSessions.append(oneHotSes[0])\n",
    "            #trainingTargets.append(normalTarget)\n",
    "\n",
    "            #ENCODE ABBY NORMAL SESSION\n",
    "            adversaryList = [sessionForEncoding, \n",
    "                             dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs), \n",
    "                             portDirSwitcher(sessionForEncoding), \n",
    "                             ipDirSwitcher(sessionForEncoding)]\n",
    "            abbyIndex = random.sample(range(len(adversaryList)), 1)[0]\n",
    "            #abbyHexSession = random.sample(range(len(adversaryList), 1)[0]\n",
    "            #abbyHexSession = ipDirSwitcher(sessionForEncoding)\n",
    "            #abbyHexSession = dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs)\n",
    "            #abbyHexSession = portDirSwitcher(sessionForEncoding)\n",
    "            abbyOneHotSes = oneSessionEncoder(adversaryList[abbyIndex],\n",
    "                                              hexDict = hexDict,\n",
    "                                              packetReverse=packetReverse, \n",
    "                                              padOldTimeSteps = padOldTimeSteps, \n",
    "                                              maxPackets = maxPackets, \n",
    "                                              packetTimeSteps = packetTimeSteps)\n",
    "\n",
    "            targetClasses = [0]*numClasses\n",
    "            targetClasses[abbyIndex] = 1\n",
    "            abbyTarget = np.array(targetClasses, dtype=theano.config.floatX)\n",
    "            trainingSessions.append(abbyOneHotSes[0])\n",
    "            trainingTargets.append(abbyTarget)\n",
    "  \n",
    "        #trainingSessions2 = [item for sublist in trainingSessions for item in sublist] #FIX in oneSessionEncoder\n",
    "        sessionsMinibatch = np.asarray(trainingSessions, dtype=theano.config.floatX)\\\n",
    "                                       .reshape((batch_sizeClass*maxPackets, packetTimeSteps, 1, dimIn))\n",
    "        targetsMinibatch = np.asarray(trainingTargets, dtype=theano.config.floatX)\n",
    "\n",
    "        predcostfun = predictFun(sessionsMinibatch)\n",
    "        testCollect.append(np.mean(np.argmax(predcostfun,axis=1) == np.argmax(targetsMinibatch, axis=1)))\n",
    "        \n",
    "        predtargets = predtargets + list(np.argmax(predcostfun,axis=1))\n",
    "        actualtargets = actualtargets + list(np.argmax(targetsMinibatch, axis=1))\n",
    "    \n",
    "    print \"TEST accuracy:         \", np.mean(testCollect)\n",
    "    print\n",
    "\n",
    "    return predtargets, actualtargets, np.mean(testCollect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binaryPrecisionRecall(predictions, targets, numClasses = 4):\n",
    "    for cla in range(numClasses):\n",
    "        \n",
    "        confustop = np.array([])\n",
    "        confusbottom = np.array([])\n",
    "\n",
    "        predictions = np.asarray(predictions).flatten()\n",
    "        targets = np.asarray(targets).flatten()\n",
    "\n",
    "        pred1 = np.where(predictions == cla)\n",
    "        pred0 = np.where(predictions != cla)\n",
    "        target1 = np.where(targets == cla)\n",
    "        target0 = np.where(targets != cla)\n",
    "\n",
    "        truePos = np.intersect1d(pred1[0],target1[0]).shape[0]\n",
    "        trueNeg = np.intersect1d(pred0[0],target0[0]).shape[0]\n",
    "        falsePos = np.intersect1d(pred1[0],target0[0]).shape[0]\n",
    "        falseNeg = np.intersect1d(pred0[0],target1[0]).shape[0]\n",
    "\n",
    "        top = np.append(confustop, (truePos, falsePos))\n",
    "        bottom = np.append(confusbottom, (falseNeg, trueNeg))\n",
    "        confusionMatrix = np.vstack((top, bottom))\n",
    "        \n",
    "        precision  = float(truePos)/(truePos + falsePos + 0.00001) #1 - (how much junk did we give user)\n",
    "        recall = float(truePos)/(truePos + falseNeg + 0.00001) #1 - (how much good stuff did we miss)\n",
    "        f1 = 2*((precision*recall)/(precision+recall+0.00001))\n",
    "        \n",
    "        print 'class '+str(cla)+' precision: ', precision\n",
    "        print 'class '+str(cla)+' recall:    ', recall\n",
    "        print 'class '+str(cla)+' f1:        ', f1\n",
    "        print\n",
    "    \n",
    "        #return confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickleModel(trainedClassifier, file2save2 = None, filePath='/work/notebooks/drawModels/', fileName = 'myModels'):\n",
    "    \n",
    "    if file2save2 == None:\n",
    "        f=file(filePath+fileName+'.save', 'wb')\n",
    "    else:\n",
    "        f=file(filePath+file2save2, 'wb')\n",
    "        \n",
    "    cPickle.dump(trainedClassifier, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "def loadModel(filePath):\n",
    "    file2open = file(filePath, 'rb')\n",
    "    model = cPickle.load(file2open)\n",
    "    file2open.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization for both the unsupervised net and the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4('inputs')\n",
    "Y = T.matrix('targets')\n",
    "linewt_init = IsotropicGaussian(wtstd)\n",
    "line_bias = Constant(1.0)\n",
    "rnnwt_init = IsotropicGaussian(wtstd)\n",
    "rnnbias_init = Constant(0.0)\n",
    "classifierWts = IsotropicGaussian(wtstd)\n",
    "\n",
    "###ENCODER\n",
    "if rnnType == 'gru':\n",
    "    rnn = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "fork = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dimIn, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "###CONTEXT\n",
    "if rnnType == 'gru':\n",
    "    rnnContext = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                biases_init = rnnbias_init, name = 'gruContext')\n",
    "else:\n",
    "    rnnContext = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, \n",
    "                      name = 'lstmContext')\n",
    "\n",
    "forkContext = Fork(output_names=['linearContext', 'gatesContext'],\n",
    "            name='forkContext', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "\n",
    "\n",
    "forkDec = Fork(output_names=['linear', 'gates'],\n",
    "            name='forkDec', input_dim=dim, output_dims=[dim, dim*dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "#CLASSIFIER\n",
    "bmlp = BatchNormalizedMLP( activations=[Logistic(),Logistic()], \n",
    "           dims=[dim, dim, numClasses],\n",
    "           weights_init=classifierWts,\n",
    "           biases_init=Constant(0.0001) )\n",
    "\n",
    "#initialize the weights in all the functions\n",
    "fork.initialize()\n",
    "rnn.initialize()\n",
    "\n",
    "forkContext.initialize()\n",
    "rnnContext.initialize()\n",
    "\n",
    "forkDec.initialize()\n",
    "bmlp.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling functions you talented soul\n",
      "finished compiling\n"
     ]
    }
   ],
   "source": [
    "def onestepEnc(X):\n",
    "    data1, data2 = fork.apply(X) \n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hEnc = rnn.apply(data1, data2) \n",
    "    else:\n",
    "        hEnc, _ = rnn.apply(data2)\n",
    "    \n",
    "    return hEnc\n",
    "\n",
    "hEnc, _ = theano.scan(onestepEnc, X)\n",
    "hEncReshape = T.reshape(hEnc[:,-1], (batch_sizeClass,maxPackets,1,dim))\n",
    "\n",
    "\n",
    "#TODO: BIDIRECTIONAL PARAM\n",
    "def onestepContext(hEncReshape):\n",
    "    \n",
    "    data3, data4 = forkContext.apply(hEncReshape)\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        hContext = rnnContext.apply(data3, data4)\n",
    "    else:\n",
    "        hinitContext, _ = rnnContext.apply(data4)\n",
    "        hContext = hinitContext #hContext shape = (batch_size, maxPackets, dim)\n",
    "\n",
    "    return hContext\n",
    "\n",
    "\n",
    "hContext, _ = theano.scan(onestepContext, hEncReshape)\n",
    "hContextReshape = T.reshape(hContext[:,-1], (batch_sizeClass,dim))\n",
    "\n",
    "data5, _ = forkDec.apply(hContextReshape)\n",
    "\n",
    "pyx = bmlp.apply(data5)\n",
    "softmax = Softmax()\n",
    "softoutClass = softmax.apply(pyx)\n",
    "costClass = T.mean(CategoricalCrossEntropy().apply(Y, softoutClass))\n",
    "\n",
    "#CREATE GRAPH\n",
    "cgClass = ComputationGraph([costClass])\n",
    "paramsClass = VariableFilter(roles = [PARAMETER])(cgClass.variables)\n",
    "updatesClass = Adam(paramsClass, costClass, learning_rateClass, c=clippings) \n",
    "#updatesClass = RMSprop(costClass, paramsClass, learning_rateClass, c=clippings)\n",
    "\n",
    "#print 'grad compiling'\n",
    "#gradients = T.grad(costClass, paramsClass)\n",
    "#gradients = clip_norms(gradients, clippings)\n",
    "#gradientFun = theano.function([X,Y], gradients, allow_input_downcast=True)\n",
    "#print 'finish with grads'\n",
    "\n",
    "print 'compiling functions you talented soul'\n",
    "classifierTrain = theano.function([X,Y], [costClass, hEnc, hContext, pyx, softoutClass], \n",
    "                                  updates=updatesClass, allow_input_downcast=True)\n",
    "classifierPredict = theano.function([X], softoutClass, allow_input_downcast=True)\n",
    "print 'finished compiling'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are amazing\n",
      "\n",
      "   Iteration:  200\n",
      "   Cost:  1.11947\n",
      "   TRAIN accuracy:  0.635\n",
      "\n",
      "\n",
      "   Iteration:  400\n",
      "   Cost:  0.981984\n",
      "   TRAIN accuracy:  0.7025\n",
      "\n",
      "TEST accuracy:          0.696590909091\n",
      "\n",
      "class 0 precision:  0.356164359167\n",
      "class 0 recall:     0.127450977268\n",
      "class 0 f1:         0.187721743358\n",
      "\n",
      "class 1 precision:  0.508990311079\n",
      "class 1 recall:     0.84018262922\n",
      "class 1 f1:         0.633931552255\n",
      "\n",
      "class 2 precision:  0.919239883153\n",
      "class 2 recall:     0.865771792712\n",
      "class 2 f1:         0.891700053092\n",
      "\n",
      "class 3 precision:  0.891489342734\n",
      "class 3 recall:     0.897216254878\n",
      "class 3 f1:         0.894338630936\n",
      "\n",
      "\n",
      "   Iteration:  600\n",
      "   Cost:  0.972666\n",
      "   TRAIN accuracy:  0.6875\n",
      "\n",
      "TEST accuracy:          0.755113636364\n",
      "\n",
      "class 0 precision:  0.486021494924\n",
      "class 0 recall:     0.54987833212\n",
      "class 0 f1:         0.515976742427\n",
      "\n",
      "class 1 precision:  0.549636790566\n",
      "class 1 recall:     0.501103741697\n",
      "class 1 f1:         0.52424442124\n",
      "\n",
      "class 2 precision:  0.989200842566\n",
      "class 2 recall:     0.976545821396\n",
      "class 2 f1:         0.982827597168\n",
      "\n",
      "class 3 precision:  0.997613341346\n",
      "class 3 recall:     0.978922693702\n",
      "class 3 f1:         0.988174646142\n",
      "\n",
      "\n",
      "   Iteration:  10600\n",
      "   Cost:  0.877074\n",
      "   TRAIN accuracy:  0.755\n",
      "\n",
      "\n",
      "   Iteration:  10800\n",
      "   Cost:  0.881938\n",
      "   TRAIN accuracy:  0.7575\n",
      "\n",
      "\n",
      "   Iteration:  11000\n",
      "   Cost:  0.872409\n",
      "   TRAIN accuracy:  0.7825\n",
      "\n",
      "TEST accuracy:          0.746590909091\n",
      "\n",
      "class 0 precision:  0.505035963956\n",
      "class 0 recall:     0.801369844718\n",
      "class 0 f1:         0.619589244596\n",
      "\n",
      "class 1 precision:  0.588235262661\n",
      "class 1 recall:     0.237580988389\n",
      "class 1 f1:         0.338457429588\n",
      "\n",
      "class 2 precision:  0.959660276865\n",
      "class 2 recall:     0.993406571573\n",
      "class 2 f1:         0.976236881081\n",
      "\n",
      "class 3 precision:  0.98525796105\n",
      "class 3 recall:     0.992574232857\n",
      "class 3 f1:         0.988897565102\n",
      "\n",
      "Epoch:  13\n",
      "Epoch cost average:  0.877581\n",
      "Epoch TRAIN accuracy:  0.749\n",
      "\n",
      "   Iteration:  11200\n",
      "   Cost:  0.875729\n",
      "   TRAIN accuracy:  0.7575\n",
      "\n",
      "\n",
      "   Iteration:  27800\n",
      "   Cost:  0.845\n",
      "   TRAIN accuracy:  0.885\n",
      "\n",
      "Epoch:  34\n",
      "Epoch cost average:  0.799068\n",
      "Epoch TRAIN accuracy:  0.928\n",
      "\n",
      "   Iteration:  28000\n",
      "   Cost:  0.811912\n",
      "   TRAIN accuracy:  0.9175\n",
      "\n",
      "TEST accuracy:          0.919318181818\n",
      "\n",
      "class 0 precision:  0.864608055472\n",
      "class 0 recall:     0.838709658094\n",
      "class 0 f1:         0.851456969572\n",
      "\n",
      "class 1 precision:  0.858407060655\n",
      "class 1 recall:     0.866071409239\n",
      "class 1 f1:         0.862217203189\n",
      "\n",
      "class 2 precision:  0.957983173152\n",
      "class 2 recall:     0.995633166034\n",
      "class 2 f1:         0.976440377119\n",
      "\n",
      "class 3 precision:  0.997566885704\n",
      "class 3 recall:     0.976190452948\n",
      "class 3 f1:         0.986757913084\n",
      "\n",
      "\n",
      "   Iteration:  28200\n",
      "   Cost:  0.772591\n",
      "   TRAIN accuracy:  0.9625\n",
      "\n",
      "\n",
      "   Iteration:  28400\n",
      "   Cost:  0.80566\n",
      "   TRAIN accuracy:  0.92\n",
      "\n",
      "TEST accuracy:          0.939772727273\n",
      "\n",
      "class 0 precision:  0.895348816387\n",
      "class 0 recall:     0.87301585322\n",
      "class 0 f1:         0.884036312329\n",
      "\n",
      "class 1 precision:  0.887168121965\n",
      "class 1 recall:     0.899103118854\n",
      "class 1 f1:         0.893090748735\n",
      "\n",
      "class 2 precision:  0.977116682446\n",
      "class 2 recall:     0.995337972137\n",
      "class 2 f1:         0.986138164744\n",
      "\n",
      "class 3 precision:  0.999999977324\n",
      "class 3 recall:     0.993243220873\n",
      "class 3 f1:         0.996605147052\n",
      "\n",
      "\n",
      "   Iteration:  28600\n",
      "   Cost:  0.815959\n",
      "   TRAIN accuracy:  0.9175\n",
      "\n",
      "Epoch:  35\n",
      "Epoch cost average:  0.796514\n",
      "Epoch TRAIN accuracy:  0.943\n",
      "\n",
      "   Iteration:  28800\n",
      "   Cost:  0.785346\n",
      "   TRAIN accuracy:  0.95\n",
      "\n",
      "\n",
      "   Iteration:  29000\n",
      "   Cost:  0.780652\n",
      "   TRAIN accuracy:  0.95\n",
      "\n",
      "TEST accuracy:          0.925568181818\n",
      "\n",
      "class 0 precision:  0.930666641849\n",
      "class 0 recall:     0.780760608932\n",
      "class 0 f1:         0.849143436221\n",
      "\n",
      "class 1 precision:  0.816205517466\n",
      "class 1 recall:     0.942922352901\n",
      "class 1 f1:         0.874995007435\n",
      "\n",
      "class 2 precision:  0.979999978222\n",
      "class 2 recall:     0.995485304842\n",
      "class 2 f1:         0.987676949097\n",
      "\n",
      "class 3 precision:  0.99300696986\n",
      "class 3 recall:     0.986111088284\n",
      "class 3 f1:         0.989542015427\n",
      "\n",
      "\n",
      "   Iteration:  29200\n",
      "   Cost:  0.800892\n",
      "   TRAIN accuracy:  0.9425\n",
      "\n",
      "\n",
      "   Iteration:  29400\n",
      "   Cost:  0.818064\n",
      "   TRAIN accuracy:  0.915\n",
      "\n",
      "Epoch:  36\n",
      "Epoch cost average:  0.792289\n",
      "Epoch TRAIN accuracy:  0.939\n",
      "TEST accuracy:          0.939772727273\n",
      "\n",
      "class 0 precision:  0.897777757827\n",
      "class 0 recall:     0.882096050609\n",
      "class 0 f1:         0.889862822225\n",
      "\n",
      "class 1 precision:  0.882629087262\n",
      "class 1 recall:     0.89099523955\n",
      "class 1 f1:         0.886787432055\n",
      "\n",
      "class 2 precision:  0.982608674291\n",
      "class 2 recall:     0.997792472455\n",
      "class 2 f1:         0.990137366362\n",
      "\n",
      "class 3 precision:  0.995282995394\n",
      "class 3 recall:     0.988290374981\n",
      "class 3 f1:         0.991769359858\n",
      "\n",
      "\n",
      "   Iteration:  29600\n",
      "   Cost:  0.777097\n",
      "   TRAIN accuracy:  0.9675\n",
      "\n",
      "\n",
      "   Iteration:  29800\n",
      "   Cost:  0.778938\n",
      "   TRAIN accuracy:  0.96\n",
      "\n",
      "\n",
      "   Iteration:  30000\n",
      "   Cost:  0.792772\n",
      "   TRAIN accuracy:  0.9375\n",
      "\n",
      "TEST accuracy:          0.933522727273\n",
      "\n",
      "class 0 precision:  0.913978470054\n",
      "class 0 recall:     0.82125601881\n",
      "class 0 f1:         0.865134941401\n",
      "\n",
      "class 1 precision:  0.854736824111\n",
      "class 1 recall:     0.926940618106\n",
      "class 1 f1:         0.889370673314\n",
      "\n",
      "class 2 precision:  0.980728030391\n",
      "class 2 recall:     0.982832596935\n",
      "class 2 f1:         0.981774185845\n",
      "\n",
      "class 3 precision:  0.984304910666\n",
      "class 3 recall:     0.993212647212\n",
      "class 3 f1:         0.988733716597\n",
      "\n",
      "\n",
      "   Iteration:  30200\n",
      "   Cost:  0.795392\n",
      "   TRAIN accuracy:  0.9375\n",
      "\n",
      "Epoch:  37\n",
      "Epoch cost average:  0.800328\n",
      "Epoch TRAIN accuracy:  0.935\n",
      "\n",
      "   Iteration:  30400\n",
      "   Cost:  0.789938\n",
      "   TRAIN accuracy:  0.9525\n",
      "\n",
      "TEST accuracy:          0.939772727273\n",
      "\n",
      "class 0 precision:  0.89099523955\n",
      "class 0 recall:     0.872389770942\n",
      "class 0 f1:         0.881589352716\n",
      "\n",
      "class 1 precision:  0.88811186741\n",
      "class 1 recall:     0.898584884467\n",
      "class 1 f1:         0.893312681482\n",
      "\n",
      "class 2 precision:  0.978118140523\n",
      "class 2 recall:     0.991130798423\n",
      "class 2 f1:         0.984576476354\n",
      "\n",
      "class 3 precision:  0.995575199213\n",
      "class 3 recall:     0.99118940548\n",
      "class 3 f1:         0.993372461564\n",
      "\n",
      "\n",
      "   Iteration:  30600\n",
      "   Cost:  0.778163\n",
      "   TRAIN accuracy:  0.96\n",
      "\n",
      "\n",
      "   Iteration:  30800\n",
      "   Cost:  0.812821\n",
      "   TRAIN accuracy:  0.915\n",
      "\n",
      "\n",
      "   Iteration:  31000\n",
      "   Cost:  0.811293\n",
      "   TRAIN accuracy:  0.9275\n",
      "\n",
      "TEST accuracy:          0.920454545455\n",
      "\n",
      "class 0 precision:  0.892156840879\n",
      "class 0 recall:     0.805309716697\n",
      "class 0 f1:         0.846506621338\n",
      "\n",
      "class 1 precision:  0.817982438202\n",
      "class 1 recall:     0.905339783851\n",
      "class 1 f1:         0.859441997682\n",
      "\n",
      "class 2 precision:  0.979452032433\n",
      "class 2 recall:     0.974999977841\n",
      "class 2 f1:         0.977215934511\n",
      "\n",
      "class 3 precision:  0.991266353902\n",
      "class 3 recall:     0.995614013254\n",
      "class 3 f1:         0.993430426889\n",
      "\n",
      "Epoch:  38\n",
      "Epoch cost average:  0.791471\n",
      "Epoch TRAIN accuracy:  0.945\n",
      "\n",
      "   Iteration:  31200\n",
      "   Cost:  0.794235\n",
      "   TRAIN accuracy:  0.925\n",
      "\n",
      "\n",
      "   Iteration:  31400\n",
      "   Cost:  0.784056\n",
      "   TRAIN accuracy:  0.945\n",
      "\n",
      "TEST accuracy:          0.935795454545\n",
      "\n",
      "class 0 precision:  0.880841100915\n",
      "class 0 recall:     0.872685164984\n",
      "class 0 f1:         0.876739165794\n",
      "\n",
      "class 1 precision:  0.884526538464\n",
      "class 1 recall:     0.896955482507\n",
      "class 1 f1:         0.890692653976\n",
      "\n",
      "class 2 precision:  0.977011471793\n",
      "class 2 recall:     0.979262650247\n",
      "class 2 f1:         0.978130765783\n",
      "\n",
      "class 3 precision:  0.995689633714\n",
      "class 3 recall:     0.9892933407\n",
      "class 3 f1:         0.992476181764\n",
      "\n",
      "\n",
      "   Iteration:  31600\n",
      "   Cost:  0.806153\n",
      "   TRAIN accuracy:  0.915\n",
      "\n",
      "\n",
      "   Iteration:  31800\n",
      "   Cost:  0.800881\n",
      "   TRAIN accuracy:  0.9375\n",
      "\n",
      "Epoch:  39\n",
      "Epoch cost average:  0.795035\n",
      "Epoch TRAIN accuracy:  0.942\n",
      "\n",
      "   Iteration:  32000\n",
      "   Cost:  0.786574\n",
      "   TRAIN accuracy:  0.95\n",
      "\n",
      "TEST accuracy:          0.935227272727\n",
      "\n",
      "class 0 precision:  0.936708837045\n",
      "class 0 recall:     0.814977955617\n",
      "class 0 f1:         0.871608666776\n",
      "\n",
      "class 1 precision:  0.842213097496\n",
      "class 1 recall:     0.947004586475\n",
      "class 1 f1:         0.891535127992\n",
      "\n",
      "class 2 precision:  0.983213405678\n",
      "class 2 recall:     0.985576899385\n",
      "class 2 f1:         0.984388733901\n",
      "\n",
      "class 3 precision:  0.98913041328\n",
      "class 3 recall:     0.997806995662\n",
      "class 3 f1:         0.993444760089\n",
      "\n",
      "\n",
      "   Iteration:  32200\n",
      "   Cost:  0.806204\n",
      "   TRAIN accuracy:  0.9375\n",
      "\n",
      "\n",
      "   Iteration:  32400\n",
      "   Cost:  0.80853\n",
      "   TRAIN accuracy:  0.9125\n",
      "\n",
      "TEST accuracy:          0.940340909091\n",
      "\n",
      "class 0 precision:  0.898617490815\n",
      "class 0 recall:     0.880361153942\n",
      "class 0 f1:         0.889390647319\n",
      "\n",
      "class 1 precision:  0.899563299136\n",
      "class 1 recall:     0.909492253654\n",
      "class 1 f1:         0.904495529168\n",
      "\n",
      "class 2 precision:  0.977064197774\n",
      "class 2 recall:     0.983833695523\n",
      "class 2 f1:         0.980432261755\n",
      "\n",
      "class 3 precision:  0.988425903046\n",
      "class 3 recall:     0.990719234554\n",
      "class 3 f1:         0.989566240135\n",
      "\n",
      "\n",
      "   Iteration:  32600\n",
      "   Cost:  0.78761\n",
      "   TRAIN accuracy:  0.9525\n",
      "\n",
      "Epoch:  40\n",
      "Epoch cost average:  0.798294\n",
      "Epoch TRAIN accuracy:  0.939\n",
      "\n",
      "   Iteration:  32800\n",
      "   Cost:  0.764778\n",
      "   TRAIN accuracy:  0.9725\n",
      "\n",
      "\n",
      "   Iteration:  33000\n",
      "   Cost:  0.810339\n",
      "   TRAIN accuracy:  0.9225\n",
      "\n",
      "TEST accuracy:          0.928977272727\n",
      "\n",
      "class 0 precision:  0.907859053988\n",
      "class 0 recall:     0.807228896211\n",
      "class 0 f1:         0.854586832176\n",
      "\n",
      "class 1 precision:  0.842718430238\n",
      "class 1 recall:     0.925373114598\n",
      "class 1 f1:         0.882108814164\n",
      "\n",
      "class 2 precision:  0.982222200395\n",
      "class 2 recall:     0.993258404646\n",
      "class 2 f1:         0.987704475316\n",
      "\n",
      "class 3 precision:  0.995305140955\n",
      "class 3 recall:     0.983758677871\n",
      "class 3 f1:         0.989493226812\n",
      "\n",
      "\n",
      "   Iteration:  33200\n",
      "   Cost:  0.796507\n",
      "   TRAIN accuracy:  0.935\n",
      "\n",
      "\n",
      "   Iteration:  33400\n",
      "   Cost:  0.818253\n",
      "   TRAIN accuracy:  0.925\n",
      "\n",
      "Epoch:  41\n",
      "Epoch cost average:  0.796376\n",
      "Epoch TRAIN accuracy:  0.944\n",
      "TEST accuracy:          0.946590909091\n",
      "\n",
      "class 0 precision:  0.887828141102\n",
      "class 0 recall:     0.894230747735\n",
      "class 0 f1:         0.891012942823\n",
      "\n",
      "class 1 precision:  0.90277775688\n",
      "class 1 recall:     0.892448492164\n",
      "class 1 f1:         0.897578408765\n",
      "\n",
      "class 2 precision:  0.999999977876\n",
      "class 2 recall:     0.993406571573\n",
      "class 2 f1:         0.996687370605\n",
      "\n",
      "class 3 precision:  0.98905905932\n",
      "class 3 recall:     0.999999977876\n",
      "class 3 f1:         0.99449442824\n",
      "\n",
      "\n",
      "   Iteration:  33600\n",
      "   Cost:  0.775111\n",
      "   TRAIN accuracy:  0.96\n",
      "\n",
      "\n",
      "   Iteration:  33800\n",
      "   Cost:  0.821567\n",
      "   TRAIN accuracy:  0.9075\n",
      "\n",
      "\n",
      "   Iteration:  34000\n",
      "   Cost:  0.775653\n",
      "   TRAIN accuracy:  0.9625\n",
      "\n",
      "TEST accuracy:          0.944886363636\n",
      "\n",
      "class 0 precision:  0.908256859902\n",
      "class 0 recall:     0.879999980444\n",
      "class 0 f1:         0.893900172972\n",
      "\n",
      "class 1 precision:  0.883928551698\n",
      "class 1 recall:     0.910344806659\n",
      "class 1 f1:         0.896937223151\n",
      "\n",
      "class 2 precision:  0.988913503572\n",
      "class 2 recall:     0.9933184634\n",
      "class 2 f1:         0.991106089136\n",
      "\n",
      "class 3 precision:  0.999999976471\n",
      "class 3 recall:     0.997652558741\n",
      "class 3 f1:         0.998819888426\n",
      "\n",
      "\n",
      "   Iteration:  34200\n",
      "   Cost:  0.788079\n",
      "   TRAIN accuracy:  0.9525\n",
      "\n",
      "Epoch:  42\n",
      "Epoch cost average:  0.799841\n",
      "Epoch TRAIN accuracy:  0.938\n",
      "\n",
      "   Iteration:  34400\n",
      "   Cost:  0.786302\n",
      "   TRAIN accuracy:  0.955\n",
      "\n",
      "TEST accuracy:          0.948295454545\n",
      "\n",
      "class 0 precision:  0.864035068771\n",
      "class 0 recall:     0.93809521576\n",
      "class 0 f1:         0.89953836693\n",
      "\n",
      "class 1 precision:  0.943627427852\n",
      "class 1 recall:     0.863228680197\n",
      "class 1 f1:         0.901634333074\n",
      "\n",
      "class 2 precision:  0.986363613946\n",
      "class 2 recall:     0.995412821206\n",
      "class 2 f1:         0.990862557416\n",
      "\n",
      "class 3 precision:  0.99999997807\n",
      "class 3 recall:     0.995633166034\n",
      "class 3 f1:         0.997806794408\n",
      "\n",
      "\n",
      "   Iteration:  34600\n",
      "   Cost:  0.815608\n",
      "   TRAIN accuracy:  0.925\n",
      "\n",
      "\n",
      "   Iteration:  34800\n",
      "   Cost:  0.839241\n",
      "   TRAIN accuracy:  0.8975\n",
      "\n",
      "\n",
      "   Iteration:  35000\n",
      "   Cost:  0.806102\n",
      "   TRAIN accuracy:  0.9325\n",
      "\n",
      "TEST accuracy:          0.940340909091\n",
      "\n",
      "class 0 precision:  0.87301585322\n",
      "class 0 recall:     0.897435876517\n",
      "class 0 f1:         0.885052451898\n",
      "\n",
      "class 1 precision:  0.912472627736\n",
      "class 1 recall:     0.891025621987\n",
      "class 1 f1:         0.901616602862\n",
      "\n",
      "class 2 precision:  0.983606534342\n",
      "class 2 recall:     0.983606534342\n",
      "class 2 f1:         0.983601534367\n",
      "\n",
      "class 3 precision:  0.995402275968\n",
      "class 3 recall:     0.993119243277\n",
      "class 3 f1:         0.994254449073\n",
      "\n",
      "Epoch:  43\n",
      "Epoch cost average:  0.797788\n",
      "Epoch TRAIN accuracy:  0.936\n",
      "\n",
      "   Iteration:  35200\n",
      "   Cost:  0.769011\n",
      "   TRAIN accuracy:  0.97\n",
      "\n",
      "\n",
      "   Iteration:  35400\n",
      "   Cost:  0.817895\n",
      "   TRAIN accuracy:  0.9225\n",
      "\n",
      "TEST accuracy:          0.944318181818\n",
      "\n",
      "class 0 precision:  0.906172817132\n",
      "class 0 recall:     0.87173394604\n",
      "class 0 f1:         0.88861483511\n",
      "\n",
      "class 1 precision:  0.887029270146\n",
      "class 1 recall:     0.921739110397\n",
      "class 1 f1:         0.904046155301\n",
      "\n",
      "class 2 precision:  0.990632295301\n",
      "class 2 recall:     0.988317733918\n",
      "class 2 f1:         0.989468661097\n",
      "\n",
      "class 3 precision:  0.995555533432\n",
      "class 3 recall:     0.993348093274\n",
      "class 3 f1:         0.99444558839\n",
      "\n",
      "\n",
      "   Iteration:  35600\n",
      "   Cost:  0.79542\n",
      "   TRAIN accuracy:  0.935\n",
      "\n",
      "\n",
      "   Iteration:  35800\n",
      "   Cost:  0.803931\n",
      "   TRAIN accuracy:  0.9275\n",
      "\n",
      "Epoch:  44\n",
      "Epoch cost average:  0.791715\n",
      "Epoch TRAIN accuracy:  0.941\n",
      "\n",
      "   Iteration:  36000\n",
      "   Cost:  0.779745\n",
      "   TRAIN accuracy:  0.9625\n",
      "\n",
      "TEST accuracy:          0.948863636364\n",
      "\n",
      "class 0 precision:  0.959999976\n",
      "class 0 recall:     0.847682100493\n",
      "class 0 f1:         0.900346698103\n",
      "\n",
      "class 1 precision:  0.856837588529\n",
      "class 1 recall:     0.963942284521\n",
      "class 1 f1:         0.907234815807\n",
      "\n",
      "class 2 precision:  0.995381039368\n",
      "class 2 recall:     0.988532087419\n",
      "class 2 f1:         0.991939741352\n",
      "\n",
      "class 3 precision:  0.989106732263\n",
      "class 3 recall:     0.997802175872\n",
      "class 3 f1:         0.99343042696\n",
      "\n",
      "\n",
      "   Iteration:  36200\n",
      "   Cost:  0.80769\n",
      "   TRAIN accuracy:  0.9325\n",
      "\n",
      "\n",
      "   Iteration:  36400\n",
      "   Cost:  0.798633\n",
      "   TRAIN accuracy:  0.9425\n",
      "\n",
      "TEST accuracy:          0.9375\n",
      "\n",
      "class 0 precision:  0.907582916882\n",
      "class 0 recall:     0.858744375364\n",
      "class 0 f1:         0.88248346278\n",
      "\n",
      "class 1 precision:  0.858426947002\n",
      "class 1 recall:     0.913875576223\n",
      "class 1 f1:         0.885278877801\n",
      "\n",
      "class 2 precision:  0.981395326014\n",
      "class 2 recall:     0.988290374981\n",
      "class 2 f1:         0.984825782238\n",
      "\n",
      "class 3 precision:  0.999999978402\n",
      "class 3 recall:     0.987206801979\n",
      "class 3 f1:         0.993557210671\n",
      "\n",
      "\n",
      "   Iteration:  36600\n",
      "   Cost:  0.78636\n",
      "   TRAIN accuracy:  0.9525\n",
      "\n",
      "Epoch:  45\n",
      "Epoch cost average:  0.785842\n",
      "Epoch TRAIN accuracy:  0.953\n",
      "\n",
      "   Iteration:  36800\n",
      "   Cost:  0.770893\n",
      "   TRAIN accuracy:  0.9725\n",
      "\n",
      "\n",
      "   Iteration:  37000\n",
      "   Cost:  0.797921\n",
      "   TRAIN accuracy:  0.94\n",
      "\n",
      "TEST accuracy:          0.936931818182\n",
      "\n",
      "class 0 precision:  0.889411743779\n",
      "class 0 recall:     0.864988538559\n",
      "class 0 f1:         0.877025143062\n",
      "\n",
      "class 1 precision:  0.880434763469\n",
      "class 1 recall:     0.896017679292\n",
      "class 1 f1:         0.888152875673\n",
      "\n",
      "class 2 precision:  0.980306324282\n",
      "class 2 recall:     0.999999977679\n",
      "class 2 f1:         0.990050227259\n",
      "\n",
      "class 3 precision:  0.999999976077\n",
      "class 3 recall:     0.98817964567\n",
      "class 3 f1:         0.994049673352\n",
      "\n",
      "\n",
      "   Iteration:  37200\n",
      "   Cost:  0.791328\n",
      "   TRAIN accuracy:  0.9475\n",
      "\n",
      "\n",
      "   Iteration:  37400\n",
      "   Cost:  0.780529\n",
      "   TRAIN accuracy:  0.9625\n",
      "\n",
      "Epoch:  46\n",
      "Epoch cost average:  0.786342\n",
      "Epoch TRAIN accuracy:  0.954\n",
      "TEST accuracy:          0.943181818182\n",
      "\n",
      "class 0 precision:  0.936507911733\n",
      "class 0 recall:     0.832941156872\n",
      "class 0 f1:         0.881688644014\n",
      "\n",
      "class 1 precision:  0.861328108177\n",
      "class 1 recall:     0.946351911022\n",
      "class 1 f1:         0.901835483444\n",
      "\n",
      "class 2 precision:  0.990929682745\n",
      "class 2 recall:     0.995444168669\n",
      "class 2 f1:         0.993176795661\n",
      "\n",
      "class 3 precision:  0.997668974413\n",
      "class 3 recall:     0.995348814062\n",
      "class 3 f1:         0.996502543769\n",
      "\n",
      "\n",
      "   Iteration:  37600\n",
      "   Cost:  0.773255\n",
      "   TRAIN accuracy:  0.965\n",
      "\n",
      "\n",
      "   Iteration:  37800\n",
      "   Cost:  0.771991\n",
      "   TRAIN accuracy:  0.9725\n",
      "\n",
      "\n",
      "   Iteration:  38000\n",
      "   Cost:  0.787577\n",
      "   TRAIN accuracy:  0.955\n",
      "\n",
      "TEST accuracy:          0.943181818182\n",
      "\n",
      "class 0 precision:  0.895833312596\n",
      "class 0 recall:     0.885583503762\n",
      "class 0 f1:         0.890673921007\n",
      "\n",
      "class 1 precision:  0.901287534307\n",
      "class 1 recall:     0.919037179015\n",
      "class 1 f1:         0.910070820436\n",
      "\n",
      "class 2 precision:  0.981481458762\n",
      "class 2 recall:     0.979214757986\n",
      "class 2 f1:         0.980341798174\n",
      "\n",
      "class 3 precision:  0.997674395403\n",
      "class 3 recall:     0.99076210183\n",
      "class 3 f1:         0.994201234287\n",
      "\n",
      "\n",
      "   Iteration:  38200\n",
      "   Cost:  0.789885\n",
      "   TRAIN accuracy:  0.95\n",
      "\n",
      "Epoch:  47\n",
      "Epoch cost average:  0.786008\n",
      "Epoch TRAIN accuracy:  0.952\n",
      "\n",
      "   Iteration:  38400\n",
      "   Cost:  0.759219\n",
      "   TRAIN accuracy:  0.9825\n",
      "\n",
      "TEST accuracy:          0.943181818182\n",
      "\n",
      "class 0 precision:  0.877358469874\n",
      "class 0 recall:     0.896385520569\n",
      "class 0 f1:         0.886764943708\n",
      "\n",
      "class 1 precision:  0.913348924746\n",
      "class 1 recall:     0.894495392328\n",
      "class 1 f1:         0.903818849846\n",
      "\n",
      "class 2 precision:  0.977375543498\n",
      "class 2 recall:     0.984054647288\n",
      "class 2 f1:         0.980698723564\n",
      "\n",
      "class 3 precision:  0.997858651009\n",
      "class 3 recall:     0.991489340607\n",
      "class 3 f1:         0.99465879955\n",
      "\n",
      "\n",
      "   Iteration:  38600\n",
      "   Cost:  0.791877\n",
      "   TRAIN accuracy:  0.945\n",
      "\n",
      "\n",
      "   Iteration:  38800\n",
      "   Cost:  0.793291\n",
      "   TRAIN accuracy:  0.9525\n",
      "\n",
      "\n",
      "   Iteration:  39000\n",
      "   Cost:  0.807352\n",
      "   TRAIN accuracy:  0.9325\n",
      "\n",
      "TEST accuracy:          0.929545454545\n",
      "\n",
      "class 0 precision:  0.909348416166\n",
      "class 0 recall:     0.782926810173\n",
      "class 0 f1:         0.841410471147\n",
      "\n",
      "class 1 precision:  0.8299999834\n",
      "class 1 recall:     0.934684663633\n",
      "class 1 f1:         0.879232287131\n",
      "\n",
      "class 2 precision:  0.986143164292\n",
      "class 2 recall:     0.990719234554\n",
      "class 2 f1:         0.988420903098\n",
      "\n",
      "class 3 precision:  0.997890274306\n",
      "class 3 recall:     0.99578945272\n",
      "class 3 f1:         0.996833756683\n",
      "\n",
      "Epoch:  48\n",
      "Epoch cost average:  0.790979\n",
      "Epoch TRAIN accuracy:  0.949\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-97411e751d74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mtargetsMinibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingTargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mcostfun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifierTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msessionsMinibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetsMinibatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mcostCollect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcostfun\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/bradh/.theano/compiledir_Linux-4.2--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/scan_perform/mod.cpp:4193)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hexSessionsKeys = hexSessions.keys()\n",
    "trainIndex = int(len(hexSessionsKeys)*trainPercent)\n",
    "#random.shuffle(hexSessionsKeys) #not needed because of time orientation of data?\n",
    "\n",
    "epochCost = []\n",
    "gradNorms = []\n",
    "trainAcc = []\n",
    "testAcc = []\n",
    "\n",
    "#normalTarget = np.array([0,1], dtype=theano.config.floatX)\n",
    "#abbyTarget = np.array([1,0], dtype=theano.config.floatX)\n",
    "costCollect = []\n",
    "trainCollect = []\n",
    "\n",
    "iteration = 0\n",
    "#epoch\n",
    "for epoch in xrange(epochs):\n",
    "\n",
    "    #iteration/minibatch\n",
    "    for start, end in zip(range(0, trainIndex,batch_sizeClass),\n",
    "                          range(batch_sizeClass, trainIndex, batch_sizeClass)):\n",
    "        \n",
    "        trainingTargets = []\n",
    "        trainingSessions = []\n",
    "        \n",
    "        #create one minibatch with 0.5 normal and 0.5 abby normal traffic\n",
    "        for trainKey in range(start, end):\n",
    "            sessionForEncoding = list(hexSessions[hexSessions.keys()[trainKey]])\n",
    "            \n",
    "            #encode a normal session\n",
    "            #oneHotSes = oneSessionEncoder(sessionForEncoding,hexDict = hexDict, packetReverse=packetReverse, \n",
    "            #                              padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets,\n",
    "            #                              packetTimeSteps = packetTimeSteps)\n",
    "            #trainingSessions.append(oneHotSes[0])\n",
    "            #trainingTargets.append(normalTarget)\n",
    "            \n",
    "            #encode an abby normal session\n",
    "            adversaryList = [sessionForEncoding, \n",
    "                             dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs), \n",
    "                             portDirSwitcher(sessionForEncoding), \n",
    "                             ipDirSwitcher(sessionForEncoding)]\n",
    "            abbyIndex = random.sample(range(len(adversaryList)), 1)[0]\n",
    "            #abbyHexSession = random.sample(range(len(adversaryList), 1)[0]\n",
    "            #abbyHexSession = ipDirSwitcher(sessionForEncoding)\n",
    "            #abbyHexSession = dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs)\n",
    "            #abbyHexSession = portDirSwitcher(sessionForEncoding)\n",
    "            abbyOneHotSes = oneSessionEncoder(adversaryList[abbyIndex],\n",
    "                                              hexDict = hexDict,\n",
    "                                              packetReverse=packetReverse, \n",
    "                                              padOldTimeSteps = padOldTimeSteps, \n",
    "                                              maxPackets = maxPackets, \n",
    "                                              packetTimeSteps = packetTimeSteps)\n",
    "            \n",
    "            targetClasses = [0]*numClasses\n",
    "            targetClasses[abbyIndex] = 1\n",
    "            abbyTarget = np.array(targetClasses, dtype=theano.config.floatX)\n",
    "            trainingSessions.append(abbyOneHotSes[0])\n",
    "            trainingTargets.append(abbyTarget)\n",
    "            \n",
    "        sessionsMinibatch = np.asarray(trainingSessions).reshape((batch_sizeClass*maxPackets, packetTimeSteps, 1, dimIn))\n",
    "        targetsMinibatch = np.asarray(trainingTargets)\n",
    "    \n",
    "        costfun = classifierTrain(sessionsMinibatch, targetsMinibatch)\n",
    "        \n",
    "        costCollect.append(costfun[0])\n",
    "        trainCollect.append(np.mean(np.argmax(costfun[-1],axis=1) == np.argmax(targetsMinibatch, axis=1)))\n",
    "\n",
    "        iteration+=1\n",
    "        \n",
    "        if iteration == 1:\n",
    "            print 'you are amazing'\n",
    "             \n",
    "        \n",
    "        if iteration%200 == 0:\n",
    "            print\n",
    "            print '   Iteration: ', iteration\n",
    "            print '   Cost: ', np.mean(costCollect[-20:])\n",
    "            print '   TRAIN accuracy: ', np.mean(trainCollect[-20:])\n",
    "            print\n",
    "            \n",
    "            \n",
    "            #print costfun[-1]\n",
    "            #grads = gradientFun(sessionsMinibatch, targetsMinibatch)\n",
    "            #for gra in grads:\n",
    "            #    print '  gradient norms: ', np.linalg.norm(gra)\n",
    "            np.savetxt('/data/fs4/home/bradh/outputs/'+runname+\"_TRAIN.csv\", trainCollect[::50], delimiter=\",\")\n",
    "            np.savetxt('/data/fs4/home/bradh/outputs/'+runname+\"_COST.csv\", costCollect[::50], delimiter=\",\")\n",
    "\n",
    "        #testing accuracy\n",
    "        if iteration%500 == 0:\n",
    "            predtar, acttar, testCollect = predictClass(classifierPredict, hexSessions, comsDict, uniqIPs, hexDict,\n",
    "                                                     numClasses, trainPercent, dimIn, maxPackets, packetTimeSteps,\n",
    "                                                     padOldTimeSteps, batch_sizeClass)\n",
    "            \n",
    "            binaryPrecisionRecall(predtar, acttar)\n",
    "            \n",
    "            testAcc.append(testCollect)\n",
    "            np.savetxt('/data/fs4/home/bradh/outputs/'+runname+\"_TEST.csv\", testAcc, delimiter=\",\")\n",
    "            \n",
    "        #save the models\n",
    "        if iteration%1500 == 0:\n",
    "            pickleModel(classifierTrain, filePath='/data/fs4/home/bradh/outputs/',\n",
    "                        fileName=runname+'TRAIN'+str(iteration))\n",
    "            pickleModel(classifierPredict, filePath='/data/fs4/home/bradh/outputs/',\n",
    "                        fileName=runname+'PREDICT'+str(iteration))\n",
    "    \n",
    "    epochCost.append(np.mean(costCollect[-50:]))\n",
    "    trainAcc.append(np.mean(trainCollect[-50:]))\n",
    "    print 'Epoch: ', epoch\n",
    "    print 'Epoch cost average: ', epochCost[-1]\n",
    "    print 'Epoch TRAIN accuracy: ', trainAcc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierPredict = loadModel('/data/fs4/home/bradh/outputs/hredClassify4FullPacketsPREDICT61500.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST accuracy:          0.942045454545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predtar, acttar, acc  = predictClass(classifierPredict, hexSessions, comsDict, uniqIPs, hexDict,\n",
    "                               numClasses, trainPercent, dimIn, maxPackets, packetTimeSteps,\n",
    "                               padOldTimeSteps, batch_sizeClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 precision:  0.951156787888\n",
      "class 0 recall:     0.833333314565\n",
      "class 0 f1:         0.888350342633\n",
      "\n",
      "class 1 precision:  0.846481858284\n",
      "class 1 recall:     0.945238072732\n",
      "class 1 f1:         0.89313335283\n",
      "\n",
      "class 2 precision:  0.99295772317\n",
      "class 2 recall:     0.99295772317\n",
      "class 2 f1:         0.992952723195\n",
      "\n",
      "class 3 precision:  0.983193256656\n",
      "class 3 recall:     0.995744659665\n",
      "class 3 f1:         0.989424154784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binaryPrecisionRecall(predtar, acttar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def oneSessionTokenized(sessionDict, hexDict, packetTimeSteps=50):\n",
    "\n",
    "    dstMac = []\n",
    "    srcMac = []\n",
    "    firstType = []\n",
    "    ihl = []\n",
    "    tos = []\n",
    "    firLen = []\n",
    "    firId = []\n",
    "    frag = []\n",
    "    ttl = []\n",
    "    protocol = []\n",
    "    firCheck = []\n",
    "    srcip = []\n",
    "    dstip = []\n",
    "    sport = []\n",
    "    dport = []\n",
    "    \n",
    "    i=0\n",
    "    for key in sessionDict.keys():\n",
    "        sessionPackets = sessionDict[key]\n",
    "        \n",
    "        #if len(sessionPackets) > maxPackets: #crop the number of sessions to maxPackets\n",
    "        #    sessionList = sessionPackets[:maxPackets]\n",
    "        #else:\n",
    "        #    sessionList = sessionPackets\n",
    "\n",
    "        for packet in sessionPackets:\n",
    "            \n",
    "            dstMac.append(packet[0:12]) \n",
    "            srcMac.append(packet[12:24]) \n",
    "            firstType.append(packet[24:28])\n",
    "            ihl.append(packet[28:30]) \n",
    "            tos.append(packet[30:32])\n",
    "            firLen.append(packet[32:36])\n",
    "            firId.append(packet[36:40]) \n",
    "            frag.append(packet[40:44]) \n",
    "            ttl.append(packet[44:46])\n",
    "            protocol.append(packet[46:48])\n",
    "            firCheck.append(packet[48:52]) \n",
    "            srcip.append(packet[52:60])\n",
    "            dstip.append(packet[60:68])\n",
    "            sport.append(packet[68:72])\n",
    "            dport.append(packet[72:76])\n",
    "            \n",
    "            i+=1\n",
    "    print i\n",
    "    return np.asarray(dstMac), np.asarray(srcMac),np.asarray(firstType),np.asarray(ihl),np.asarray(tos),\\\n",
    "           np.asarray(firLen),np.asarray(firId),np.asarray(frag),np.asarray(ttl),np.asarray(protocol),\\\n",
    "           np.asarray(firCheck),np.asarray(srcip),np.asarray(dstip), np.asarray(sport), np.asarray(dport)\n",
    "\n",
    "netstats  = oneSessionTokenized(hexSessions, hexDict)\n",
    "\n",
    "indx = ['dstMac', 'srcMac', 'firstType', 'ihl', 'tos', 'firLen', 'firId', 'frag', 'ttl', 'protocol', 'firCheck',\n",
    "       'srcip', 'dstip', 'sport', 'dport']\n",
    "for num in range(len(indx)):\n",
    "    print indx[num], len(np.unique(netstats[num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "packet = hexSessions[hexSessions.keys()[1]][1]\n",
    "\n",
    "coll = []\n",
    "for key in hexSessions.keys():\n",
    "    sessionPackets = hexSessions[key]\n",
    "    for packet in sessionPackets:\n",
    "        coll.append(packet[32:36]+packet[44:46]+packet[46:48]+packet[52:60]+packet[60:68]+packet[68:70]+packet[70:72]+\n",
    "                   packet[72:74])\n",
    "\n",
    "np.unique(coll).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#turns the sessions into a dictionary key = session_number, val = list of packages in hex\n",
    "minPackets = 3\n",
    "\n",
    "def hexSessionDictCreator(scapySessions, minPackets = 2):\n",
    "\n",
    "    hexSessions = OrderedDict()\n",
    "    i=0\n",
    "    for k,v in sessionPrep.items(): # v is the session\n",
    "        \n",
    "        if len(v) < minPackets:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            scpcaps = []    \n",
    "            \n",
    "            for p in v: #p is the individual packet in the session  \n",
    "                \n",
    "                try: #getting rid of payload\n",
    "                    rawindex = len(p[Raw]) \n",
    "                    #payloadLens.append(rawindex)\n",
    "                    scpcaps.append(binascii.hexlify(str(p.original)[:-rawindex])) #turn it into hex\n",
    "                \n",
    "                except: #if no payload\n",
    "                    scpcaps.append(binascii.hexlify(str(p.original)))\n",
    "    \n",
    "            hexSessions['session_' + str(i)] = scpcaps\n",
    "            i+=1\n",
    "    #assert that all sessions have len of at least minPackets\n",
    "    return hexSessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "hexSessionstest = hexSessionDictCreator(sessionPrep, minPackets=minPackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adversaryList = [dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs), portDirSwitcher(sessionForEncoding), \n",
    "                 ipDirSwitcher(sessionForEncoding)]\n",
    "\n",
    "abbyHexSession = random.sample(adversaryList, 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testing for generalization\n",
    "\n",
    "testCollect = []\n",
    "for start, end in zip(range(trainIndex, len(hexSessionsKeys), batch_sizeClass/2),\n",
    "                      range(trainIndex + batch_sizeClass/2, len(hexSessionsKeys), batch_sizeClass/2)):\n",
    "    trainingTargets = []\n",
    "    trainingSessions = []\n",
    "    for trainKey in range(start, end):\n",
    "        sessionForEncoding = hexSessions[hexSessions.keys()[trainKey]]\n",
    "\n",
    "        #encode a normal session\n",
    "        oneHotSes = oneSessionEncoder(sessionForEncoding,hexDict = hexDict, packetReverse=packetReverse, \n",
    "                                      padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets,\n",
    "                                      packetTimeSteps = packetTimeSteps)\n",
    "        trainingSessions.append(oneHotSes[0])\n",
    "        trainingTargets.append(normalTarget)\n",
    "\n",
    "        #encode an abby normal session\n",
    "        abbyHexSession = dstIpSwapOut(sessionForEncoding, comsDict, uniqIPs) #95%, 88%\n",
    "        #abbyHexSession = ipDirSwitcher(sessionForEncoding) #96%, 98%\n",
    "        #abbyHexSession = portDirSwitcher(sessionForEncoding) #96%, 98%\n",
    "        abbyOneHotSes = oneSessionEncoder(abbyHexSession,hexDict = hexDict,packetReverse=packetReverse, \n",
    "                                          padOldTimeSteps = padOldTimeSteps, maxPackets = maxPackets, \n",
    "                                          packetTimeSteps = packetTimeSteps)\n",
    "        trainingSessions.append(abbyOneHotSes[0])\n",
    "        trainingTargets.append(abbyTarget)\n",
    "\n",
    "    #trainingSessions = [item for sublist in trainingSessions for item in sublist] #FIX in oneSessionEncoder\n",
    "    sessionsMinibatch = np.asarray(trainingSessions, dtype=theano.config.floatX)\\\n",
    "                                   .reshape((batch_sizeClass*maxPackets, packetTimeSteps, 1, 257))\n",
    "    targetsMinibatch = np.asarray(trainingTargets, dtype=theano.config.floatX)\n",
    "\n",
    "    predcostfun = classifierPredict(sessionsMinibatch)\n",
    "    testCollect.append(np.mean(np.argmax(predcostfun, axis=1) == targetsMinibatch[:,1]))\n",
    "\n",
    "print 'test accuracy: ', np.mean(testCollect)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
