{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how data are represented at each level (forward, backward, forward with padding on top) needs a little\n",
    "    #experimentation to determine the best representation\n",
    "    #also, is encoding at each layer really the best way? or just feeding the raw through?\n",
    "    \n",
    "#Outside web ips are going to be a problem/messy/noisy. Start by categorizing all outside ips by <OUTSIDE_IP>\n",
    "    #instead of the ip address, or another 4 digit symbol to insert into the hex string.\n",
    "    \n",
    "#to help the models generalize more, for a given source ip address with probability p (say p = 0.1) \n",
    "    #use the token <OTHER_MACHINE>\n",
    "    \n",
    "#should we remove random parts of the header, i.e. checksum\n",
    "\n",
    "#should I take out bias for RNNs?\n",
    "\n",
    "#for the decoder,does the fork encoding need to happen ?\n",
    "    #do we simply cat the hContext with the next words?\n",
    "    \n",
    "#Should the architecture just be encode, context and then prediction???\n",
    "\n",
    "#Input data, should it have character and hex pair encoding as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to execute tcpdump. Check it is installed and in the PATH\n",
      "WARNING: No route found for IPv6 destination :: (no default route?)\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=gpu,optimizer=fast_compile'\n",
    "\n",
    "import sys\n",
    "import binascii\n",
    "import multiprocessing as mp\n",
    "from itertools import chain\n",
    "from scapy.all import *\n",
    "sys.path.append('hed-dlg/')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import itemfreq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import blocks\n",
    "from blocks.bricks import Linear, Softmax, Softplus, NDimensionalSoftmax, BatchNormalizedMLP, \\\n",
    "                                Rectifier, Logistic, Tanh, MLP\n",
    "from blocks.bricks.recurrent import GatedRecurrent, Fork, LSTM\n",
    "from blocks.initialization import Constant, IsotropicGaussian, Identity, Uniform\n",
    "from blocks.bricks.cost import BinaryCrossEntropy, CategoricalCrossEntropy\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.roles import PARAMETER\n",
    "from blocks.graph import ComputationGraph\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "###These warnings do not impede progress\n",
    "#WARNING: Failed to execute tcpdump. Check it is installed and in the PATH\n",
    "#WARNING: No route found for IPv6 destination :: (no default route?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPath = '/data/fs4/datasets/pcaps/smallFlows.pcap'\n",
    "pcaps = rdpcap(dataPath)\n",
    "sessionPrep = pcaps.sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ipComs(listOsessions, hexOut = False):\n",
    "    '''\n",
    "    takes scapy sessions\n",
    "    \n",
    "    returns a dictionary of source ips and the ips they talk to, and a list of \n",
    "    all of the unique ip addresses in the data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ipAddressDict = {}\n",
    "    uniqIPs = []\n",
    "    \n",
    "    for k,v in listOsessions.items():\n",
    "        for p in v:\n",
    "            sourceIP = p.payload.fields['src']\n",
    "            destIP = p.payload.fields['dst']\n",
    "            \n",
    "            #if source ip is not in dictionary, then add it with dest ip as list\n",
    "            if sourceIP not in ipAddressDict:\n",
    "                ipAddressDict[sourceIP] = [destIP]\n",
    "            \n",
    "            else:\n",
    "                ipAddressDict[sourceIP] = list(set(ipAddressDict[sourceIP]) | set([destIP]))\n",
    "            \n",
    "            uniqIPs = list(set(uniqIPs) | set([destIP, sourceIP]))\n",
    "            \n",
    "    return ipAddressDict, uniqIPs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sessionDict, uniqips = ipComs(sessionPrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneIpDirSwitcher(normHexSessionList):\n",
    "    '''\n",
    "    input is a list of packets from ONE session\n",
    "    '''\n",
    "    \n",
    "    session = []\n",
    "        \n",
    "    for p in normHexSessionList:\n",
    "        sourceIP = p[52:60]\n",
    "        destIP = p[60:68]\n",
    "\n",
    "        session.append(p[:52]+destIP+sourceIP+p[68:])\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ipDirectionSwitcher(hexSessionsDict):\n",
    "    '''\n",
    "    input is a dictionary of many sessions\n",
    "    '''\n",
    "    badSessions = {}\n",
    "    \n",
    "    for k in hexSessionsDict.keys():\n",
    "        \n",
    "        session = oneIpDirSwitcher(k)\n",
    "        \n",
    "        badSessions[k] = session\n",
    "            \n",
    "    return badSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#turns the sessions into a dictionary key = session_number, val = list of packages in hex\n",
    "\n",
    "i=0\n",
    "hexSessions = {}\n",
    "\n",
    "for k,v in sessionPrep.items(): # v is the session\n",
    "    #for attr, value in v.__dict__.iteritems(): THIS IS TO GET DICT OF VALUES\n",
    "    #    print attr, value\n",
    "    #if i == 2:\n",
    "    #    break\n",
    "    scpcaps = []    \n",
    "    for p in v: #p is the individual packet in the session\n",
    "        \n",
    "        try:\n",
    "            rawindex = len(p[Raw])\n",
    "            payloadLens.append(rawindex)\n",
    "            scpcaps.append(binascii.hexlify(str(p.original)[:-rawindex])) #turn it into hex\n",
    "        except:\n",
    "            scpcaps.append(binascii.hexlify(p.original))\n",
    "        #for attr, value in p.payload.__dict__.iteritems():#this give the fields that are accessable\n",
    "        #    print attr, value\n",
    "        \n",
    "        #print len(binascii.hexlify(p.original))\n",
    "    hexSessions['session_' + str(i)] = scpcaps\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making the hex dictionary\n",
    "hexstring = '0,\t1,\t2,\t3,\t4,\t5,\t6,\t7,\t8,\t9,\tA,\tB,\tC,\tD,\tE,\tF,\t10,\t11,\t12,\t13,\t14,\t15,\t16,\t17,\t18,\t19\\\n",
    ",\t1A,\t1B,\t1C,\t1D,\t1E,\t1F,\t20,\t21,\t22,\t23,\t24,\t25,\t26,\t27,\t28,\t29,\t2A,\t2B,\t2C,\t2D,\t2E,\t2F,\t30,\t31,\t32,\t33,\t34,\t35\\\n",
    ",\t36,\t37,\t38,\t39,\t3A,\t3B,\t3C,\t3D,\t3E,\t3F,\t40,\t41,\t42,\t43,\t44,\t45,\t46,\t47,\t48,\t49,\t4A,\t4B,\t4C,\t4D,\t4E,\t4F,\t50,\t51\\\n",
    ",\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t5A,\t5B,\t5C,\t5D,\t5E,\t5F,\t60,\t61,\t62,\t63,\t64,\t65,\t66,\t67,\t68,\t69,\t6A,\t6B,\t6C,\t6D\\\n",
    ",\t6E,\t6F,\t70,\t71,\t72,\t73,\t74,\t75,\t76,\t77,\t78,\t79,\t7A,\t7B,\t7C,\t7D,\t7E,\t7F,\t80,\t81,\t82,\t83,\t84,\t85,\t86,\t87,\t88,\t89\\\n",
    ",\t8A,\t8B,\t8C,\t8D,\t8E,\t8F,\t90,\t91,\t92,\t93,\t94,\t95,\t96,\t97,\t98,\t99,\t9A,\t9B,\t9C,\t9D,\t9E,\t9F,\tA0,\tA1,\tA2,\tA3,\tA4,\tA5\\\n",
    ",\tA6,\tA7,\tA8,\tA9,\tAA,\tAB,\tAC,\tAD,\tAE,\tAF,\tB0,\tB1,\tB2,\tB3,\tB4,\tB5,\tB6,\tB7,\tB8,\tB9,\tBA,\tBB,\tBC,\tBD,\tBE,\tBF,\tC0,\tC1\\\n",
    ",\tC2,\tC3,\tC4,\tC5,\tC6,\tC7,\tC8,\tC9,\tCA,\tCB,\tCC,\tCD,\tCE,\tCF,\tD0,\tD1,\tD2,\tD3,\tD4,\tD5,\tD6,\tD7,\tD8,\tD9,\tDA,\tDB,\tDC,\tDD\\\n",
    ",\tDE,\tDF,\tE0,\tE1,\tE2,\tE3,\tE4,\tE5,\tE6,\tE7,\tE8,\tE9,\tEA,\tEB,\tEC,\tED,\tEE,\tEF,\tF0,\tF1,\tF2,\tF3,\tF4,\tF5,\tF6,\tF7,\tF8,\tF9\\\n",
    ",\tFA,\tFB,\tFC,\tFD,\tFE,\tFF'.replace('\\t', '')\n",
    "\n",
    "hexList = hexstring.lower().split(',')\n",
    "hexList.append('<EOP>') #End Of Packet token\n",
    "hexDict = {}\n",
    "    \n",
    "for key, val in enumerate(hexList):\n",
    "    if len(val) == 1:\n",
    "        val = '0'+val\n",
    "    hexDict[val] = key  #dictionary k=hex, v=int  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHot(index, granular = 'hex'):\n",
    "    if granular == 'hex':\n",
    "        vecLen = 257\n",
    "    else:\n",
    "        vecLen = 17\n",
    "    \n",
    "    zeroVec = np.zeros(vecLen)\n",
    "    zeroVec[index] = 1.0\n",
    "    \n",
    "    return zeroVec\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxPackets = 2\n",
    "packetTimeSteps = 66\n",
    "def oneSessionEncoder(sessionPackets, hexDict, maxPackets, packetTimeSteps,\n",
    "                       packetReverse = True, charLevel = False, padOldTimeSteps = True):    \n",
    "            \n",
    "    sessionCollect = []\n",
    "    \n",
    "    if charLevel:\n",
    "        vecLen = 17\n",
    "    else:\n",
    "        vecLen = 257\n",
    "    \n",
    "    if len(sessionPackets) > maxPackets: #crop the number of sessions to maxPackets\n",
    "        sessionList = sessionPackets[:maxPackets]\n",
    "    else:\n",
    "        sessionList = sessionPackets\n",
    "\n",
    "    for packet in sessionList:\n",
    "        packet = [hexDict[packet[i:i+2]] for i in xrange(0,len(packet)-2+1,2)]\n",
    "\n",
    "        if len(packet) >= packetTimeSteps: #crop packet to length packetTimeSteps\n",
    "            packet = packet[:packetTimeSteps-1]\n",
    "\n",
    "        packet = packet+[256] #add <EOP> end of packet token\n",
    "\n",
    "        pacMat = np.array([oneHot(x) for x in packet]) #one hot encoding of packet into a matrix\n",
    "        pacMatLen = len(pacMat)\n",
    "        \n",
    "        #padding packet\n",
    "        if packetReverse:\n",
    "            pacMat = pacMat[::-1]\n",
    "\n",
    "        if pacMatLen < packetTimeSteps:\n",
    "            #pad by stacking zeros on top of data so that earlier timesteps do not have information\n",
    "            #padding the packet such that zeros are after the actual info for better translation\n",
    "            if padOldTimeSteps:\n",
    "                pacMat = np.vstack( ( np.zeros((packetTimeSteps-pacMatLen,vecLen)), pacMat) ) \n",
    "            else:\n",
    "                pacMat = np.vstack( (pacMat, np.zeros((packetTimeSteps-pacMatLen,vecLen))) ) \n",
    "\n",
    "        if pacMatLen > packetTimeSteps:\n",
    "            pacMat = pacMat[:packetTimeSteps, :]\n",
    "\n",
    "        sessionCollect.append(pacMat)\n",
    "\n",
    "    #padding session\n",
    "    sessionCollect = np.asarray(sessionCollect, dtype=theano.config.floatX)\n",
    "    numPacketsInSession = sessionCollect.shape[0]\n",
    "    if numPacketsInSession < maxPackets:\n",
    "        #pad sessions to fit the \n",
    "        sessionCollect = np.vstack( (sessionCollect,np.zeros((maxPackets-numPacketsInSession, \n",
    "                                                             packetTimeSteps, vecLen))) )\n",
    "    return sessionCollect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hexKeys = hexSessions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hexLens = []\n",
    "pacLens = []\n",
    "for key in hexKeys:\n",
    "    hexLens.append(len(hexSessions[key]))\n",
    "    for pac in hexSessions[key]:\n",
    "        pacLens.append(len(pac)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14261"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pacLens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "#input is a 4d tensor (numMiniBatch, session, packetRow, packetCol)\n",
    "sessions = oneHotSessions(hexSessions)\n",
    "#badSessions = oneHotSessions(badHexSessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p != 0:\n",
    "        retain_prob = 1 - p\n",
    "        X = X / retain_prob * srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "    return X\n",
    "\n",
    "# Gradient clipping\n",
    "def clip_norm(g, c, n): \n",
    "    '''n is the norm, c is the threashold, and g is the gradient'''\n",
    "    \n",
    "    if c > 0: \n",
    "        g = T.switch(T.ge(n, c), g*c/n, g) \n",
    "    return g\n",
    "\n",
    "def clip_norms(gs, c):\n",
    "    norm = T.sqrt(sum([T.sum(g**2) for g in gs]))\n",
    "    return [clip_norm(g, c, norm) for g in gs]\n",
    "\n",
    "# Regularizers\n",
    "def max_norm(p, maxnorm = 0.):\n",
    "    if maxnorm > 0:\n",
    "        norms = T.sqrt(T.sum(T.sqr(p), axis=0))\n",
    "        desired = T.clip(norms, 0, maxnorm)\n",
    "        p = p * (desired/ (1e-7 + norms))\n",
    "    return p\n",
    "\n",
    "def gradient_regularize(p, g, l1 = 0., l2 = 0.):\n",
    "    g += p * l2\n",
    "    g += T.sgn(p) * l1\n",
    "    return g\n",
    "\n",
    "def weight_regularize(p, maxnorm = 0.):\n",
    "    p = max_norm(p, maxnorm)\n",
    "    return p\n",
    "\n",
    "def Adam(params, cost, lr=0.0002, b1=0.1, b2=0.001, e=1e-8, l1 = 0., l2 = 0., maxnorm = 0., c = 8):\n",
    "    \n",
    "    updates = []\n",
    "    grads = T.grad(cost, params)\n",
    "    grads = clip_norms(grads, c)\n",
    "    \n",
    "    i = theano.shared(floatX(0.))\n",
    "    i_t = i + 1.\n",
    "    fix1 = 1. - b1**(i_t)\n",
    "    fix2 = 1. - b2**(i_t)\n",
    "    lr_t = lr * (T.sqrt(fix2) / fix1)\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        m = theano.shared(p.get_value() * 0.)\n",
    "        v = theano.shared(p.get_value() * 0.)\n",
    "        m_t = (b1 * g) + ((1. - b1) * m)\n",
    "        v_t = (b2 * T.sqr(g)) + ((1. - b2) * v)\n",
    "        g_t = m_t / (T.sqrt(v_t) + e)\n",
    "        g_t = gradient_regularize(p, g_t, l1=l1, l2=l2)\n",
    "        p_t = p - (lr_t * g_t)\n",
    "        p_t = weight_regularize(p_t, maxnorm=maxnorm)\n",
    "        \n",
    "        updates.append((m, m_t))\n",
    "        updates.append((v, v_t))\n",
    "        updates.append((p, p_t))\n",
    "    \n",
    "    updates.append((i, i_t))\n",
    "    return updates\n",
    "\n",
    "def RMSprop(cost, params, lr = 0.001, l1 = 0., l2 = 0., maxnorm = 0., rho=0.9, epsilon=1e-6, c = 8):\n",
    "    \n",
    "    grads = T.grad(cost, params)\n",
    "    grads = clip_norms(grads, c)\n",
    "    updates = []\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        g = gradient_regularize(p, g, l1 = l1, l2 = l2)\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        updates.append((acc, acc_new))\n",
    "        \n",
    "        updated_p = p - lr * (g / T.sqrt(acc_new + epsilon))\n",
    "        updated_p = weight_regularize(updated_p, maxnorm = maxnorm)\n",
    "        updates.append((p, updated_p))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#makes output by shifting inputs down in time one step and then copying the last time step to the end.\n",
    "#def targetModifier(targetArray):\n",
    "#    newTarget = np.vstack((targetArray[1:, :], targetArray[-1,:]))\n",
    "#    return newTarget\n",
    "\n",
    "#def targetMaker(listOinputs):\n",
    "    #TODO: do this with arrays\n",
    "#    outputs = []\n",
    "#    for inp in listOinputs:\n",
    "#        outputs.append(targetModifier(inp))\n",
    "#    outputs = np.asarray(outputs)\n",
    "#    \n",
    "#    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4('inputs')\n",
    "Y = T.matrix('targets')\n",
    "\n",
    "dimIn = 257 #hex has 256 characters + the <EOP> character\n",
    "dim = 128 #dimension reduction size\n",
    "rnnType = 'lstm' #gru or lstm\n",
    "bidirectional = False\n",
    "linewt_init = Uniform(width=0.08)\n",
    "line_bias = Constant(0.0)\n",
    "rnnwt_init = IsotropicGaussian(0.08)\n",
    "rnnbias_init = Constant(0.0)\n",
    "packetReverse = False\n",
    "\n",
    "###ENCODER\n",
    "if rnnType == 'gru':\n",
    "    rnn = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "fork = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dimIn, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "\n",
    "###CONTEXT\n",
    "if rnnType == 'gru':\n",
    "    rnnContext = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                biases_init = rnnbias_init, name = 'gruContext')\n",
    "else:\n",
    "    rnnContext = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, \n",
    "                      name = 'lstmContext')\n",
    "\n",
    "forkContext = Fork(output_names=['linearContext', 'gatesContext'],\n",
    "            name='forkContext', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "if bidirectional:\n",
    "    dimDec = dim*2\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        rnnContextRev = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                       biases_init = rnnbias_init, name = 'gruContextRev')\n",
    "        \n",
    "    else:\n",
    "        rnnContextRev = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init,\n",
    "                             name = 'lstmContextRev')\n",
    "    \n",
    "    rnnContextRev.initialize()\n",
    "\n",
    "else:\n",
    "    dimDec = dim\n",
    "\n",
    "\n",
    "###DECODER\n",
    "if rnnType == 'gru':\n",
    "    rnnDec = GatedRecurrent(dim=dimIn, weights_init = rnnwt_init, \n",
    "                            biases_init = rnnbias_init, name = 'gruDecoder')\n",
    "else:\n",
    "    rnnDec = LSTM(dim=dimIn, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstmDecoder')\n",
    "\n",
    "\n",
    "forkDec = Fork(output_names=['linear', 'gates'],\n",
    "            name='forkDec', input_dim=dimDec, output_dims=[dim, dim*dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "forkFinal = Fork(output_names=['linear', 'gates'],\n",
    "            name='forkFinal', input_dim=dim, output_dims=[dimIn, dimIn*dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "#reduce dimension of bidirectLSTM\n",
    "\n",
    "fork.initialize()\n",
    "rnn.initialize()\n",
    "\n",
    "forkContext.initialize()\n",
    "rnnContext.initialize()\n",
    "\n",
    "forkDec.initialize()\n",
    "forkFinal.initialize()\n",
    "rnnDec.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "def oneStep(X):\n",
    "    ###ENCODER\n",
    "    i = 0\n",
    "    data1, data2 = fork.apply(X)\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hEnc = rnn.apply(data1, data2)[:,-1] #the [:,-1] gets the last hidden state for each obs in minibatch\n",
    "                                             #i.e. the last state for each sentence\n",
    "    else:\n",
    "        hinit, _ = rnn.apply(data2)\n",
    "        hEnc = hinit[:,-1]\n",
    "    \n",
    "    hEnc = T.reshape(hEnc,(maxPackets, 1, dim))\n",
    "    \n",
    "    data3, data4 = forkContext.apply(hEnc)\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        hContext = rnnContext.apply(data3, data4)\n",
    "    else:\n",
    "        hinitContext, _ = rnnContext.apply(data4)\n",
    "        hContext = hinitContext\n",
    "    \n",
    "    if bidirectional:\n",
    "        data3 = data3[::-1]\n",
    "        data4 = data4[::-1]\n",
    "        \n",
    "        if rnnType == 'gru':\n",
    "            hContextRev = rnnContextRev.apply(data3, data4)\n",
    "        else:\n",
    "            hinitContext, _ = rnnContextRev.apply(data4)\n",
    "            hContextRev = hinitContext\n",
    "        \n",
    "        hContext = T.concatenate((hContext, hContextRev), axis=2)\n",
    "            \n",
    "    data5, data6 = forkDec.apply(hContext)\n",
    "    \n",
    "    #decoding data needs to be one timestep (next packet in session) ahead, thus data1 we ignore the first packet\n",
    "    #and the last hidden state of the context RNN.\n",
    "    #Think about L2 pooling before cat\n",
    "    if packetReverse:\n",
    "        data1 = data1[:,::-1]\n",
    "        \n",
    "    data7 = T.concatenate((data5[:-1,:,:], data1[1:, :-1, :]), axis=1) #data1 is the original embedding of X\n",
    "\n",
    "    #data8 = T.concatenate((data7, data5), axis = 2)\n",
    "    data8, data9 = forkFinal.apply(data7)\n",
    "\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hDec = rnnDec.apply(data8, data9) \n",
    "    else:\n",
    "        hinit, _ = rnnDec.apply(data9)\n",
    "        hDec = hinit\n",
    "    \n",
    "    softmax = NDimensionalSoftmax()\n",
    "    softout = softmax.apply(hDec, extra_ndim = 1)\n",
    "\n",
    "    precost = X[1:, :, :]*np.log(softout) + (1-X[1:, :, :])*np.log(1-softout)\n",
    "    precost2 = -T.sum(T.sum(precost, axis = 2), axis = 1)\n",
    "    #precost2 = -T.mean(T.sum(T.sum(precost, axis = 2), axis = 1))\n",
    "    i+=1\n",
    "    #precost2 = BinaryCrossEntropy().apply(X[1:, :, :], softout)\n",
    "\n",
    "    #return data4\n",
    "    return precost2, softout, hContext, data5, data7, data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hContext, _ = theano.scan(fn = oneStep, sequences=[X])\n",
    "[scanOut, softout, hContext, data5, data7, data1], _ = theano.scan(fn = oneStep, sequences=[X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testCont = theano.function([X], [hContext, data7, data5, data1], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingSessions = []\n",
    "hexTests = []\n",
    "for trainKey in range(0, 20):\n",
    "    sessionForEncoding = hexSessions[hexSessions.keys()[trainKey]]\n",
    "    hexTests.append(sessionForEncoding)\n",
    "    oneHotSes = oneSessionEncoder(sessionForEncoding,packetReverse=packetReverse, hexDict = hexDict, \n",
    "                                  padOldTimeSteps = packetReverse,\n",
    "                                  maxPackets = maxPackets, \n",
    "                                  packetTimeSteps = packetTimeSteps)\n",
    "    trainingSessions.append(oneHotSes)\n",
    "\n",
    "sessionsMinibatch = np.asarray(trainingSessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2, 300, 257)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessionsMinibatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-f66922d534e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestCont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msessionsMinibatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "testCont(sessionsMinibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac05582b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testCont(sessionsMinibatch)[0][2][-1].squeeze(), 'b', testCont(sessionsMinibatch)[0][3][-1].squeeze(), 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54]),\n",
       " array([  0,  26, 140,  21, 249, 128,  64,  97, 134, 154, 241, 245,   8,\n",
       "          0,  69,   0,   0,  40,  46, 178,  64,   0, 128,   6, 247, 233,\n",
       "        192, 168,   3, 131,  65,  55, 206, 209, 218, 145,   0,  80, 175,\n",
       "         70, 163, 161,  49,  96, 168,  34,  80,  16, 250, 240, 217,  98,\n",
       "          0,   0, 256]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.where((sessionsMinibatch[1][-1] == sessionsMinibatch[2][-1]) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996562905318 1.0\n",
      "0.999286640726 1.0\n",
      "1.0 1.0\n",
      "0.999286640726 1.0\n",
      "0.999286640726 1.0\n",
      "0.999208819715 1.0\n",
      "0.999286640726 1.0\n",
      "0.999286640726 1.0\n",
      "1.0 1.0\n",
      "0.999208819715 1.0\n",
      "0.999208819715 1.0\n",
      "0.999208819715 1.0\n",
      "0.996108949416 0.0\n",
      "0.999286640726 1.0\n",
      "0.996108949416 0.0\n",
      "0.999208819715 1.0\n",
      "0.999286640726 1.0\n",
      "0.999208819715 1.0\n",
      "0.999286640726 1.0\n",
      "0.996108949416 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print np.mean(sessionsMinibatch[2][-1]==sessionsMinibatch[i][-1]), np.mean(testCont(sessionsMinibatch)[0][2][-1]==testCont(sessionsMinibatch)[0][i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = T.mean(scanOut)\n",
    "#cost = BinaryCrossEntropy().apply(Y, softout)\n",
    "cg = ComputationGraph([cost])\n",
    "learning_rate = 0.0001\n",
    "params = VariableFilter(roles = [PARAMETER])(cg.variables)\n",
    "updates = Adam(params, cost, learning_rate, c=5) #c is gradient clipping parameter\n",
    "#updates = RMSprop(cost, params, learning_rate, c=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "gradients = T.grad(cost, params)\n",
    "gradients = clip_norms(gradients, 1)\n",
    "gradientFun = theano.function([X], gradients, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling you beautiful person\n",
      "finished compiling\n"
     ]
    }
   ],
   "source": [
    "print \"compiling you beautiful person\"\n",
    "train = theano.function([X], cost, updates = updates, allow_input_downcast=True)\n",
    "#predict = theano.function([X], softout, allow_input_downcast=True)\n",
    "print \"finished compiling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Epoch:  0\n",
      "Epoch cost average:  710.844\n",
      " \n",
      "Epoch:  2\n",
      "Epoch cost average:  707.899\n",
      " \n",
      "Epoch:  4\n",
      "Epoch cost average:  705.632\n",
      " \n",
      "Epoch:  6\n",
      "Epoch cost average:  703.782\n",
      " \n",
      "Epoch:  8\n",
      "Epoch cost average:  702.137\n"
     ]
    }
   ],
   "source": [
    "#Eventually we will need to do all of the transformations on the fly so we can pull from disc\n",
    "hexSessionsKeys = hexSessions.keys()\n",
    "#random.shuffle(hexSessionsKeys)\n",
    "trainPercent = 0.9\n",
    "trainIndex = int(len(hexSessionsKeys)*trainPercent)\n",
    "\n",
    "runname = 'hred'\n",
    "epochCost = []\n",
    "gradNorms = []\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 20\n",
    "iteration = 0\n",
    "\n",
    "\n",
    "for epoch in xrange(epochs):\n",
    "    costCollect = []\n",
    "\n",
    "    for start, end in zip(range(0, trainIndex,batch_size), range(batch_size, trainIndex, batch_size)):\n",
    "        #build a 4d array of oneHot sessions\n",
    "        \n",
    "        trainingSessions = []\n",
    "        for trainKey in range(start, end):\n",
    "            sessionForEncoding = hexSessions[hexSessions.keys()[trainKey]]\n",
    "            oneHotSes = oneSessionEncoder(sessionForEncoding, packetReverse=packetReverse, \n",
    "                                          padOldTimeSteps = packetReverse,\n",
    "                                          hexDict = hexDict,\n",
    "                                          maxPackets = maxPackets, packetTimeSteps = packetTimeSteps)\n",
    "            trainingSessions.append(oneHotSes)\n",
    "            \n",
    "        sessionsMinibatch = np.asarray(trainingSessions)\n",
    "        \n",
    "    \n",
    "        costfun = train(sessionsMinibatch)\n",
    "        costCollect.append(costfun)\n",
    "                \n",
    "        iteration+=1\n",
    "        \n",
    "    ####SAVE COST TO FILE  \n",
    "    if epoch%2 == 0:\n",
    "        print(' ')\n",
    "        print 'Epoch: ', epoch\n",
    "        epochCost.append(np.mean(costCollect))\n",
    "        print 'Epoch cost average: ', epochCost[-1]\n",
    "        #grads = gradientFun(inputs, outputs)\n",
    "        #for gra in grads:\n",
    "        #    print '  gradient norms: ', np.linalg.norm(gra)\n",
    "        \n",
    "    np.savetxt(runname+\"_COST.csv\", epochCost, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = T.matrix('targets')\n",
    "batch_sizeClass = 20\n",
    "numClasses = 2\n",
    "clippings = 5\n",
    "learning_rateClass = 0.001\n",
    "classifierWts = IsotropicGaussian(0.08, 0)\n",
    "\n",
    "bmlp = BatchNormalizedMLP(activations=[Tanh(),Tanh()], \n",
    "           dims=[dimDec, dimDec, 2],\n",
    "           weights_init=classifierWts,\n",
    "           biases_init=Constant(0.0) )\n",
    "\n",
    "\n",
    "bmlp.initialize()\n",
    "\n",
    "def oneStep(X):\n",
    "    ###ENCODER\n",
    "    \n",
    "    data1class, data2class = fork.apply(X) #reusing the weights from fork, rnn, and rnnContext\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        hEncclass = rnn.apply(data1class, data2class)[:,-1] #the [:,-1] gets the last hidden state for \n",
    "                                                            #each obs in minibatch i.e. the last state \n",
    "                                                            #for each sentence\n",
    "    else:\n",
    "        hinitclass, _ = rnn.apply(data2class)\n",
    "        hEncclass = hinitclass[:,-1]\n",
    "    \n",
    "    hEncclass = T.reshape(hEncclass,(maxPackets, 1, dim))\n",
    "    \n",
    "    data3class, data4class = forkContext.apply(hEncclass)\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        hContextClass = rnnContext.apply(data3class, data4class)\n",
    "    else:\n",
    "        hinitContextClass, _ = rnnContext.apply(data4class)\n",
    "        hContextClass = hinitContextClass\n",
    "    \n",
    "    if bidirectional:\n",
    "        \n",
    "        data3classRev = data3class[::-1]\n",
    "        data4classRev = data4class[::-1]\n",
    "        \n",
    "        if rnnType == 'gru':\n",
    "            hContextRev = rnnContextRev.apply(data3classRev, data4classRev)\n",
    "        else:\n",
    "            hinitContextRevClass, _ = rnnContextRev.apply(data4classRev)\n",
    "            hContextRevClass = hinitContextRevClass\n",
    "        \n",
    "        hContextClass = T.concatenate((hContextClass, hContextRevClass), axis=2)\n",
    "        \n",
    "    return hContextClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hContextClass, _ = theano.scan(fn = oneStep, sequences=[X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#newhContextClass = hContextClass[:, -1].reshape((batch_sizeClass, dimDec)) \n",
    "newhContextClass = T.mean(hContextClass, axis = (1,2))\n",
    "pyx = bmlp.apply(newhContextClass)\n",
    "softmax = Softmax()\n",
    "softoutClass = softmax.apply(pyx)\n",
    "costClass = T.mean(BinaryCrossEntropy().apply(Y, softoutClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cgClass = ComputationGraph([costClass])\n",
    "paramsClass = VariableFilter(roles = [PARAMETER])(cgClass.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updatesClass = Adam(paramsClass, costClass, learning_rateClass, c=clippings) \n",
    "#updatesClass = RMSprop(costClass, paramsClass, learning_rateClass, c=clippings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print 'grad compiling'\n",
    "gradients = T.grad(costClass, paramsClass)\n",
    "gradients = clip_norms(gradients, clippings)\n",
    "gradientFun = theano.function([X,Y], gradients, allow_input_downcast=True)\n",
    "print 'finish with grads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling functions you talented soul\n",
      "finished compiling\n"
     ]
    }
   ],
   "source": [
    "print 'compiling functions you talented soul'\n",
    "classifierTrain = theano.function([X,Y], [softoutClass,costClass], updates=updatesClass, allow_input_downcast=True)\n",
    "#classifierPredict = theano.function([X], softoutClass, allow_input_downcast=True)\n",
    "print 'finished compiling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-71552df89822>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mtargetsMinibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingTargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mcostfun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifierTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msessionsMinibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetsMinibatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mcostCollect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcostfun\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/bradh/.theano/compiledir_Linux-4.2--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/scan_perform/mod.cpp:4193)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mallow_gc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_input_storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mfree\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes_with_inner_function\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runname = 'hredClassify'\n",
    "epochCost = []\n",
    "gradNorms = []\n",
    "\n",
    "epochs = 300\n",
    "iteration = 0\n",
    "\n",
    "normalTarget = np.array([0,1], dtype=theano.config.floatX)\n",
    "abbyTarget = np.array([1,0], dtype=theano.config.floatX)\n",
    "\n",
    "for epoch in xrange(epochs):\n",
    "    costCollect = []\n",
    "\n",
    "    for start, end in zip(range(0, trainIndex,batch_sizeClass/2),\n",
    "                          range(batch_sizeClass/2, trainIndex, batch_sizeClass/2)):\n",
    "\n",
    "        #build a 4d array of oneHot sessions\n",
    "        \n",
    "        trainingTargets = []\n",
    "        trainingSessions = []\n",
    "        for trainKey in range(start, end):\n",
    "            sessionForEncoding = hexSessions[hexSessions.keys()[trainKey]]\n",
    "            \n",
    "            #encode a normal session\n",
    "            oneHotSes = oneSessionEncoder(sessionForEncoding,hexDict = hexDict, packetReverse=packetReverse, \n",
    "                                          padOldTimeSteps = packetReverse, maxPackets = maxPackets,\n",
    "                                          packetTimeSteps = packetTimeSteps)\n",
    "            trainingSessions.append(oneHotSes)\n",
    "            trainingTargets.append(normalTarget)\n",
    "            \n",
    "            #encode an abby normal session\n",
    "            abbyHexSession = oneIpDirSwitcher(sessionForEncoding)\n",
    "            abbyOneHotSes = oneSessionEncoder(abbyHexSession,hexDict = hexDict,packetReverse=packetReverse, \n",
    "                                          padOldTimeSteps = packetReverse, maxPackets = maxPackets, \n",
    "                                              packetTimeSteps = packetTimeSteps)\n",
    "            trainingSessions.append(abbyOneHotSes)\n",
    "            trainingTargets.append(abbyTarget)\n",
    "             \n",
    "        sessionsMinibatch = np.asarray(trainingSessions, dtype=theano.config.floatX)\n",
    "        targetsMinibatch = np.asarray(trainingTargets, dtype=theano.config.floatX)\n",
    "    \n",
    "        costfun = classifierTrain(sessionsMinibatch, targetsMinibatch)\n",
    "        costCollect.append(costfun[1])\n",
    "                \n",
    "        iteration+=1\n",
    "        \n",
    "    ####SAVE COST TO FILE  \n",
    "    if epoch%2 == 0:\n",
    "        print(' ')\n",
    "        print 'Epoch: ', epoch\n",
    "        epochCost.append(np.mean(costCollect))\n",
    "        print 'Epoch cost average: ', epochCost[-1]\n",
    "        #grads = gradientFun(sessionsMinibatch, targetsMinibatch)\n",
    "        print 'pyx: ', costfun[0]\n",
    "        #for gra in grads:\n",
    "        #    print '  gradient norms: ', np.linalg.norm(gra)\n",
    "        \n",
    "    np.savetxt(runname+\"_COST.csv\", epochCost, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advesarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary of packet/session stats\n",
    "\n",
    "#switch ips\n",
    "#switch ports\n",
    "#swap out and replace one ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tests to show effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#jack up ip field and see diff in prediction before and after\n",
    "#jack up checksum and see diff in prediciton before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 257 #original data dimension/timesteps/columns\n",
    "rnnType = 'gru' #gru or lstm\n",
    "bidirectional = True\n",
    "X = T.tensor3('inputs')\n",
    "Xrev = T.matrix('reversed_inputs')\n",
    "linewt_init = Uniform(width=0.08)\n",
    "rnnwt_init = IsotropicGaussian(0.05)\n",
    "rnnbias_init = Constant(0.0)\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    rnn = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "###RECURRENT LAYER\n",
    "\n",
    "#To use or not to use that is the question\n",
    "fork = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "data1, data2 = fork.apply(X)\n",
    "\n",
    "###for raw inputs\n",
    "#data1 = X\n",
    "#data2 = T.concatenate([X]*dimMultiplier, axis=2)\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hEnc = rnn.apply(data1, data2)[:,-1] #the [:,-1] gets the last hidden state for each obs in minibatch\n",
    "                                         #i.e. the last state for each sentence\n",
    "else:\n",
    "    hinit, _ = rnn.apply(data2)\n",
    "    hEnc = hinit[:,-1]\n",
    "\n",
    "hEnc = T.reshape(hEnc,(maxPackets, 1, dim))\n",
    "#get weights initialized. without weights are nans.\n",
    "fork.initialize()\n",
    "rnn.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST Encoder will return a maxPackets x packet length matrix\n",
    "encoder = theano.function([X], hEnc, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST ENCODED PACKETS shape = (maxPackets, 1, dim)\n",
    "encoder(sessions[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X = T.tensor4('testInputs')\n",
    "Y = T.vector('targets')\n",
    "dim = 257 #original data dimension/timesteps/columns\n",
    "dimDec = dim*2\n",
    "rnnType = 'gru' #gru or lstm\n",
    "bidirectional = True\n",
    "linewt_init = Uniform(width=0.05)\n",
    "rnnwt_init = IsotropicGaussian(0.02)\n",
    "rnnbias_init = Constant(0.0)\n",
    "\n",
    "def oneStep(X):\n",
    "    ###ENCODER\n",
    "    if rnnType == 'gru':\n",
    "        rnn = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "        dimMultiplier = 2\n",
    "    else:\n",
    "        rnn = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "        dimMultiplier = 4\n",
    "    \n",
    "    #To use (fork) or not to use that is the question\n",
    "    fork = Fork(output_names=['linear', 'gates'],\n",
    "                name='fork', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "                weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "    data1, data2 = fork.apply(X)\n",
    "\n",
    "    ###for raw inputs... for not using fork\n",
    "    #data1 = X\n",
    "    #data2 = T.concatenate([X]*dimMultiplier, axis=2)\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hEnc = rnn.apply(data1, data2)[:,-1] #the [:,-1] gets the last hidden state for each obs in minibatch\n",
    "                                             #i.e. the last state for each sentence\n",
    "    else:\n",
    "        hinit, _ = rnn.apply(data2)\n",
    "        hEnc = hinit[:,-1]\n",
    "\n",
    "    hEnc = T.reshape(hEnc,(maxPackets, 1, dim))\n",
    "\n",
    "    fork.initialize()\n",
    "    rnn.initialize()\n",
    "\n",
    "    \n",
    "    ###CONTEXT\n",
    "    if rnnType == 'gru':\n",
    "        rnnContext = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                    biases_init = rnnbias_init, name = 'gruContext')\n",
    "        dimMultiplier = 2\n",
    "    else:\n",
    "        rnnContext = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, \n",
    "                          name = 'lstmContext')\n",
    "        dimMultiplier = 4\n",
    "\n",
    "    ###RECURRENT LAYER\n",
    "    forkContext = Fork(output_names=['linearContext', 'gatesContext'],\n",
    "                name='forkContext', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "                weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "    data3, data4 = forkContext.apply(hEnc)\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hContext = rnnContext.apply(data3, data4)\n",
    "    else:\n",
    "        hinitContext, _ = rnnContext.apply(data4)\n",
    "        hContext = hinitContext\n",
    "\n",
    "    #THINK ABOUT ADDING L2 POOLING BEFORE CAT\n",
    "    if bidirectional:\n",
    "\n",
    "        data3 = data3[::-1]\n",
    "        data4 = data4[::-1]\n",
    "\n",
    "        if rnnType == 'gru':\n",
    "            rnnContextRev = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                           biases_init = rnnbias_init, name = 'gruContextRev')\n",
    "            hContextRev = rnnContextRev.apply(data3, data4)\n",
    "        else:\n",
    "            rnnContextRev = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init,\n",
    "                                 name = 'lstmContextRev')\n",
    "            hinitContext, _ = rnnContextRev.apply(data4)\n",
    "            hContextRev = hinitContext\n",
    "\n",
    "\n",
    "        hContext = T.concatenate((hContext, hContextRev), axis=2)\n",
    "        rnnContextRev.initialize()\n",
    "\n",
    "    forkContext.initialize()\n",
    "    rnnContext.initialize()\n",
    "\n",
    "    \n",
    "    ###DECODER\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        rnnDec = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                biases_init = rnnbias_init, name = 'gruDecoder')\n",
    "        dimMultiplier = 2\n",
    "    else:\n",
    "        rnnDec = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstmDecoder')\n",
    "        dimMultiplier = 4\n",
    "\n",
    "\n",
    "    forkDec = Fork(output_names=['linear', 'gates'],\n",
    "                name='forkDec', input_dim=dimDec, output_dims=[dim, dim*dimMultiplier], \n",
    "                weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "\n",
    "    forkFinal = Fork(output_names=['linear', 'gates'],\n",
    "                name='forkDec', input_dim=dim, output_dims=[dim, dim*dimMultiplier], \n",
    "                weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "\n",
    "    data5, data6 = forkDec.apply(hContext)#reduce dimension of bidirectLSTM\n",
    "\n",
    "    #decoding data needs to be one timestep (next packet in session) ahead, thus data1 we ignore the first packet\n",
    "    #and the last hidden state of the context RNN.\n",
    "    data7 = T.concatenate((data5[:-1,:,:], data1[1:, :-1, :]), axis=1) #data1 is the original embedding of X\n",
    "\n",
    "    #data8 = T.concatenate((data7, data5), axis = 2)\n",
    "    data8, data9 = forkFinal.apply(data7)\n",
    "\n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hDec = rnnDec.apply(data8, data9) \n",
    "    else:\n",
    "        hinit, _ = rnnDec.apply(data9)\n",
    "        hDec = hinit\n",
    "\n",
    "    #Smooth out the probabilities of hDec\n",
    "    softmax = NDimensionalSoftmax()\n",
    "    softout = softmax.apply(hDec, extra_ndim = 1)\n",
    "\n",
    "\n",
    "    precost = X[1:, :, :]*np.log(softout) + (1-X[1:, :, :])*np.log(1-softout)\n",
    "    precost2 = -T.sum(T.sum(precost, axis = 2), axis = 1)\n",
    "    #precost2 = -T.mean(T.sum(T.sum(precost, axis = 2), axis = 1))\n",
    "    \n",
    "    #cost = BinaryCrossEntropy().apply(X[1:, :, :], softout)\n",
    "\n",
    "    forkDec.initialize()\n",
    "    forkFinal.initialize()\n",
    "    rnnDec.initialize()\n",
    "    \n",
    "    return precost2, hEnc, hContext, hDec, softout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if rnnType == 'gru':\n",
    "    rnnContext = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                biases_init = rnnbias_init, name = 'gruContext')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnnContext = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, \n",
    "                      name = 'lstmContext')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "\n",
    "###ICLR suggestion -> don't use bias in RNNs\n",
    "\n",
    "###RECURRENT LAYER\n",
    "forkContext = Fork(output_names=['linearContext', 'gatesContext'],\n",
    "            name='forkContext', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "data3, data4 = forkContext.apply(hEnc)\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hContext = rnnContext.apply(data3, data4)\n",
    "else:\n",
    "    hinitContext, _ = rnnContext.apply(data4)\n",
    "    hContext = hinitContext\n",
    "\n",
    "#THINK ABOUT ADDING L2 POOLING BEFORE CAT\n",
    "if bidirectional:\n",
    "    \n",
    "    data3 = data3[::-1]\n",
    "    data4 = data4[::-1]\n",
    "    \n",
    "    if rnnType == 'gru':\n",
    "        rnnContextRev = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                                       biases_init = rnnbias_init, name = 'gruContextRev')\n",
    "        hContextRev = rnnContextRev.apply(data3, data4)\n",
    "    else:\n",
    "        rnnContextRev = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init,\n",
    "                             name = 'lstmContextRev')\n",
    "        hinitContext, _ = rnnContextRev.apply(data4)\n",
    "        hContextRev = hinitContext\n",
    "    \n",
    "    \n",
    "    hContext = T.concatenate((hContext, hContextRev), axis=2)\n",
    "    rnnContextRev.initialize()\n",
    "    \n",
    "#get weights initialized. without weights are nans.\n",
    "forkContext.initialize()\n",
    "rnnContext.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST output shape = (maxPackets, 1, dim*2)\n",
    "context = theano.function([X], hContext, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "context(sessions[1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dimDec = dim*2\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    rnnDec = GatedRecurrent(dim=dim, weights_init = rnnwt_init, \n",
    "                            biases_init = rnnbias_init, name = 'gruDecoder')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnnDec = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstmDecoder')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "\n",
    "forkDec = Fork(output_names=['linear', 'gates'],\n",
    "            name='forkDec', input_dim=dimDec, output_dims=[dim, dim*dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "\n",
    "forkFinal = Fork(output_names=['linear', 'gates'],\n",
    "            name='forkDec', input_dim=dim, output_dims=[dim, dim*dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = rnnbias_init)\n",
    "\n",
    "data5, data6 = forkDec.apply(hContext)#reduce dimension of bidirectLSTM\n",
    "\n",
    "#decoding data needs to be one timestep (next packet in session) ahead, thus data1 we ignore the first packet\n",
    "#and the last hidden state of the context RNN.\n",
    "data7 = T.concatenate((data5[:-1,:,:], data1[1:, :-1, :]), axis=1) #data1 is the original embedding of X\n",
    "\n",
    "#data8 = T.concatenate((data7, data5), axis = 2)\n",
    "data8, data9 = forkFinal.apply(data7)\n",
    "\n",
    "\n",
    "if rnnType == 'gru':\n",
    "    hDec = rnnDec.apply(data8, data9) \n",
    "else:\n",
    "    hinit, _ = rnnDec.apply(data9)\n",
    "    hDec = hinit\n",
    "\n",
    "#Smooth out the probabilities of hDec\n",
    "softmax = NDimensionalSoftmax()\n",
    "softout = softmax.apply(hDec, extra_ndim = 1)\n",
    "    \n",
    "\n",
    "precost = X[1:, :, :]*np.log(softout) + (1-X[1:, :, :])*np.log(1-softout)\n",
    "cost = -T.mean(T.sum(T.sum(precost, axis = 2), axis = 1))\n",
    "#cost = BinaryCrossEntropy().apply(X[1:, :, :], softout)\n",
    "\n",
    "#get weights initialized\n",
    "forkDec.initialize()\n",
    "forkFinal.initialize()\n",
    "rnnDec.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def oneHotSessions(sessionDict, hexDict = hexDict, maxPackets = maxPackets, packetTimeSteps = packetTimeSteps,\\n                   reverse = False, charLevel = False):\\n    \"\"\"\\n    This takes a list of int tokens and onehot encodes them, pads sessions with zero tensors according to maxPackets\\n    and packet according to packetTimeSteps\\n    \\n    sessionDict = dict of lists of key = sessions and value = list of packets\\n    timeSteps = maximum len of packet. it will be padded with zero vectors is packet is too short.\\n    \\n    \"\"\"\\n    \\n    listOsessions = []\\n\\n    if charLevel:\\n        vecLen = 17\\n    else:\\n        vecLen = 257\\n    \\n    sessionKeys = sessionDict.keys()\\n    \\n    for session in sessionKeys:\\n        \\n        sessionCollect = oneSessionEncoder(session, hexDict = hexDict, maxPackets = maxPackets, \\n                                           packetTimeSteps = packetTimeSteps, reverse = reverse, \\n                                           charLevel = charLevel )\\n        \\n        listOsessions.append(sessionCollect)\\n        \\n    return listOsessions'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   \n",
    "'''def oneHotSessions(sessionDict, hexDict = hexDict, maxPackets = maxPackets, packetTimeSteps = packetTimeSteps,\n",
    "                   reverse = False, charLevel = False):\n",
    "    \"\"\"\n",
    "    This takes a list of int tokens and onehot encodes them, pads sessions with zero tensors according to maxPackets\n",
    "    and packet according to packetTimeSteps\n",
    "    \n",
    "    sessionDict = dict of lists of key = sessions and value = list of packets\n",
    "    timeSteps = maximum len of packet. it will be padded with zero vectors is packet is too short.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    listOsessions = []\n",
    "\n",
    "    if charLevel:\n",
    "        vecLen = 17\n",
    "    else:\n",
    "        vecLen = 257\n",
    "    \n",
    "    sessionKeys = sessionDict.keys()\n",
    "    \n",
    "    for session in sessionKeys:\n",
    "        \n",
    "        sessionCollect = oneSessionEncoder(session, hexDict = hexDict, maxPackets = maxPackets, \n",
    "                                           packetTimeSteps = packetTimeSteps, reverse = reverse, \n",
    "                                           charLevel = charLevel )\n",
    "        \n",
    "        listOsessions.append(sessionCollect)\n",
    "        \n",
    "    return listOsessions'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "decoder = theano.function([X], cost, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = T.tensor4('input')\n",
    "decoderTest = theano.function([X], cost, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: make a training function\n",
    "runname = 'firstRun'\n",
    "epochCost = []\n",
    "gradNorms = []\n",
    "\n",
    "epochs = 200000\n",
    "batch_size = 64\n",
    "iteration = 0\n",
    "\n",
    "for epoch in xrange(epochs):\n",
    "    \n",
    "    costCollect = []\n",
    "\n",
    "    for start, end in zip(range(0, len(trainData),batch_size), range(batch_size, len(trainData), batch_size)):\n",
    "        \n",
    "        inputs = trainData[start:end]\n",
    "        outputs = targetMaker(inputs)\n",
    "        costfun = train(inputs, outputs)\n",
    "        \n",
    "        \n",
    "        costCollect.append(costfun)\n",
    "                \n",
    "        iteration+=1\n",
    "        \n",
    "    ####SAVE COST TO FILE  \n",
    "    if epoch%30 == 0:\n",
    "        print(' ')\n",
    "        print 'Epoch: ', epoch\n",
    "        epochCost.append(np.mean(costCollect))\n",
    "        print 'Epoch cost average: ', epochCost[-1]\n",
    "        grads = gradientFun(inputs, outputs)\n",
    "        for gra in grads:\n",
    "            print '  gradient norms: ', np.linalg.norm(gra)\n",
    "        \n",
    "    \n",
    "    np.savetxt(runname+\"_COST.csv\", epochCost, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GPU TO CPU conversion\n",
    "#Now get the weights from the test function. These weights will be numpy arrays\n",
    "w1 = test.get_shared()[0].get_value()\n",
    "\n",
    "#Here the weights are going to be set to the numpy arrays taken from the GPU predict function\n",
    "input_linear.parameters[0].set_value(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.get_shared()[2].get_value().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = '1234567890abcdefghijklmnopqrstuvwxyz'\n",
    "words = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#we add 256 on the end to signify the end of the packet ('EOP')\n",
    "\n",
    "maxPackets = 10 #limit the number of packets\n",
    "tokSessions = []\n",
    "oneHotSessions = []\n",
    "\n",
    "for ses in hexSessions.keys():    \n",
    "    tokPacket = []\n",
    "    oneHotPacket = []\n",
    "    for p in hexSessions[ses][:maxPackets]:\n",
    "        tokP = [hexDict[p[i:i+2]] for i in xrange(0,len(p)-2+1,2)]+[256] #takes hexstring and tokenizes hex pairs\n",
    "        tokPacket.append(tokP)\n",
    "        oneHotPacket.append(oneHot(tokP))\n",
    "\n",
    "    tokSessions.append(tokPacket)\n",
    "    oneHotSessions.append(oneHotPacket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ALT RNN LAYER\n",
    "def initialize(to_init):\n",
    "    for bricks in to_init:\n",
    "        bricks.weights_init = initialization.Uniform(width=0.08)\n",
    "        bricks.biases_init = initialization.Constant(0)\n",
    "        bricks.initialize()\n",
    "\n",
    "def gru_layer(dim, h, n):\n",
    "    fork = Fork(output_names=['linear' + str(n), 'gates' + str(n)],\n",
    "                name='fork' + str(n), input_dim=dim, output_dims=[dim, dim * 2])\n",
    "    gru = GatedRecurrent(dim=dim, name='gru' + str(n))\n",
    "    initialize([fork, gru])\n",
    "    linear, gates = fork.apply(h)\n",
    "    return gru.apply(linear, gates)\n",
    "\n",
    "\n",
    "def lstm_layer(dim, h, n):\n",
    "    linear = Linear(input_dim=dim, output_dim=dim * 4, name='linear' + str(n))\n",
    "    lstm = LSTM(dim=dim, name='lstm' + str(n))\n",
    "    initialize([linear, lstm])\n",
    "    return lstm.apply(linear.apply(h))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
